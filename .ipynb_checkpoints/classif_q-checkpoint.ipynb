{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification de la question**\n",
    "\n",
    "Lorsque l'agent reçoit une question, il devra décider si la question est réellement liée au domaine métier ou non. Si oui et si les données sont en plus regroupées par thématiques, une deuxième décision est à prendre : sur laquelle de ces thématiques porte la question.\n",
    "\n",
    "Si c'est une question métier, le chatbot retournera une réponse pertinente selon sa stratégie ; si non, il déclenchera la composante conversationnelle, qui produira une réponse originale.\n",
    "\n",
    "Il faut donc mettre en place une stratégie pour la prise de ces décisions et pour la sélection de la réponse.\n",
    "\n",
    "Quelle que soit l'approche il faudra d'abord :\n",
    "\n",
    "    prétraiter la base de données (à faire une seule fois et à stocker). Attention, si on vectorise le corpus il faudra garder le vectoriseur (l'enregistrer comme pickle) pour appliquer ensuite le même vectoriseur à la question ;\n",
    "    prétraiter la question (en temps réel).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prétraitement textuel de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lecture du fichier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reponse</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>Il est possible d’arriver n’importe quel jour ...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>Le classement par « birdies » évalue l’offre C...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>En réservant votre hébergement, vous bénéficie...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>Lors de la réservation de votre hébergement, v...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>Sur la page d'accueil de notre site, cliquez s...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   Quels sont les jours d’arrivée ?   \n",
       "1  Comment évaluer le confort de mon domaine et d...   \n",
       "2  Quels sont les services et activités compris d...   \n",
       "3                   Comment réserver mes activités ?   \n",
       "4                    Où trouver le plan du domaine ?   \n",
       "\n",
       "                                             reponse                theme  \n",
       "0  Il est possible d’arriver n’importe quel jour ...  Préparer mon séjour  \n",
       "1  Le classement par « birdies » évalue l’offre C...  Préparer mon séjour  \n",
       "2  En réservant votre hébergement, vous bénéficie...  Préparer mon séjour  \n",
       "3  Lors de la réservation de votre hébergement, v...  Préparer mon séjour  \n",
       "4  Sur la page d'accueil de notre site, cliquez s...  Préparer mon séjour  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq = pd.read_pickle('faq_centerPark.pkl')\n",
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données est composé de :\n",
    "- 54 lignes\n",
    "- 3 colonnes\n",
    "- 5 thèmes différents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pose :\n",
    "- 1 = Préparer mon séjour\n",
    "- 2 = Réserver et payer\n",
    "- 3 = Gérer ma réservation\n",
    "- 4 = Mon séjour\n",
    "- 5 = Assurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_code_theme = {\"Préparer mon séjour\": 1,\n",
    "                  \"Réserver et payer\": 2,\n",
    "                  \"Gérer ma réservation\": 3,\n",
    "                  \"Mon séjour\": 4,\n",
    "                  \"Assurances\": 5}\n",
    "dic_decode_theme = {val: key for key, val in dic_code_theme.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faq[\"theme\"].replace(dic_code_theme, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reponse</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>Il est possible d’arriver n’importe quel jour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>Le classement par « birdies » évalue l’offre C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>En réservant votre hébergement, vous bénéficie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>Lors de la réservation de votre hébergement, v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>Sur la page d'accueil de notre site, cliquez s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   Quels sont les jours d’arrivée ?   \n",
       "1  Comment évaluer le confort de mon domaine et d...   \n",
       "2  Quels sont les services et activités compris d...   \n",
       "3                   Comment réserver mes activités ?   \n",
       "4                    Où trouver le plan du domaine ?   \n",
       "\n",
       "                                             reponse  theme  \n",
       "0  Il est possible d’arriver n’importe quel jour ...      1  \n",
       "1  Le classement par « birdies » évalue l’offre C...      1  \n",
       "2  En réservant votre hébergement, vous bénéficie...      1  \n",
       "3  Lors de la réservation de votre hébergement, v...      1  \n",
       "4  Sur la page d'accueil de notre site, cliquez s...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enora\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_question = df_faq[['question', 'theme']]\n",
    "df_question.rename(columns={'question': 'texte', 'theme': 'theme'}, inplace=True)\n",
    "df_reponse = df_faq[['reponse', 'theme']]\n",
    "df_reponse.rename(columns={'reponse': 'texte', 'theme': 'theme'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_question, df_reponse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puis-je venir avec mon animal domestique ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peut-on accéder au domaine à la journée (sans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Comment réserver un logement adapté aux person...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Comment recevoir la brochure ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Est-il possible d'acheter des billets pour les...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Un visa ou un passeport est-il impératif pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Comment utiliser l’offre Early Booking avec le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Y a-t-il un service bagagerie pour déposer mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Y'a-t-il des frais de dossier ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dois-je payer la totalité de mon séjour au mom...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ai-je un droit de rétractation ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Comment payer si je réserve mon séjour sur le ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Comment payer si je réserve mon séjour via le ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Puis-je adresser mon règlement par courrier ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Comment puis-je payer si je ne réside pas en F...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texte  theme\n",
       "0                    Quels sont les jours d’arrivée ?      1\n",
       "1   Comment évaluer le confort de mon domaine et d...      1\n",
       "2   Quels sont les services et activités compris d...      1\n",
       "3                    Comment réserver mes activités ?      1\n",
       "4                     Où trouver le plan du domaine ?      1\n",
       "5          Puis-je venir avec mon animal domestique ?      1\n",
       "6   Peut-on accéder au domaine à la journée (sans ...      1\n",
       "7   Comment réserver un logement adapté aux person...      1\n",
       "8                      Comment recevoir la brochure ?      1\n",
       "9   Est-il possible d'acheter des billets pour les...      1\n",
       "10  Un visa ou un passeport est-il impératif pour ...      1\n",
       "11  Comment utiliser l’offre Early Booking avec le...      1\n",
       "12  Y a-t-il un service bagagerie pour déposer mes...      1\n",
       "13                    Y'a-t-il des frais de dossier ?      2\n",
       "14  Dois-je payer la totalité de mon séjour au mom...      2\n",
       "15                   Ai-je un droit de rétractation ?      2\n",
       "16  Comment payer si je réserve mon séjour sur le ...      2\n",
       "17  Comment payer si je réserve mon séjour via le ...      2\n",
       "18      Puis-je adresser mon règlement par courrier ?      2\n",
       "19  Comment puis-je payer si je ne réside pas en F...      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "df_concat.to_pickle('df_concat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Définition de fonctions pour le nettoyage du texte des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# pour le nettoyage du texte\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# pour la classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.read_pickle('df_concat.pkl')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_concat['texte'],\n",
    "                                                    df_concat['theme'],\n",
    "                                                    train_size=0.7,\n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('french')\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # tokenizer for tweet\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']\n",
    "sw.sort()\n",
    "\n",
    "def lemmatise_text(text):\n",
    "    lst_lematised = [token.lemma_ for token in nlp(text)] \n",
    "    return ' '.join(lst_lematised).lower()\n",
    "\n",
    "\n",
    "def stem_text(text):\n",
    "    lst_stemmerised = [stemmer.stem(token) for token in tokenizer.tokenize(text)]    \n",
    "    return ' '.join(lst_stemmerised)\n",
    "\n",
    "\n",
    "def replace_words_with_pos_tag(text):\n",
    "    lst_tags = [token.pos_ for token in nlp(text)]    \n",
    "    return ' '.join(lst_tags)\n",
    "\n",
    "\n",
    "def ner(text): #entites nommees\n",
    "    dico_remplacement = {entite_nommee.text : entite_nommee.label_ for entite_nommee in nlp(text).ents}\n",
    "    for entite_nommee, remplacement in dico_remplacement.items():\n",
    "        text = text.replace(entite_nommee, remplacement)\n",
    "    return text\n",
    "\n",
    "\n",
    "def substitute_punctuation(text):\n",
    "    return ' '.join(text.replace(\"'\", ' ').translate(str.maketrans('', '', string.punctuation)).split())\n",
    "\n",
    "\n",
    "def substitute_number(text, url_replacement=''):\n",
    "    return re.sub(r\"\\d\", url_replacement, text)\n",
    "\n",
    "\n",
    "def supp(text):\n",
    "    return text.replace(\"«\", \"\").replace(\"’\", \"\").replace(\"•\", \"\").replace(\"®\", \"\")\n",
    "\n",
    "\n",
    "def supprime_accent(txt):\n",
    "    return unidecode.unidecode(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Nettoyage du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Nettoyage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On combine quelques fonctions définies en partie A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = (X_train.apply(lemmatise_text)\n",
    "                        .apply(stem_text)\n",
    "                        .apply(substitute_punctuation)\n",
    "                        .apply(supprime_accent)\n",
    "#                         .apply(substitute_number)\n",
    "                         .apply(supp)\n",
    "                )\n",
    "X_test_clean = (X_test.apply(lemmatise_text)\n",
    "                       .apply(stem_text)\n",
    "                       .apply(substitute_punctuation)\n",
    "                       .apply(supprime_accent)\n",
    "#                        .apply(substitute_number)\n",
    "                        .apply(supp)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test de différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tester différents modèles sur le texte des tweets qui ont été nettoyés dans la partie 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Les différents vectoriseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriseur numérique discret\n",
    "\n",
    "vect_count = CountVectorizer(binary=False)\n",
    "vect_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_count = vect_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_count = vect_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriseur binaire\n",
    "\n",
    "bin_count = CountVectorizer(binary=True)\n",
    "bin_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_bin = vect_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_bin = vect_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vectoriseur numérique continu : TF-IDF\n",
    "\n",
    "vect_tfidf = TfidfVectorizer(stop_words=sw)\n",
    "vect_tfidf.fit(X_train_clean)\n",
    "X_train_clean_vectorized_tfidf = vect_tfidf.transform(X_train_clean)\n",
    "X_test_clean_vectorized_tfidf = vect_tfidf.transform(X_test_clean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Les différents modèles\n",
    "\n",
    "Nous entraînerons des modèles de classification appartenant à quelques familles d'algorithmes d'apprentissage automatique classique. L'objectif est de comparer non seulement les performances des différentes méthodes entre elles, mais aussi la performance d'une même méthode sur des représentations différentes du texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b.1 DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='most_frequent').fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_prop_class = DummyClassifier(strategy='most_frequent').fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "pred = random_prop_class.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b.2 Classifieur naïf bayesien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.3 Complement NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.4 BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.5 RandomForestClassifier/LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enora\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestClassifier': 0.48484848484848486, 'LinearSVC': 0.36363636363636365}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=500, max_depth=100, random_state=0),\n",
    "    LinearSVC()\n",
    "]\n",
    "\n",
    "dic_acc = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    predictions_valid = model.fit(X_train_clean_vectorized_count, y_train).predict(X_test_clean_vectorized_count)\n",
    "    dic_acc[model_name] = accuracy_score(y_test, predictions_valid)\n",
    "\n",
    "print(dic_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.6 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(5).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.7. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42424242424242425"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48484848484848486"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.1).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.1).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.8 Réseaux de neurones de convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, SpatialDropout1D, MaxPooling1D, Conv1D, Flatten, MaxPooling2D, Conv2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_clean_vectorized_tfidf.toarray().reshape(X_train_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_train_clean_vectorized_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 8.0583 - accuracy: 0.0000e+00 - val_loss: 5.9808 - val_accuracy: 0.0435\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 6.7330 - accuracy: 0.0385 - val_loss: 5.0590 - val_accuracy: 0.0870\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 5.8343 - accuracy: 0.1731 - val_loss: 4.2685 - val_accuracy: 0.2174\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.5002 - accuracy: 0.2885 - val_loss: 3.8385 - val_accuracy: 0.2174\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.6833 - accuracy: 0.3462 - val_loss: 3.1776 - val_accuracy: 0.2609\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.7920 - accuracy: 0.3846 - val_loss: 2.9163 - val_accuracy: 0.3043\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.3378 - accuracy: 0.3462 - val_loss: 2.3512 - val_accuracy: 0.3478\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 2.1219 - accuracy: 0.4038 - val_loss: 2.2403 - val_accuracy: 0.3043\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.8121 - accuracy: 0.4038 - val_loss: 2.1562 - val_accuracy: 0.3478\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.7250 - accuracy: 0.4423 - val_loss: 1.7299 - val_accuracy: 0.3478\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.6769 - accuracy: 0.4423 - val_loss: 1.6204 - val_accuracy: 0.3043\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.6474 - accuracy: 0.4423 - val_loss: 1.5764 - val_accuracy: 0.3043\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.6300 - accuracy: 0.4615 - val_loss: 1.5504 - val_accuracy: 0.3043\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.6190 - accuracy: 0.5000 - val_loss: 1.5309 - val_accuracy: 0.3478\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.6096 - accuracy: 0.4615 - val_loss: 1.5175 - val_accuracy: 0.3043\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 346us/step - loss: 1.6018 - accuracy: 0.4808 - val_loss: 1.5071 - val_accuracy: 0.3478\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.5938 - accuracy: 0.4808 - val_loss: 1.4969 - val_accuracy: 0.3478\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.5856 - accuracy: 0.5000 - val_loss: 1.4867 - val_accuracy: 0.3913\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.5774 - accuracy: 0.4615 - val_loss: 1.4774 - val_accuracy: 0.4348\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.5682 - accuracy: 0.4615 - val_loss: 1.4687 - val_accuracy: 0.4783\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.5577 - accuracy: 0.4615 - val_loss: 1.4606 - val_accuracy: 0.4783\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.5465 - accuracy: 0.5000 - val_loss: 1.4530 - val_accuracy: 0.4348\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.5349 - accuracy: 0.5385 - val_loss: 1.4459 - val_accuracy: 0.4348\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.5227 - accuracy: 0.5769 - val_loss: 1.4392 - val_accuracy: 0.3478\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 346us/step - loss: 1.5105 - accuracy: 0.5769 - val_loss: 1.4331 - val_accuracy: 0.3478\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.4980 - accuracy: 0.6154 - val_loss: 1.4271 - val_accuracy: 0.3478\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.4853 - accuracy: 0.6346 - val_loss: 1.4216 - val_accuracy: 0.3043\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4720 - accuracy: 0.6346 - val_loss: 1.4164 - val_accuracy: 0.3043\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.4582 - accuracy: 0.6346 - val_loss: 1.4107 - val_accuracy: 0.3043\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.4439 - accuracy: 0.6346 - val_loss: 1.4059 - val_accuracy: 0.3043\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.4290 - accuracy: 0.6346 - val_loss: 1.4020 - val_accuracy: 0.3043\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4142 - accuracy: 0.6346 - val_loss: 1.3988 - val_accuracy: 0.3043\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.3996 - accuracy: 0.6346 - val_loss: 1.3951 - val_accuracy: 0.3043\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3849 - accuracy: 0.6154 - val_loss: 1.3908 - val_accuracy: 0.3478\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 385us/step - loss: 1.3698 - accuracy: 0.6154 - val_loss: 1.3858 - val_accuracy: 0.3913\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.3542 - accuracy: 0.6154 - val_loss: 1.3813 - val_accuracy: 0.3913\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3390 - accuracy: 0.6346 - val_loss: 1.3775 - val_accuracy: 0.3913\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3233 - accuracy: 0.6538 - val_loss: 1.3741 - val_accuracy: 0.3913\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.3075 - accuracy: 0.6538 - val_loss: 1.3709 - val_accuracy: 0.3913\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.2906 - accuracy: 0.6538 - val_loss: 1.3680 - val_accuracy: 0.3913\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.2737 - accuracy: 0.6538 - val_loss: 1.3653 - val_accuracy: 0.3913\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 1.2562 - accuracy: 0.6538 - val_loss: 1.3632 - val_accuracy: 0.3913\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 1.2372 - accuracy: 0.6538 - val_loss: 1.3626 - val_accuracy: 0.3913\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.2170 - accuracy: 0.6923 - val_loss: 1.3628 - val_accuracy: 0.3913\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1958 - accuracy: 0.6923 - val_loss: 1.3645 - val_accuracy: 0.3913\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.1739 - accuracy: 0.6923 - val_loss: 1.3679 - val_accuracy: 0.3913\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.1519 - accuracy: 0.6923 - val_loss: 1.3728 - val_accuracy: 0.3913\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.1291 - accuracy: 0.6923 - val_loss: 1.3785 - val_accuracy: 0.3913\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1058 - accuracy: 0.6923 - val_loss: 1.3853 - val_accuracy: 0.3913\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.0812 - accuracy: 0.6923 - val_loss: 1.3977 - val_accuracy: 0.3913\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.0540 - accuracy: 0.6923 - val_loss: 1.4225 - val_accuracy: 0.3913\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.0256 - accuracy: 0.7115 - val_loss: 1.7771 - val_accuracy: 0.3913\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.9977 - accuracy: 0.7115 - val_loss: 1.7712 - val_accuracy: 0.3913\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.9695 - accuracy: 0.7308 - val_loss: 1.7666 - val_accuracy: 0.3913\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.9401 - accuracy: 0.7308 - val_loss: 1.7652 - val_accuracy: 0.3913\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.9099 - accuracy: 0.7308 - val_loss: 1.7664 - val_accuracy: 0.3913\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7554 - accuracy: 0.7308 - val_loss: 1.8624 - val_accuracy: 0.3913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6709 - accuracy: 0.7500 - val_loss: 2.3068 - val_accuracy: 0.3913\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6583 - accuracy: 0.7692 - val_loss: 2.4908 - val_accuracy: 0.3913\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 0.6497 - accuracy: 0.8077 - val_loss: 2.8281 - val_accuracy: 0.3478\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6420 - accuracy: 0.8077 - val_loss: 3.2387 - val_accuracy: 0.3478\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6321 - accuracy: 0.8462 - val_loss: 3.3013 - val_accuracy: 0.3043\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6215 - accuracy: 0.8269 - val_loss: 3.7086 - val_accuracy: 0.3043\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.6087 - accuracy: 0.8269 - val_loss: 3.7345 - val_accuracy: 0.2609\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.5947 - accuracy: 0.8654 - val_loss: 3.7473 - val_accuracy: 0.3478\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.5782 - accuracy: 0.8462 - val_loss: 3.7580 - val_accuracy: 0.3478\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.5607 - accuracy: 0.8654 - val_loss: 3.8023 - val_accuracy: 0.3478\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.5409 - accuracy: 0.8654 - val_loss: 3.9768 - val_accuracy: 0.3478\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.5193 - accuracy: 0.8846 - val_loss: 4.4173 - val_accuracy: 0.3478\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.4950 - accuracy: 0.8462 - val_loss: 4.3471 - val_accuracy: 0.3043\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.4666 - accuracy: 0.8462 - val_loss: 4.0976 - val_accuracy: 0.3043\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.4310 - accuracy: 0.8846 - val_loss: 3.9011 - val_accuracy: 0.3043\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.3975 - accuracy: 0.8846 - val_loss: 3.8568 - val_accuracy: 0.3043\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.3578 - accuracy: 0.8846 - val_loss: 3.8411 - val_accuracy: 0.3043\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.3336 - accuracy: 0.8846 - val_loss: 4.3346 - val_accuracy: 0.2609\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.3177 - accuracy: 0.8846 - val_loss: 4.2978 - val_accuracy: 0.2609\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.3013 - accuracy: 0.8846 - val_loss: 4.3385 - val_accuracy: 0.2609\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.2855 - accuracy: 0.8846 - val_loss: 4.5384 - val_accuracy: 0.3043\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.2570 - accuracy: 0.8846 - val_loss: 4.3200 - val_accuracy: 0.3043\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.4116 - accuracy: 0.9038 - val_loss: 4.9286 - val_accuracy: 0.3043\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.2420 - accuracy: 0.9038 - val_loss: 5.1521 - val_accuracy: 0.3043\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.2179 - accuracy: 0.9038 - val_loss: 5.0771 - val_accuracy: 0.3043\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.2041 - accuracy: 0.9038 - val_loss: 4.8892 - val_accuracy: 0.2609\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1986 - accuracy: 0.8846 - val_loss: 5.0351 - val_accuracy: 0.2609\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.1966 - accuracy: 0.8846 - val_loss: 5.3155 - val_accuracy: 0.2609\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1952 - accuracy: 0.8846 - val_loss: 5.3833 - val_accuracy: 0.2609\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.1928 - accuracy: 0.8654 - val_loss: 5.1648 - val_accuracy: 0.2609\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.1853 - accuracy: 0.8846 - val_loss: 5.0696 - val_accuracy: 0.2609\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1766 - accuracy: 0.8846 - val_loss: 4.7685 - val_accuracy: 0.2609\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.1739 - accuracy: 0.9038 - val_loss: 4.6489 - val_accuracy: 0.2609\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1676 - accuracy: 0.9231 - val_loss: 4.5714 - val_accuracy: 0.2609\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1601 - accuracy: 0.9231 - val_loss: 4.4420 - val_accuracy: 0.2609\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1498 - accuracy: 0.9231 - val_loss: 4.2981 - val_accuracy: 0.2609\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.1439 - accuracy: 0.9231 - val_loss: 4.5066 - val_accuracy: 0.2609\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.2165 - accuracy: 0.9231 - val_loss: 4.5048 - val_accuracy: 0.2609\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.2050 - accuracy: 0.9231 - val_loss: 4.5100 - val_accuracy: 0.2609\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1983 - accuracy: 0.9231 - val_loss: 4.4265 - val_accuracy: 0.2609\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1888 - accuracy: 0.9231 - val_loss: 4.4279 - val_accuracy: 0.2609\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.1885 - accuracy: 0.9231 - val_loss: 4.6498 - val_accuracy: 0.2609\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1849 - accuracy: 0.9423 - val_loss: 4.6452 - val_accuracy: 0.2609\n"
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = X.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[0], activation='relu'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "history = model.fit(X, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin = X_train_clean_vectorized_bin.toarray().reshape(X_train_clean_vectorized_bin.shape[0],1,\n",
    "                                                X_train_clean_vectorized_bin.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 4.3150 - accuracy: 0.0192 - val_loss: 4.3129 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 4.2893 - accuracy: 0.0192 - val_loss: 4.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.2679 - accuracy: 0.0192 - val_loss: 4.2869 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.2466 - accuracy: 0.0192 - val_loss: 4.2742 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 4.2238 - accuracy: 0.0769 - val_loss: 4.2625 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 4.2027 - accuracy: 0.0769 - val_loss: 4.2499 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.1800 - accuracy: 0.0962 - val_loss: 4.2373 - val_accuracy: 0.0435\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 4.1565 - accuracy: 0.1154 - val_loss: 4.2239 - val_accuracy: 0.1304\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 4.1313 - accuracy: 0.1154 - val_loss: 4.2097 - val_accuracy: 0.1739\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.1040 - accuracy: 0.1538 - val_loss: 4.1944 - val_accuracy: 0.1739\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 4.0751 - accuracy: 0.1538 - val_loss: 4.1773 - val_accuracy: 0.1739\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.0442 - accuracy: 0.1731 - val_loss: 4.1586 - val_accuracy: 0.2174\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.0113 - accuracy: 0.1923 - val_loss: 4.1388 - val_accuracy: 0.2174\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.9765 - accuracy: 0.1923 - val_loss: 4.1170 - val_accuracy: 0.2174\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.9402 - accuracy: 0.2308 - val_loss: 4.0927 - val_accuracy: 0.1739\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.9015 - accuracy: 0.2500 - val_loss: 4.0664 - val_accuracy: 0.1739\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.8604 - accuracy: 0.2692 - val_loss: 4.0389 - val_accuracy: 0.1739\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.8156 - accuracy: 0.2885 - val_loss: 4.0089 - val_accuracy: 0.1739\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.7689 - accuracy: 0.3077 - val_loss: 3.9753 - val_accuracy: 0.1304\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 3.7196 - accuracy: 0.3077 - val_loss: 3.9384 - val_accuracy: 0.1739\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.6679 - accuracy: 0.3269 - val_loss: 3.8995 - val_accuracy: 0.1739\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.6152 - accuracy: 0.3269 - val_loss: 3.8584 - val_accuracy: 0.2174\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.5613 - accuracy: 0.3269 - val_loss: 3.8152 - val_accuracy: 0.2174\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.5057 - accuracy: 0.3462 - val_loss: 3.7694 - val_accuracy: 0.2174\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.4484 - accuracy: 0.3654 - val_loss: 3.7216 - val_accuracy: 0.1739\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.3897 - accuracy: 0.3654 - val_loss: 3.6732 - val_accuracy: 0.2174\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.3312 - accuracy: 0.3846 - val_loss: 3.6226 - val_accuracy: 0.2174\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.2722 - accuracy: 0.3846 - val_loss: 3.5699 - val_accuracy: 0.2174\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.2135 - accuracy: 0.3846 - val_loss: 3.5160 - val_accuracy: 0.2174\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.1553 - accuracy: 0.3846 - val_loss: 3.4598 - val_accuracy: 0.2174\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.0966 - accuracy: 0.3846 - val_loss: 3.4029 - val_accuracy: 0.2174\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.0388 - accuracy: 0.3846 - val_loss: 3.3438 - val_accuracy: 0.2174\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.9803 - accuracy: 0.4038 - val_loss: 3.2842 - val_accuracy: 0.2174\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 2.9219 - accuracy: 0.4231 - val_loss: 3.2235 - val_accuracy: 0.2174\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.8635 - accuracy: 0.4231 - val_loss: 3.1617 - val_accuracy: 0.2174\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.8052 - accuracy: 0.4231 - val_loss: 3.0992 - val_accuracy: 0.2174\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 2.7469 - accuracy: 0.4423 - val_loss: 3.0364 - val_accuracy: 0.3043\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.6882 - accuracy: 0.4615 - val_loss: 2.9736 - val_accuracy: 0.3478\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.6296 - accuracy: 0.5000 - val_loss: 2.9106 - val_accuracy: 0.3478\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 2.5707 - accuracy: 0.5192 - val_loss: 2.8481 - val_accuracy: 0.3478\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 2.5127 - accuracy: 0.5577 - val_loss: 2.7866 - val_accuracy: 0.3043\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.4554 - accuracy: 0.5769 - val_loss: 2.7253 - val_accuracy: 0.2609\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 2.3988 - accuracy: 0.5962 - val_loss: 2.6646 - val_accuracy: 0.3043\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.3427 - accuracy: 0.5962 - val_loss: 2.6055 - val_accuracy: 0.3043\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.2878 - accuracy: 0.6154 - val_loss: 2.5476 - val_accuracy: 0.3043\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 2.2341 - accuracy: 0.6346 - val_loss: 2.4911 - val_accuracy: 0.3043\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.1814 - accuracy: 0.6538 - val_loss: 2.4352 - val_accuracy: 0.3913\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 2.1299 - accuracy: 0.6731 - val_loss: 2.3794 - val_accuracy: 0.3913\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 2.0786 - accuracy: 0.6923 - val_loss: 2.3237 - val_accuracy: 0.3913\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.0276 - accuracy: 0.7308 - val_loss: 2.2686 - val_accuracy: 0.4348\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 307us/step - loss: 1.9775 - accuracy: 0.7692 - val_loss: 2.2135 - val_accuracy: 0.3913\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.9273 - accuracy: 0.8077 - val_loss: 2.1592 - val_accuracy: 0.3913\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.8779 - accuracy: 0.8462 - val_loss: 2.1064 - val_accuracy: 0.4348\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.8300 - accuracy: 0.8269 - val_loss: 2.0541 - val_accuracy: 0.4348\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.7827 - accuracy: 0.8077 - val_loss: 2.0032 - val_accuracy: 0.4348\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.7364 - accuracy: 0.8077 - val_loss: 1.9543 - val_accuracy: 0.4348\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.6913 - accuracy: 0.8077 - val_loss: 1.9073 - val_accuracy: 0.4348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.6465 - accuracy: 0.8269 - val_loss: 1.8625 - val_accuracy: 0.4348\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.6027 - accuracy: 0.8269 - val_loss: 1.8203 - val_accuracy: 0.4348\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.5598 - accuracy: 0.8269 - val_loss: 1.7811 - val_accuracy: 0.4783\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.5179 - accuracy: 0.8462 - val_loss: 1.7448 - val_accuracy: 0.4783\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.4769 - accuracy: 0.8846 - val_loss: 1.7114 - val_accuracy: 0.5217\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.4369 - accuracy: 0.9038 - val_loss: 1.6812 - val_accuracy: 0.5217\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3980 - accuracy: 0.9038 - val_loss: 1.6539 - val_accuracy: 0.5217\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.3602 - accuracy: 0.8846 - val_loss: 1.6295 - val_accuracy: 0.5217\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.3238 - accuracy: 0.8846 - val_loss: 1.6075 - val_accuracy: 0.5217\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.2883 - accuracy: 0.9038 - val_loss: 1.5879 - val_accuracy: 0.5652\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.2541 - accuracy: 0.9231 - val_loss: 1.5702 - val_accuracy: 0.5217\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.2214 - accuracy: 0.9231 - val_loss: 1.5537 - val_accuracy: 0.5217\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 270us/step - loss: 1.1900 - accuracy: 0.9231 - val_loss: 1.5380 - val_accuracy: 0.5217\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.1598 - accuracy: 0.9038 - val_loss: 1.5229 - val_accuracy: 0.5217\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 1.1310 - accuracy: 0.9038 - val_loss: 1.5078 - val_accuracy: 0.5217\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.1032 - accuracy: 0.8846 - val_loss: 1.4925 - val_accuracy: 0.5217\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.0766 - accuracy: 0.8846 - val_loss: 1.4770 - val_accuracy: 0.5217\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.0508 - accuracy: 0.9038 - val_loss: 1.4609 - val_accuracy: 0.5217\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.0258 - accuracy: 0.9038 - val_loss: 1.4441 - val_accuracy: 0.4783\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 1.0017 - accuracy: 0.9038 - val_loss: 1.4268 - val_accuracy: 0.4783\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.9786 - accuracy: 0.9038 - val_loss: 1.4090 - val_accuracy: 0.4783\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.9568 - accuracy: 0.9038 - val_loss: 1.3914 - val_accuracy: 0.4783\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.9358 - accuracy: 0.9038 - val_loss: 1.3749 - val_accuracy: 0.5217\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.9155 - accuracy: 0.9038 - val_loss: 1.3594 - val_accuracy: 0.4783\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.8964 - accuracy: 0.9231 - val_loss: 1.3444 - val_accuracy: 0.4783\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.8779 - accuracy: 0.9231 - val_loss: 1.3307 - val_accuracy: 0.4783\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8600 - accuracy: 0.9231 - val_loss: 1.3184 - val_accuracy: 0.4783\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8429 - accuracy: 0.9231 - val_loss: 1.3077 - val_accuracy: 0.4783\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8263 - accuracy: 0.9231 - val_loss: 1.2985 - val_accuracy: 0.4783\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.8101 - accuracy: 0.9231 - val_loss: 1.2904 - val_accuracy: 0.4783\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7941 - accuracy: 0.9231 - val_loss: 1.2831 - val_accuracy: 0.4783\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7787 - accuracy: 0.9231 - val_loss: 1.2759 - val_accuracy: 0.4783\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7638 - accuracy: 0.9231 - val_loss: 1.2685 - val_accuracy: 0.4783\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7491 - accuracy: 0.9231 - val_loss: 1.2605 - val_accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7348 - accuracy: 0.9231 - val_loss: 1.2519 - val_accuracy: 0.4783\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7209 - accuracy: 0.9231 - val_loss: 1.2421 - val_accuracy: 0.5217\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7073 - accuracy: 0.9231 - val_loss: 1.2323 - val_accuracy: 0.5217\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6941 - accuracy: 0.9423 - val_loss: 1.2225 - val_accuracy: 0.5217\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 251us/step - loss: 0.6809 - accuracy: 0.9423 - val_loss: 1.2128 - val_accuracy: 0.5217\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.6679 - accuracy: 0.9231 - val_loss: 1.2031 - val_accuracy: 0.5217\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6552 - accuracy: 0.9231 - val_loss: 1.1933 - val_accuracy: 0.5217\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6428 - accuracy: 0.9231 - val_loss: 1.1835 - val_accuracy: 0.5217\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6306 - accuracy: 0.9231 - val_loss: 1.1737 - val_accuracy: 0.5217\n"
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = X_bin.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[0], activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "history = model.fit(X_bin, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count = X_train_clean_vectorized_count.toarray().reshape(X_train_clean_vectorized_count.shape[0],1,\n",
    "                                                X_train_clean_vectorized_count.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 8.4548 - accuracy: 0.0192 - val_loss: 7.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 8.1950 - accuracy: 0.0769 - val_loss: 7.4636 - val_accuracy: 0.0435\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 7.8272 - accuracy: 0.1154 - val_loss: 7.2732 - val_accuracy: 0.0435\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 7.6161 - accuracy: 0.1346 - val_loss: 7.1033 - val_accuracy: 0.0870\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 7.2395 - accuracy: 0.1731 - val_loss: 6.9430 - val_accuracy: 0.2174\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 7.0500 - accuracy: 0.2308 - val_loss: 6.7871 - val_accuracy: 0.2609\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 6.6350 - accuracy: 0.3269 - val_loss: 6.6355 - val_accuracy: 0.3913\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 6.0778 - accuracy: 0.3654 - val_loss: 6.5001 - val_accuracy: 0.4348\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 5.6491 - accuracy: 0.4038 - val_loss: 6.3599 - val_accuracy: 0.4783\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 366us/step - loss: 5.0607 - accuracy: 0.4808 - val_loss: 6.2242 - val_accuracy: 0.4783\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.6984 - accuracy: 0.5000 - val_loss: 6.0932 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 4.2066 - accuracy: 0.5192 - val_loss: 5.9825 - val_accuracy: 0.5652\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.0075 - accuracy: 0.5000 - val_loss: 5.8788 - val_accuracy: 0.6087\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.8924 - accuracy: 0.5192 - val_loss: 5.7770 - val_accuracy: 0.6087\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.7896 - accuracy: 0.6154 - val_loss: 5.6844 - val_accuracy: 0.6087\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 384us/step - loss: 3.5455 - accuracy: 0.6154 - val_loss: 5.6039 - val_accuracy: 0.6087\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.4196 - accuracy: 0.5769 - val_loss: 5.1343 - val_accuracy: 0.6087\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 3.3496 - accuracy: 0.6346 - val_loss: 5.0393 - val_accuracy: 0.6087\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.8756 - accuracy: 0.6346 - val_loss: 4.6615 - val_accuracy: 0.5217\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.7958 - accuracy: 0.6154 - val_loss: 4.4969 - val_accuracy: 0.4783\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.7412 - accuracy: 0.6154 - val_loss: 4.4211 - val_accuracy: 0.4783\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.5125 - accuracy: 0.5962 - val_loss: 4.3565 - val_accuracy: 0.4783\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 289us/step - loss: 2.4358 - accuracy: 0.5962 - val_loss: 3.8949 - val_accuracy: 0.4783\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.3834 - accuracy: 0.5962 - val_loss: 3.4002 - val_accuracy: 0.4783\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.3343 - accuracy: 0.5769 - val_loss: 2.8833 - val_accuracy: 0.4783\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.0697 - accuracy: 0.5577 - val_loss: 2.7624 - val_accuracy: 0.4783\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.0110 - accuracy: 0.5769 - val_loss: 2.6812 - val_accuracy: 0.4783\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.7996 - accuracy: 0.5962 - val_loss: 2.6280 - val_accuracy: 0.4783\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.6903 - accuracy: 0.6154 - val_loss: 2.5925 - val_accuracy: 0.4783\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4751 - accuracy: 0.5962 - val_loss: 2.5578 - val_accuracy: 0.4783\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1975 - accuracy: 0.6154 - val_loss: 2.5334 - val_accuracy: 0.4783\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.1606 - accuracy: 0.6538 - val_loss: 2.5111 - val_accuracy: 0.4783\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.1249 - accuracy: 0.6538 - val_loss: 2.4763 - val_accuracy: 0.4783\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.2938 - accuracy: 0.7115 - val_loss: 2.4450 - val_accuracy: 0.4783\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.2636 - accuracy: 0.7115 - val_loss: 2.4156 - val_accuracy: 0.4783\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.2247 - accuracy: 0.7308 - val_loss: 2.3854 - val_accuracy: 0.4783\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1841 - accuracy: 0.7692 - val_loss: 2.3651 - val_accuracy: 0.4783\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 1.1480 - accuracy: 0.7115 - val_loss: 2.3487 - val_accuracy: 0.4783\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.1149 - accuracy: 0.7115 - val_loss: 2.1276 - val_accuracy: 0.4783\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.0828 - accuracy: 0.7115 - val_loss: 1.9157 - val_accuracy: 0.4783\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.0529 - accuracy: 0.7308 - val_loss: 1.9032 - val_accuracy: 0.4783\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.0173 - accuracy: 0.7500 - val_loss: 1.8940 - val_accuracy: 0.5217\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 270us/step - loss: 0.9922 - accuracy: 0.7500 - val_loss: 1.9002 - val_accuracy: 0.5217\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.9651 - accuracy: 0.7692 - val_loss: 1.9159 - val_accuracy: 0.5217\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.9309 - accuracy: 0.8077 - val_loss: 1.9261 - val_accuracy: 0.4783\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.8983 - accuracy: 0.8077 - val_loss: 1.9774 - val_accuracy: 0.4783\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.8639 - accuracy: 0.8269 - val_loss: 2.4178 - val_accuracy: 0.4783\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.8343 - accuracy: 0.8269 - val_loss: 3.1288 - val_accuracy: 0.4783\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8035 - accuracy: 0.8077 - val_loss: 3.1182 - val_accuracy: 0.4783\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.7760 - accuracy: 0.8269 - val_loss: 3.1133 - val_accuracy: 0.4783\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7514 - accuracy: 0.8269 - val_loss: 3.1133 - val_accuracy: 0.4783\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7246 - accuracy: 0.8269 - val_loss: 3.1210 - val_accuracy: 0.4783\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6931 - accuracy: 0.8269 - val_loss: 3.1434 - val_accuracy: 0.4783\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6672 - accuracy: 0.8269 - val_loss: 3.2257 - val_accuracy: 0.4783\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.6586 - accuracy: 0.8269 - val_loss: 3.5679 - val_accuracy: 0.4783\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6377 - accuracy: 0.8462 - val_loss: 3.9475 - val_accuracy: 0.4783\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.6272 - accuracy: 0.8462 - val_loss: 3.9345 - val_accuracy: 0.4783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6238 - accuracy: 0.8462 - val_loss: 3.9371 - val_accuracy: 0.4783\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6100 - accuracy: 0.8462 - val_loss: 3.9456 - val_accuracy: 0.4783\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.5928 - accuracy: 0.8462 - val_loss: 3.9957 - val_accuracy: 0.4783\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7873 - accuracy: 0.8269 - val_loss: 4.3636 - val_accuracy: 0.4348\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 0.5835 - accuracy: 0.8269 - val_loss: 4.3387 - val_accuracy: 0.4348\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.5721 - accuracy: 0.8462 - val_loss: 4.3232 - val_accuracy: 0.4348\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6648 - accuracy: 0.8269 - val_loss: 4.3260 - val_accuracy: 0.4348\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6775 - accuracy: 0.8462 - val_loss: 4.4152 - val_accuracy: 0.4348\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.6817 - accuracy: 0.8654 - val_loss: 4.6517 - val_accuracy: 0.4348\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7615 - accuracy: 0.8462 - val_loss: 4.6246 - val_accuracy: 0.4348\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7597 - accuracy: 0.8462 - val_loss: 4.5917 - val_accuracy: 0.4348\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7502 - accuracy: 0.8462 - val_loss: 4.5582 - val_accuracy: 0.4348\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7409 - accuracy: 0.8462 - val_loss: 4.5120 - val_accuracy: 0.4348\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7308 - accuracy: 0.8462 - val_loss: 4.7537 - val_accuracy: 0.4348\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7208 - accuracy: 0.8462 - val_loss: 4.7249 - val_accuracy: 0.4348\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7113 - accuracy: 0.8462 - val_loss: 4.6707 - val_accuracy: 0.4348\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7024 - accuracy: 0.8462 - val_loss: 4.5297 - val_accuracy: 0.4348\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.6929 - accuracy: 0.8462 - val_loss: 4.5269 - val_accuracy: 0.4348\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6803 - accuracy: 0.8462 - val_loss: 4.5278 - val_accuracy: 0.4348\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6688 - accuracy: 0.8462 - val_loss: 4.5285 - val_accuracy: 0.4348\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6588 - accuracy: 0.8462 - val_loss: 4.5295 - val_accuracy: 0.4348\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.6468 - accuracy: 0.8654 - val_loss: 4.5317 - val_accuracy: 0.4348\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.6352 - accuracy: 0.8654 - val_loss: 4.5409 - val_accuracy: 0.4348\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6227 - accuracy: 0.8654 - val_loss: 4.5795 - val_accuracy: 0.4348\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6142 - accuracy: 0.8846 - val_loss: 4.8987 - val_accuracy: 0.4348\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.5988 - accuracy: 0.8846 - val_loss: 5.0719 - val_accuracy: 0.3913\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.5876 - accuracy: 0.8846 - val_loss: 5.0577 - val_accuracy: 0.3913\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.5782 - accuracy: 0.9038 - val_loss: 5.0369 - val_accuracy: 0.3913\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6483 - accuracy: 0.8846 - val_loss: 5.0151 - val_accuracy: 0.3913\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.6388 - accuracy: 0.8846 - val_loss: 4.9964 - val_accuracy: 0.3913\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6288 - accuracy: 0.8846 - val_loss: 4.9795 - val_accuracy: 0.3913\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6181 - accuracy: 0.8846 - val_loss: 4.9622 - val_accuracy: 0.3913\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6122 - accuracy: 0.8846 - val_loss: 4.9447 - val_accuracy: 0.3913\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6087 - accuracy: 0.8846 - val_loss: 4.9294 - val_accuracy: 0.3913\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6049 - accuracy: 0.8654 - val_loss: 4.9142 - val_accuracy: 0.3913\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.8913 - accuracy: 0.8462 - val_loss: 4.8903 - val_accuracy: 0.3913\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7567 - accuracy: 0.8269 - val_loss: 4.8653 - val_accuracy: 0.3913\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.8584 - accuracy: 0.7885 - val_loss: 4.8187 - val_accuracy: 0.4348\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.7601 - accuracy: 0.8269 - val_loss: 4.7600 - val_accuracy: 0.4348\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7601 - accuracy: 0.8269 - val_loss: 4.6813 - val_accuracy: 0.4348\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.8471 - accuracy: 0.8462 - val_loss: 4.5601 - val_accuracy: 0.4348\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7523 - accuracy: 0.8462 - val_loss: 4.5396 - val_accuracy: 0.4348\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6611 - accuracy: 0.8654 - val_loss: 4.5138 - val_accuracy: 0.4348\n"
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = X_count.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[0], activation='relu'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "history = model.fit(X_count, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle vectoriel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du vectoriseur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On passe au vectoriseur use_idf=False pour qu'il soit binaire (0 = absence du terme, 1 = présence du terme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words=None,\n",
    "                            ngram_range=(1, 1),\n",
    "                            use_idf=False, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la matrice termes-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = vectorizer.fit_transform(df['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interrogation du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons trouver le document du corpus qui est le plus similaire à cette requête:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('french')\n",
    "sw.append('les') # manque dans la liste, par exemple\n",
    "vect = vectorizer = TfidfVectorizer(lowercase=True, stop_words=None,\n",
    "                            ngram_range=(1, 1),\n",
    "                            use_idf=False, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')\n",
    "dtm = vect.fit_transform(df)\n",
    "\n",
    "def vectorize_query(query_text):\n",
    "    query_file = 'query.txt'\n",
    "    with open(query_file, 'w', encoding=\"utf-8\") as out_f:\n",
    "        out_f.write(query_text)\n",
    "    query_vector = vect.transform([query_file])\n",
    "    os.unlink(query_file)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les salutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction sera utilisé pour le message d'acceuil entré par l'utilisateur et la génération de la réponse correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour les salutations de départ\n",
    "\n",
    "salutations_inputs = (\"salut\", \"hey\", \"coucou\", \"bonjour\")\n",
    "salutations_responses = [\"bonjour et bienvenu.e\", \"bonjour\", \"bienvenu.e\"]\n",
    "\n",
    "def generate_greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une fonction qui prend en entrée l'utilisateur, trouve la similitude en cosinus de \n",
    "l'entrée utilisateur et la compare avec les phrases du corpus.\n",
    "\n",
    "Source : https://stackabuse.com/python-for-nlp-creating-a-rule-based-chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "sw = stopwords.words('french')\n",
    "sw.append('les') # manque dans la liste, par exemple\n",
    "vect = vectorizer = TfidfVectorizer(lowercase=True, stop_words=sw,\n",
    "                            ngram_range=(1, 1),\n",
    "                            use_idf=False, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')\n",
    "dtm = vect.fit_transform(df)\n",
    "\n",
    "#Vectorisation de l'input utilisateur\n",
    "def vectorize_query(query_text):\n",
    "    query_file = 'query.txt'\n",
    "    with open(query_file, 'w', encoding=\"utf-8\") as out_f:\n",
    "        out_f.write(query_text) #ecrire l'input utilisateur dans un fichier texte\n",
    "    query_vector = vect.transform([query_file])\n",
    "    os.unlink(query_file)\n",
    "    return query_vector\n",
    "\n",
    "query = [\"test.txt\"]\n",
    "query_vector = vect.transform(query)\n",
    "#query_vector = vectorize_query(query)\n",
    "query_corpus_sim = np.squeeze(cosine_similarity(dtm, query_vector))\n",
    "idx_most_sim = np.argmax(query_corpus_sim)\n",
    "df[idx_most_sim]\n",
    "print(df[idx_most_sim])\n",
    "\n",
    "def get_best_doc(query_text):\n",
    "    query_vector = vectorize_query(query_text)\n",
    "    query_corpus_sim = np.squeeze(cosine_similarity(dtm, query_vector))\n",
    "    doc_id = np.argmax(query_corpus_sim)\n",
    "    doc_path = df[doc_id] # contient le répertoire parent\n",
    "    return doc_path\n",
    "\n",
    "def print_result(query_text):\n",
    "    doc_path = get_best_doc(query_text)\n",
    "    doc_filename = os.path.split(doc_path)[-1] # sans le répertoire parent\n",
    "    print(doc_filename) # affiche le nom du fichier\n",
    "    print('-' * 20)     # affiche une ligne de '-'\n",
    "    with open(doc_path, 'r') as in_f:\n",
    "        print(in_f.read(500) + '...') # affiche les premiers 500 caractères du doc\n",
    "\n",
    "query = 'politique'\n",
    "print_result(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
