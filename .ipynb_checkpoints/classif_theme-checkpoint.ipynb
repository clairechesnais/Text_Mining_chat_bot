{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de la question en thématiques métier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pré-traitement textuel de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Préparation du fichier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous importons la base créée après le scraping (fichier `scraping.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reponse</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>Il est possible d’arriver n’importe quel jour ...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>Le classement par « birdies » évalue l’offre C...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>En réservant votre hébergement, vous bénéficie...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>Lors de la réservation de votre hébergement, v...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>Sur la page d'accueil de notre site, cliquez s...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   Quels sont les jours d’arrivée ?   \n",
       "1  Comment évaluer le confort de mon domaine et d...   \n",
       "2  Quels sont les services et activités compris d...   \n",
       "3                   Comment réserver mes activités ?   \n",
       "4                    Où trouver le plan du domaine ?   \n",
       "\n",
       "                                             reponse                theme  \n",
       "0  Il est possible d’arriver n’importe quel jour ...  Préparer mon séjour  \n",
       "1  Le classement par « birdies » évalue l’offre C...  Préparer mon séjour  \n",
       "2  En réservant votre hébergement, vous bénéficie...  Préparer mon séjour  \n",
       "3  Lors de la réservation de votre hébergement, v...  Préparer mon séjour  \n",
       "4  Sur la page d'accueil de notre site, cliquez s...  Préparer mon séjour  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq = pd.read_pickle('faq_centerPark.pkl')\n",
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données est composé de :\n",
    "    - 54 lignes\n",
    "    - 3 colonnes\n",
    "    - 5 thèmes différents\n",
    "On pose :\n",
    "    - 1 = Préparer mon séjour\n",
    "    - 2 = Réserver et payer\n",
    "    - 3 = Gérer ma réservation\n",
    "    - 4 = Mon séjour\n",
    "    - 5 = Assurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_code_theme = {\"Préparer mon séjour\": 1,\n",
    "                  \"Réserver et payer\": 2,\n",
    "                  \"Gérer ma réservation\": 3,\n",
    "                  \"Mon séjour\": 4,\n",
    "                  \"Assurances\": 5}\n",
    "dic_decode_theme = {val: key for key, val in dic_code_theme.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faq[\"theme\"].replace(dic_code_theme, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons transposer le DataFrame de manière à ce que les questions et les réponses se retrouvent dans la même colonne, tout en restant associées à leur thème d'appartenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = df_faq[['question', 'theme']].copy()\n",
    "df_question.rename(columns={'question': 'texte', 'theme': 'theme'}, inplace=True)\n",
    "df_reponse = df_faq[['reponse', 'theme']].copy()\n",
    "df_reponse.rename(columns={'reponse': 'texte', 'theme': 'theme'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_theme = pd.concat([df_question, df_reponse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sauvegardons le DataFrame `df_theme`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_theme.to_pickle('df_classif_theme.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Nettoyage du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons procéder à un nettoyage du tableau de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# pour le nettoyage du texte\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#pour la classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous séparons le tableau `df_theme` en un jeu d'apprentissage et un jeu de test. Nous conservons 70% des données dans le jeu d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_theme = pd.read_pickle('df_classif_theme.pkl')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_theme['texte'], \n",
    "                                                    df_theme['theme'],\n",
    "                                                    train_size=0.7,\n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous définissons un certain nombre de fonctions qui nous permettrons de nettoyer le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('french')\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']\n",
    "sw.sort()\n",
    "\n",
    "def lemmatise_text(text):\n",
    "    lst_lematised = [token.lemma_ for token in nlp(text)]\n",
    "    return ' '.join(lst_lematised).lower()\n",
    "\n",
    "\n",
    "def stem_text(text):\n",
    "    lst_stemmerised = [stemmer.stem(token) for token in word_tokenize(text)]\n",
    "    return ' '.join(lst_stemmerised)\n",
    "\n",
    "\n",
    "def substitute_punctuation(text):\n",
    "    return ' '.join(text.replace(\"'\", ' ').translate(str.maketrans('', '', string.punctuation)).split())\n",
    "\n",
    "\n",
    "def substitute_special_char(text):\n",
    "    return text.replace(\"«\", \"\").replace(\"’\", \"\").replace(\"•\", \"\").replace(\"®\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = (X_train.apply(lemmatise_text)\n",
    "                        .apply(stem_text)\n",
    "                        .apply(substitute_punctuation)\n",
    "                        .apply(substitute_special_char)\n",
    "                )\n",
    "\n",
    "X_test_clean = (X_test.apply(lemmatise_text)\n",
    "                      .apply(stem_text)\n",
    "                      .apply(substitute_punctuation)\n",
    "                      .apply(substitute_special_char)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test de différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant procéder aux tests de différents classifieurs. Pour ce faire, nous allons définir plusieurs vectoriseurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Les différents vectoriseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectoriseur binaire\n",
    "\n",
    "bin_count = CountVectorizer(binary=True)\n",
    "bin_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_bin = bin_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_bin = bin_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriseur numérique discret\n",
    "\n",
    "vect_count = CountVectorizer(binary=False)\n",
    "vect_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_count = vect_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_count = vect_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#vectoriseur numérique continu : TF-IDF\n",
    "\n",
    "vect_tfidf = TfidfVectorizer(stop_words=sw)\n",
    "vect_tfidf.fit(X_train_clean)\n",
    "X_train_clean_vectorized_tfidf = vect_tfidf.transform(X_train_clean)\n",
    "X_test_clean_vectorized_tfidf = vect_tfidf.transform(X_test_clean) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Les différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous entraînerons des modèles de classification appartenant à quelques familles d'algorithmes d'apprentissage automatique classique. L'objectif est de comparer non seulement les performances des différentes méthodes entre elles, mais aussi la performance d'une même méthode sur des représentations différentes du texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1 DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15151515151515152"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12121212121212122"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.2 Classifieur naïf bayesien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060606060606061"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.3 Complement NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060606060606061"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.4 BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.5 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30303030303030304"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.7 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3939393939393939"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3939393939393939"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.8 Réseaux de neurones de convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, SpatialDropout1D, MaxPooling1D, Conv1D, Flatten, MaxPooling2D, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train = X_train_clean_vectorized_tfidf.toarray().reshape(X_train_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_train_clean_vectorized_tfidf.shape[1])\n",
    "XX_test = X_test_clean_vectorized_tfidf.toarray().reshape(X_test_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_test_clean_vectorized_tfidf.shape[1])\n",
    "YY_train = pd.get_dummies(y_train)\n",
    "YY_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 30 samples\n",
      "Epoch 1/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.6041 - accuracy: 0.18 - 0s 8ms/step - loss: 1.5982 - accuracy: 0.2444 - val_loss: 1.5939 - val_accuracy: 0.2667\n",
      "Epoch 2/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5916 - accuracy: 0.28 - 0s 467us/step - loss: 1.5888 - accuracy: 0.2667 - val_loss: 1.5904 - val_accuracy: 0.2333\n",
      "Epoch 3/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5857 - accuracy: 0.25 - 0s 444us/step - loss: 1.5810 - accuracy: 0.2889 - val_loss: 1.5864 - val_accuracy: 0.2333\n",
      "Epoch 4/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5715 - accuracy: 0.28 - 0s 400us/step - loss: 1.5737 - accuracy: 0.2889 - val_loss: 1.5821 - val_accuracy: 0.2333\n",
      "Epoch 5/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5559 - accuracy: 0.37 - 0s 467us/step - loss: 1.5661 - accuracy: 0.3111 - val_loss: 1.5777 - val_accuracy: 0.2667\n",
      "Epoch 6/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5694 - accuracy: 0.28 - 0s 422us/step - loss: 1.5571 - accuracy: 0.3111 - val_loss: 1.5732 - val_accuracy: 0.2667\n",
      "Epoch 7/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5503 - accuracy: 0.28 - 0s 533us/step - loss: 1.5495 - accuracy: 0.3111 - val_loss: 1.5680 - val_accuracy: 0.2667\n",
      "Epoch 8/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5413 - accuracy: 0.28 - 0s 422us/step - loss: 1.5409 - accuracy: 0.3333 - val_loss: 1.5626 - val_accuracy: 0.2667\n",
      "Epoch 9/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5498 - accuracy: 0.25 - 0s 711us/step - loss: 1.5315 - accuracy: 0.3333 - val_loss: 1.5572 - val_accuracy: 0.2667\n",
      "Epoch 10/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5192 - accuracy: 0.37 - 0s 400us/step - loss: 1.5227 - accuracy: 0.3333 - val_loss: 1.5515 - val_accuracy: 0.2667\n",
      "Epoch 11/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5297 - accuracy: 0.28 - 0s 378us/step - loss: 1.5122 - accuracy: 0.3333 - val_loss: 1.5458 - val_accuracy: 0.2667\n",
      "Epoch 12/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5092 - accuracy: 0.34 - 0s 378us/step - loss: 1.5017 - accuracy: 0.3333 - val_loss: 1.5396 - val_accuracy: 0.3000\n",
      "Epoch 13/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4953 - accuracy: 0.31 - 0s 422us/step - loss: 1.4903 - accuracy: 0.3556 - val_loss: 1.5332 - val_accuracy: 0.3667\n",
      "Epoch 14/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4754 - accuracy: 0.37 - 0s 422us/step - loss: 1.4786 - accuracy: 0.3556 - val_loss: 1.5265 - val_accuracy: 0.3667\n",
      "Epoch 15/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4559 - accuracy: 0.40 - 0s 378us/step - loss: 1.4662 - accuracy: 0.3556 - val_loss: 1.5198 - val_accuracy: 0.3333\n",
      "Epoch 16/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4644 - accuracy: 0.34 - 0s 444us/step - loss: 1.4525 - accuracy: 0.3556 - val_loss: 1.5127 - val_accuracy: 0.3000\n",
      "Epoch 17/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4285 - accuracy: 0.40 - 0s 555us/step - loss: 1.4394 - accuracy: 0.3556 - val_loss: 1.5054 - val_accuracy: 0.3333\n",
      "Epoch 18/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4229 - accuracy: 0.37 - 0s 356us/step - loss: 1.4247 - accuracy: 0.3556 - val_loss: 1.4976 - val_accuracy: 0.3333\n",
      "Epoch 19/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4275 - accuracy: 0.28 - 0s 378us/step - loss: 1.4093 - accuracy: 0.3556 - val_loss: 1.4892 - val_accuracy: 0.3333\n",
      "Epoch 20/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3679 - accuracy: 0.40 - 0s 378us/step - loss: 1.3944 - accuracy: 0.3778 - val_loss: 1.4806 - val_accuracy: 0.3333\n",
      "Epoch 21/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3729 - accuracy: 0.37 - 0s 555us/step - loss: 1.3771 - accuracy: 0.3778 - val_loss: 1.4718 - val_accuracy: 0.3333\n",
      "Epoch 22/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3294 - accuracy: 0.40 - 0s 422us/step - loss: 1.3606 - accuracy: 0.3778 - val_loss: 1.4629 - val_accuracy: 0.3333\n",
      "Epoch 23/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3717 - accuracy: 0.40 - 0s 356us/step - loss: 1.3418 - accuracy: 0.4000 - val_loss: 1.4539 - val_accuracy: 0.3333\n",
      "Epoch 24/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3589 - accuracy: 0.37 - 0s 378us/step - loss: 1.3232 - accuracy: 0.4222 - val_loss: 1.4446 - val_accuracy: 0.4000\n",
      "Epoch 25/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3008 - accuracy: 0.46 - 0s 511us/step - loss: 1.3048 - accuracy: 0.4667 - val_loss: 1.4345 - val_accuracy: 0.4000\n",
      "Epoch 26/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3247 - accuracy: 0.43 - 0s 378us/step - loss: 1.2840 - accuracy: 0.4667 - val_loss: 1.4242 - val_accuracy: 0.4000\n",
      "Epoch 27/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2650 - accuracy: 0.53 - 0s 400us/step - loss: 1.2641 - accuracy: 0.5111 - val_loss: 1.4137 - val_accuracy: 0.4000\n",
      "Epoch 28/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2331 - accuracy: 0.50 - 0s 355us/step - loss: 1.2431 - accuracy: 0.5111 - val_loss: 1.4026 - val_accuracy: 0.4333\n",
      "Epoch 29/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2201 - accuracy: 0.46 - 0s 444us/step - loss: 1.2212 - accuracy: 0.5111 - val_loss: 1.3916 - val_accuracy: 0.4333\n",
      "Epoch 30/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2254 - accuracy: 0.46 - 0s 378us/step - loss: 1.1993 - accuracy: 0.5333 - val_loss: 1.3810 - val_accuracy: 0.4333\n",
      "Epoch 31/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1595 - accuracy: 0.59 - 0s 355us/step - loss: 1.1778 - accuracy: 0.5778 - val_loss: 1.3709 - val_accuracy: 0.4000\n",
      "Epoch 32/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1666 - accuracy: 0.65 - 0s 356us/step - loss: 1.1548 - accuracy: 0.6444 - val_loss: 1.3611 - val_accuracy: 0.4333\n",
      "Epoch 33/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0465 - accuracy: 0.75 - 0s 489us/step - loss: 1.1337 - accuracy: 0.6667 - val_loss: 1.3521 - val_accuracy: 0.5000\n",
      "Epoch 34/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0731 - accuracy: 0.68 - 0s 444us/step - loss: 1.1105 - accuracy: 0.6667 - val_loss: 1.3435 - val_accuracy: 0.5000\n",
      "Epoch 35/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0698 - accuracy: 0.75 - 0s 378us/step - loss: 1.0880 - accuracy: 0.6889 - val_loss: 1.3349 - val_accuracy: 0.5000\n",
      "Epoch 36/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0131 - accuracy: 0.68 - 0s 378us/step - loss: 1.0654 - accuracy: 0.7111 - val_loss: 1.3264 - val_accuracy: 0.5000\n",
      "Epoch 37/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0052 - accuracy: 0.78 - 0s 378us/step - loss: 1.0424 - accuracy: 0.7333 - val_loss: 1.3180 - val_accuracy: 0.5000\n",
      "Epoch 38/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9544 - accuracy: 0.75 - 0s 378us/step - loss: 1.0200 - accuracy: 0.7333 - val_loss: 1.3090 - val_accuracy: 0.5000\n",
      "Epoch 39/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0544 - accuracy: 0.71 - 0s 400us/step - loss: 0.9972 - accuracy: 0.7333 - val_loss: 1.2993 - val_accuracy: 0.5000\n",
      "Epoch 40/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9514 - accuracy: 0.75 - 0s 356us/step - loss: 0.9749 - accuracy: 0.7333 - val_loss: 1.2893 - val_accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9280 - accuracy: 0.75 - 0s 355us/step - loss: 0.9530 - accuracy: 0.7333 - val_loss: 1.2793 - val_accuracy: 0.4667\n",
      "Epoch 42/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8979 - accuracy: 0.75 - 0s 489us/step - loss: 0.9296 - accuracy: 0.7333 - val_loss: 1.2703 - val_accuracy: 0.4667\n",
      "Epoch 43/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9163 - accuracy: 0.78 - 0s 489us/step - loss: 0.9079 - accuracy: 0.7556 - val_loss: 1.2610 - val_accuracy: 0.4667\n",
      "Epoch 44/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8832 - accuracy: 0.75 - 0s 400us/step - loss: 0.8855 - accuracy: 0.7556 - val_loss: 1.2514 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8718 - accuracy: 0.68 - 0s 378us/step - loss: 0.8633 - accuracy: 0.7556 - val_loss: 1.2418 - val_accuracy: 0.4667\n",
      "Epoch 46/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8370 - accuracy: 0.75 - 0s 378us/step - loss: 0.8414 - accuracy: 0.7778 - val_loss: 1.2328 - val_accuracy: 0.5000\n",
      "Epoch 47/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8407 - accuracy: 0.81 - 0s 556us/step - loss: 0.8192 - accuracy: 0.8444 - val_loss: 1.2248 - val_accuracy: 0.5000\n",
      "Epoch 48/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8429 - accuracy: 0.81 - 0s 422us/step - loss: 0.7982 - accuracy: 0.8444 - val_loss: 1.2168 - val_accuracy: 0.5000\n",
      "Epoch 49/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7468 - accuracy: 0.90 - 0s 422us/step - loss: 0.7774 - accuracy: 0.8667 - val_loss: 1.2081 - val_accuracy: 0.5000\n",
      "Epoch 50/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7565 - accuracy: 0.87 - 0s 400us/step - loss: 0.7572 - accuracy: 0.8667 - val_loss: 1.2000 - val_accuracy: 0.5000\n",
      "Epoch 51/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7415 - accuracy: 0.84 - 0s 378us/step - loss: 0.7363 - accuracy: 0.8667 - val_loss: 1.1931 - val_accuracy: 0.5000\n",
      "Epoch 52/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7877 - accuracy: 0.84 - 0s 378us/step - loss: 0.7161 - accuracy: 0.8667 - val_loss: 1.1864 - val_accuracy: 0.5000\n",
      "Epoch 53/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8136 - accuracy: 0.81 - 0s 600us/step - loss: 0.6963 - accuracy: 0.8667 - val_loss: 1.1795 - val_accuracy: 0.5000\n",
      "Epoch 54/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.84 - 0s 400us/step - loss: 0.6770 - accuracy: 0.8667 - val_loss: 1.1719 - val_accuracy: 0.5000\n",
      "Epoch 55/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6941 - accuracy: 0.84 - 0s 356us/step - loss: 0.6583 - accuracy: 0.8667 - val_loss: 1.1633 - val_accuracy: 0.5000\n",
      "Epoch 56/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6466 - accuracy: 0.87 - 0s 356us/step - loss: 0.6402 - accuracy: 0.8667 - val_loss: 1.1552 - val_accuracy: 0.4667\n",
      "Epoch 57/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5961 - accuracy: 0.90 - 0s 422us/step - loss: 0.6217 - accuracy: 0.8667 - val_loss: 1.1483 - val_accuracy: 0.4667\n",
      "Epoch 58/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6254 - accuracy: 0.84 - 0s 422us/step - loss: 0.6038 - accuracy: 0.8667 - val_loss: 1.1421 - val_accuracy: 0.4667\n",
      "Epoch 59/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6333 - accuracy: 0.87 - 0s 400us/step - loss: 0.5866 - accuracy: 0.9111 - val_loss: 1.1351 - val_accuracy: 0.4667\n",
      "Epoch 60/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5758 - accuracy: 0.96 - 0s 356us/step - loss: 0.5709 - accuracy: 0.9111 - val_loss: 1.1274 - val_accuracy: 0.4667\n",
      "Epoch 61/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.90 - 0s 378us/step - loss: 0.5536 - accuracy: 0.9333 - val_loss: 1.1205 - val_accuracy: 0.4667\n",
      "Epoch 62/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.93 - 0s 422us/step - loss: 0.5380 - accuracy: 0.9333 - val_loss: 1.1131 - val_accuracy: 0.4667\n",
      "Epoch 63/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.93 - 0s 422us/step - loss: 0.5227 - accuracy: 0.9333 - val_loss: 1.1063 - val_accuracy: 0.4667\n",
      "Epoch 64/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.93 - 0s 378us/step - loss: 0.5073 - accuracy: 0.9333 - val_loss: 1.1001 - val_accuracy: 0.4667\n",
      "Epoch 65/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.93 - 0s 378us/step - loss: 0.4926 - accuracy: 0.9333 - val_loss: 1.0950 - val_accuracy: 0.4667\n",
      "Epoch 66/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5154 - accuracy: 0.90 - 0s 400us/step - loss: 0.4785 - accuracy: 0.9333 - val_loss: 1.0899 - val_accuracy: 0.4667\n",
      "Epoch 67/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4861 - accuracy: 0.90 - 0s 400us/step - loss: 0.4645 - accuracy: 0.9333 - val_loss: 1.0849 - val_accuracy: 0.4667\n",
      "Epoch 68/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4317 - accuracy: 0.96 - 0s 378us/step - loss: 0.4511 - accuracy: 0.9333 - val_loss: 1.0794 - val_accuracy: 0.5000\n",
      "Epoch 69/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4302 - accuracy: 0.90 - 0s 400us/step - loss: 0.4377 - accuracy: 0.9333 - val_loss: 1.0740 - val_accuracy: 0.5000\n",
      "Epoch 70/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.93 - 0s 356us/step - loss: 0.4251 - accuracy: 0.9556 - val_loss: 1.0692 - val_accuracy: 0.5000\n",
      "Epoch 71/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.96 - 0s 422us/step - loss: 0.4125 - accuracy: 0.9556 - val_loss: 1.0644 - val_accuracy: 0.5333\n",
      "Epoch 72/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.93 - 0s 378us/step - loss: 0.4003 - accuracy: 0.9556 - val_loss: 1.0601 - val_accuracy: 0.5667\n",
      "Epoch 73/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4830 - accuracy: 0.93 - 0s 444us/step - loss: 0.3892 - accuracy: 0.9556 - val_loss: 1.0569 - val_accuracy: 0.5667\n",
      "Epoch 74/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4171 - accuracy: 0.93 - 0s 444us/step - loss: 0.3774 - accuracy: 0.9556 - val_loss: 1.0542 - val_accuracy: 0.5667\n",
      "Epoch 75/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.93 - 0s 467us/step - loss: 0.3667 - accuracy: 0.9556 - val_loss: 1.0515 - val_accuracy: 0.5667\n",
      "Epoch 76/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 0.93 - 0s 556us/step - loss: 0.3561 - accuracy: 0.9556 - val_loss: 1.0493 - val_accuracy: 0.5667\n",
      "Epoch 77/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.93 - 0s 488us/step - loss: 0.3456 - accuracy: 0.9556 - val_loss: 1.0472 - val_accuracy: 0.5667\n",
      "Epoch 78/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3240 - accuracy: 0.96 - 0s 467us/step - loss: 0.3358 - accuracy: 0.9556 - val_loss: 1.0447 - val_accuracy: 0.5667\n",
      "Epoch 79/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2878 - accuracy: 0.96 - 0s 600us/step - loss: 0.3265 - accuracy: 0.9556 - val_loss: 1.0414 - val_accuracy: 0.5667\n",
      "Epoch 80/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2916 - accuracy: 0.93 - 0s 444us/step - loss: 0.3173 - accuracy: 0.9556 - val_loss: 1.0389 - val_accuracy: 0.5667\n",
      "Epoch 81/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2761 - accuracy: 0.96 - 0s 444us/step - loss: 0.3073 - accuracy: 0.9778 - val_loss: 1.0363 - val_accuracy: 0.5667\n",
      "Epoch 82/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3284 - accuracy: 0.96 - 0s 467us/step - loss: 0.2992 - accuracy: 0.9778 - val_loss: 1.0341 - val_accuracy: 0.5667\n",
      "Epoch 83/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.96 - 0s 556us/step - loss: 0.2905 - accuracy: 0.9778 - val_loss: 1.0323 - val_accuracy: 0.5667\n",
      "Epoch 84/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3306 - accuracy: 0.96 - 0s 400us/step - loss: 0.2820 - accuracy: 0.9778 - val_loss: 1.0303 - val_accuracy: 0.5667\n",
      "Epoch 85/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2714 - accuracy: 1.00 - 0s 400us/step - loss: 0.2744 - accuracy: 0.9778 - val_loss: 1.0278 - val_accuracy: 0.5667\n",
      "Epoch 86/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3050 - accuracy: 0.96 - 0s 400us/step - loss: 0.2669 - accuracy: 0.9778 - val_loss: 1.0255 - val_accuracy: 0.5667\n",
      "Epoch 87/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2656 - accuracy: 0.96 - 0s 578us/step - loss: 0.2589 - accuracy: 0.9778 - val_loss: 1.0233 - val_accuracy: 0.5667\n",
      "Epoch 88/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.96 - 0s 400us/step - loss: 0.2522 - accuracy: 0.9778 - val_loss: 1.0213 - val_accuracy: 0.5667\n",
      "Epoch 89/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.96 - 0s 400us/step - loss: 0.2452 - accuracy: 0.9778 - val_loss: 1.0201 - val_accuracy: 0.5667\n",
      "Epoch 90/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2849 - accuracy: 0.96 - 0s 422us/step - loss: 0.2386 - accuracy: 0.9778 - val_loss: 1.0191 - val_accuracy: 0.5667\n",
      "Epoch 91/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2809 - accuracy: 0.96 - 0s 400us/step - loss: 0.2322 - accuracy: 0.9778 - val_loss: 1.0177 - val_accuracy: 0.5667\n",
      "Epoch 92/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.96 - 0s 355us/step - loss: 0.2257 - accuracy: 0.9778 - val_loss: 1.0169 - val_accuracy: 0.5667\n",
      "Epoch 93/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.96 - 0s 422us/step - loss: 0.2199 - accuracy: 0.9778 - val_loss: 1.0157 - val_accuracy: 0.5667\n",
      "Epoch 94/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.96 - 0s 378us/step - loss: 0.2144 - accuracy: 0.9778 - val_loss: 1.0139 - val_accuracy: 0.5667\n",
      "Epoch 95/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.96 - 0s 400us/step - loss: 0.2089 - accuracy: 0.9778 - val_loss: 1.0117 - val_accuracy: 0.5667\n",
      "Epoch 96/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1840 - accuracy: 1.00 - 0s 400us/step - loss: 0.2036 - accuracy: 0.9778 - val_loss: 1.0097 - val_accuracy: 0.5667\n",
      "Epoch 97/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1893 - accuracy: 0.96 - 0s 400us/step - loss: 0.1978 - accuracy: 0.9778 - val_loss: 1.0083 - val_accuracy: 0.5667\n",
      "Epoch 98/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1689 - accuracy: 0.96 - 0s 355us/step - loss: 0.1932 - accuracy: 0.9778 - val_loss: 1.0075 - val_accuracy: 0.5667\n",
      "Epoch 99/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2050 - accuracy: 0.96 - 0s 378us/step - loss: 0.1879 - accuracy: 0.9778 - val_loss: 1.0068 - val_accuracy: 0.5667\n",
      "Epoch 100/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1340 - accuracy: 1.00 - 0s 378us/step - loss: 0.1830 - accuracy: 0.9778 - val_loss: 1.0067 - val_accuracy: 0.5667\n",
      "Epoch 101/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 1.00 - 0s 378us/step - loss: 0.1789 - accuracy: 0.9778 - val_loss: 1.0060 - val_accuracy: 0.5667\n",
      "Epoch 102/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.96 - 0s 400us/step - loss: 0.1741 - accuracy: 0.9778 - val_loss: 1.0055 - val_accuracy: 0.5667\n",
      "Epoch 103/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1418 - accuracy: 1.00 - 0s 378us/step - loss: 0.1697 - accuracy: 0.9778 - val_loss: 1.0048 - val_accuracy: 0.5667\n",
      "Epoch 104/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1964 - accuracy: 0.96 - 0s 400us/step - loss: 0.1655 - accuracy: 0.9778 - val_loss: 1.0044 - val_accuracy: 0.5667\n",
      "Epoch 105/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2035 - accuracy: 0.96 - 0s 422us/step - loss: 0.1616 - accuracy: 0.9778 - val_loss: 1.0045 - val_accuracy: 0.5667\n",
      "Epoch 106/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 1.00 - 0s 400us/step - loss: 0.1575 - accuracy: 0.9778 - val_loss: 1.0046 - val_accuracy: 0.5667\n",
      "Epoch 107/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1751 - accuracy: 0.96 - 0s 356us/step - loss: 0.1539 - accuracy: 0.9778 - val_loss: 1.0047 - val_accuracy: 0.5667\n",
      "Epoch 108/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.96 - 0s 400us/step - loss: 0.1503 - accuracy: 0.9778 - val_loss: 1.0044 - val_accuracy: 0.5667\n",
      "Epoch 109/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1703 - accuracy: 0.96 - 0s 400us/step - loss: 0.1469 - accuracy: 0.9778 - val_loss: 1.0036 - val_accuracy: 0.5667\n",
      "Epoch 110/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.96 - 0s 378us/step - loss: 0.1437 - accuracy: 0.9778 - val_loss: 1.0032 - val_accuracy: 0.5667\n",
      "Epoch 111/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1181 - accuracy: 1.00 - 0s 378us/step - loss: 0.1405 - accuracy: 0.9778 - val_loss: 1.0035 - val_accuracy: 0.5667\n",
      "Epoch 112/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.96 - 0s 444us/step - loss: 0.1377 - accuracy: 0.9778 - val_loss: 1.0041 - val_accuracy: 0.5667\n",
      "Epoch 113/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.96 - 0s 378us/step - loss: 0.1347 - accuracy: 0.9778 - val_loss: 1.0048 - val_accuracy: 0.5667\n",
      "Epoch 114/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1565 - accuracy: 0.96 - 0s 356us/step - loss: 0.1318 - accuracy: 0.9778 - val_loss: 1.0054 - val_accuracy: 0.5667\n",
      "Epoch 115/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1585 - accuracy: 0.96 - 0s 400us/step - loss: 0.1292 - accuracy: 0.9778 - val_loss: 1.0052 - val_accuracy: 0.5667\n",
      "Epoch 116/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1483 - accuracy: 0.96 - 0s 378us/step - loss: 0.1266 - accuracy: 0.9778 - val_loss: 1.0049 - val_accuracy: 0.5667\n",
      "Epoch 117/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1183 - accuracy: 1.00 - 0s 377us/step - loss: 0.1244 - accuracy: 0.9778 - val_loss: 1.0056 - val_accuracy: 0.5667\n",
      "Epoch 118/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.96 - 0s 356us/step - loss: 0.1217 - accuracy: 0.9778 - val_loss: 1.0069 - val_accuracy: 0.5667\n",
      "Epoch 119/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1171 - accuracy: 0.96 - 0s 378us/step - loss: 0.1195 - accuracy: 0.9778 - val_loss: 1.0080 - val_accuracy: 0.5333\n",
      "Epoch 120/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 1.00 - 0s 355us/step - loss: 0.1178 - accuracy: 0.9778 - val_loss: 1.0086 - val_accuracy: 0.5333\n",
      "Epoch 121/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1329 - accuracy: 0.96 - 0s 355us/step - loss: 0.1150 - accuracy: 0.9778 - val_loss: 1.0090 - val_accuracy: 0.5333\n",
      "Epoch 122/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.96 - 0s 400us/step - loss: 0.1126 - accuracy: 0.9778 - val_loss: 1.0094 - val_accuracy: 0.5333\n",
      "Epoch 123/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 1.00 - 0s 356us/step - loss: 0.1106 - accuracy: 0.9778 - val_loss: 1.0099 - val_accuracy: 0.5333\n",
      "Epoch 124/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.96 - 0s 378us/step - loss: 0.1091 - accuracy: 0.9778 - val_loss: 1.0102 - val_accuracy: 0.5333\n",
      "Epoch 125/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1112 - accuracy: 0.96 - 0s 400us/step - loss: 0.1065 - accuracy: 0.9778 - val_loss: 1.0104 - val_accuracy: 0.5333\n",
      "Epoch 126/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.96 - 0s 378us/step - loss: 0.1040 - accuracy: 0.9778 - val_loss: 1.0111 - val_accuracy: 0.5333\n",
      "Epoch 127/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1336 - accuracy: 0.96 - 0s 355us/step - loss: 0.1025 - accuracy: 0.9778 - val_loss: 1.0117 - val_accuracy: 0.5333\n",
      "Epoch 128/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0812 - accuracy: 1.00 - 0s 378us/step - loss: 0.1015 - accuracy: 0.9778 - val_loss: 1.0125 - val_accuracy: 0.5333\n",
      "Epoch 129/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1054 - accuracy: 0.96 - 0s 378us/step - loss: 0.0990 - accuracy: 0.9778 - val_loss: 1.0126 - val_accuracy: 0.5333\n",
      "Epoch 130/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1061 - accuracy: 0.96 - 0s 378us/step - loss: 0.0972 - accuracy: 0.9778 - val_loss: 1.0125 - val_accuracy: 0.5333\n",
      "Epoch 131/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1066 - accuracy: 0.96 - 0s 378us/step - loss: 0.0954 - accuracy: 0.9778 - val_loss: 1.0120 - val_accuracy: 0.5333\n",
      "Epoch 132/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0977 - accuracy: 0.96 - 0s 378us/step - loss: 0.0943 - accuracy: 0.9778 - val_loss: 1.0118 - val_accuracy: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0984 - accuracy: 0.96 - 0s 378us/step - loss: 0.0920 - accuracy: 0.9778 - val_loss: 1.0122 - val_accuracy: 0.5333\n",
      "Epoch 134/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1137 - accuracy: 0.96 - 0s 378us/step - loss: 0.0907 - accuracy: 0.9778 - val_loss: 1.0128 - val_accuracy: 0.5333\n",
      "Epoch 135/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0867 - accuracy: 0.96 - 0s 400us/step - loss: 0.0894 - accuracy: 0.9778 - val_loss: 1.0136 - val_accuracy: 0.5333\n",
      "Epoch 136/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0678 - accuracy: 1.00 - 0s 422us/step - loss: 0.0884 - accuracy: 0.9778 - val_loss: 1.0140 - val_accuracy: 0.5333\n",
      "Epoch 137/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1036 - accuracy: 0.96 - 0s 400us/step - loss: 0.0866 - accuracy: 0.9778 - val_loss: 1.0139 - val_accuracy: 0.5333\n",
      "Epoch 138/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.96 - 0s 422us/step - loss: 0.0852 - accuracy: 0.9778 - val_loss: 1.0137 - val_accuracy: 0.5333\n",
      "Epoch 139/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 0.96 - 0s 400us/step - loss: 0.0839 - accuracy: 0.9778 - val_loss: 1.0138 - val_accuracy: 0.5333\n",
      "Epoch 140/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0502 - accuracy: 1.00 - 0s 378us/step - loss: 0.0825 - accuracy: 0.9778 - val_loss: 1.0141 - val_accuracy: 0.5333\n",
      "Epoch 141/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.96 - 0s 400us/step - loss: 0.0817 - accuracy: 0.9778 - val_loss: 1.0144 - val_accuracy: 0.5333\n",
      "Epoch 142/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.96 - 0s 378us/step - loss: 0.0802 - accuracy: 0.9778 - val_loss: 1.0148 - val_accuracy: 0.5333\n",
      "Epoch 143/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0394 - accuracy: 1.00 - 0s 378us/step - loss: 0.0790 - accuracy: 0.9778 - val_loss: 1.0151 - val_accuracy: 0.5333\n",
      "Epoch 144/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.96 - 0s 356us/step - loss: 0.0779 - accuracy: 0.9778 - val_loss: 1.0149 - val_accuracy: 0.5333\n",
      "Epoch 145/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0850 - accuracy: 0.96 - 0s 378us/step - loss: 0.0768 - accuracy: 0.9778 - val_loss: 1.0145 - val_accuracy: 0.5333\n",
      "Epoch 146/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 1.00 - 0s 400us/step - loss: 0.0757 - accuracy: 0.9778 - val_loss: 1.0144 - val_accuracy: 0.5333\n",
      "Epoch 147/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.96 - 0s 378us/step - loss: 0.0751 - accuracy: 0.9778 - val_loss: 1.0141 - val_accuracy: 0.5333\n",
      "Epoch 148/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.96 - 0s 400us/step - loss: 0.0736 - accuracy: 0.9778 - val_loss: 1.0147 - val_accuracy: 0.5333\n",
      "Epoch 149/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0626 - accuracy: 0.96 - 0s 378us/step - loss: 0.0725 - accuracy: 0.9778 - val_loss: 1.0156 - val_accuracy: 0.5333\n",
      "Epoch 150/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.96 - 0s 355us/step - loss: 0.0716 - accuracy: 0.9778 - val_loss: 1.0166 - val_accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = XX_train.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(units=YY_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 150\n",
    "batch_size = 32\n",
    "history = model.fit(XX_train, YY_train, epochs=epochs, batch_size=batch_size, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba=model.predict(XX_test)\n",
    "idx = np.argmax(pred_proba, axis=-1)\n",
    "YY_pred = np.zeros( pred_proba.shape )\n",
    "YY_pred[ np.arange(YY_pred.shape[0]), idx] = 1\n",
    "accuracy_score(YY_test, YY_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Choix et sauvegarde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que nous n'ayons pas laissé la trace de nos recherches, nous avons cherché, pour chaque modèle, à ajuster au mieux leurs paramètres. Après ces différents tests, nous sauvegardons le modèle associé au classifieur qui nous fournit la meilleure accuracy. Ainsi, nous choisissons le réseau de neuronnes à convolution et le classifieur TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_classif_theme.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model, 'model_classif_theme.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_classif_theme.joblib']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(vect_tfidf, 'vectorizer_classif_theme.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation quantitative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'évaluer de manière quantitative le modèle sélectionné, nous avons créé un jeu de questions - thèmes dont les thèmes correspondent à ceux de la FAQ mais dont les questions ont été imaginées pas nos soins. L'objectif étant de comparer la prédiction du modèle choisi au thème attendu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question                theme\n",
       "0                   Quels sont les jours d’arrivée ?  Préparer mon séjour\n",
       "1  Comment évaluer le confort de mon domaine et d...  Préparer mon séjour\n",
       "2  Quels sont les services et activités compris d...  Préparer mon séjour\n",
       "3                   Comment réserver mes activités ?  Préparer mon séjour\n",
       "4                    Où trouver le plan du domaine ?  Préparer mon séjour"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_quanti = pd.read_csv('jeu_test_theme.csv', \";\")\n",
    "df_test_quanti.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquons le même traitement que précédemment à ce jeu de données. Nous codons les thèmes puis nous séparons la variable d'intérêt de la variable explicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_quanti[\"theme\"].replace(dic_code_theme, inplace=True)\n",
    "X_test_quanti = df_test_quanti.question\n",
    "y_test_quanti = df_test_quanti.theme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_quanti = (X_test_quanti.apply(lemmatise_text)\n",
    "                              .apply(stem_text)\n",
    "                              .apply(substitute_punctuation)\n",
    "                              .apply(substitute_special_char)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_quanti_vectorized_tfidf = vect_tfidf.transform(X_test_quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_test_quanti = X_test_quanti_vectorized_tfidf.toarray().reshape(X_test_quanti_vectorized_tfidf.shape[0],1,\n",
    "                                                X_test_quanti_vectorized_tfidf.shape[1])\n",
    "YY_test_quanti = pd.get_dummies(y_test_quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba=model.predict(XX_test_quanti)\n",
    "idx = np.argmax(pred_proba, axis=-1)\n",
    "YY_pred_quanti = np.zeros( pred_proba.shape )\n",
    "YY_pred_quanti[ np.arange(YY_pred_quanti.shape[0]), idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6852367688022284"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(YY_test_quanti, YY_pred_quanti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6698296185567882"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(YY_test_quanti, YY_pred_quanti, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6977658241409519"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(YY_test_quanti, YY_pred_quanti, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6852367688022284"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(YY_test_quanti, YY_pred_quanti, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats obtenus sont satisfaisants puisque l'introduction de nouvelles questions ne perturbent pas le modèle. Le taux de nouvelles questions bien classées reste proche des 70%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
