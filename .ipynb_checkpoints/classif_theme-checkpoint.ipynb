{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification de la question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prétraitement textuel de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Préparation du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reponse</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>Il est possible d’arriver n’importe quel jour ...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>Le classement par « birdies » évalue l’offre C...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>En réservant votre hébergement, vous bénéficie...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>Lors de la réservation de votre hébergement, v...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>Sur la page d'accueil de notre site, cliquez s...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   Quels sont les jours d’arrivée ?   \n",
       "1  Comment évaluer le confort de mon domaine et d...   \n",
       "2  Quels sont les services et activités compris d...   \n",
       "3                   Comment réserver mes activités ?   \n",
       "4                    Où trouver le plan du domaine ?   \n",
       "\n",
       "                                             reponse                theme  \n",
       "0  Il est possible d’arriver n’importe quel jour ...  Préparer mon séjour  \n",
       "1  Le classement par « birdies » évalue l’offre C...  Préparer mon séjour  \n",
       "2  En réservant votre hébergement, vous bénéficie...  Préparer mon séjour  \n",
       "3  Lors de la réservation de votre hébergement, v...  Préparer mon séjour  \n",
       "4  Sur la page d'accueil de notre site, cliquez s...  Préparer mon séjour  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq = pd.read_pickle('faq_centerPark.pkl')\n",
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données est composé de :\n",
    "    - 54 lignes\n",
    "    - 3 colonnes\n",
    "    - 5 thèmes différents\n",
    "On pose :\n",
    "    - 1 = Préparer mon séjour\n",
    "    - 2 = Réserver et payer\n",
    "    - 3 = Gérer ma réservation\n",
    "    - 4 = Mon séjour\n",
    "    - 5 = Assurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faq.to_csv('jeu_test_similarite.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_code_theme = {\"Préparer mon séjour\": 1,\n",
    "                  \"Réserver et payer\": 2,\n",
    "                  \"Gérer ma réservation\": 3,\n",
    "                  \"Mon séjour\": 4,\n",
    "                  \"Assurances\": 5}\n",
    "dic_decode_theme = {val: key for key, val in dic_code_theme.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faq[\"theme\"].replace(dic_code_theme, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enora\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_question = df_faq[['question', 'theme']]\n",
    "df_question.rename(columns={'question': 'texte', 'theme': 'theme'}, inplace=True)\n",
    "df_reponse = df_faq[['reponse', 'theme']]\n",
    "df_reponse.rename(columns={'reponse': 'texte', 'theme': 'theme'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_question, df_reponse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "df_concat.to_pickle('df_concat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Nettoyage du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# pour le nettoyage du texte\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#pour la classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_concat = pd.read_pickle('df_concat.pkl')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_concat['texte'], \n",
    "                                                    df_concat['theme'],\n",
    "                                                    train_size=0.7,\n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('french')\n",
    "#tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # tokenizer for tweet\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']\n",
    "sw.sort()\n",
    "\n",
    "def lemmatise_text(text):\n",
    "    lst_lematised = [token.lemma_ for token in nlp(text)]\n",
    "    return ' '.join(lst_lematised).lower()\n",
    "\n",
    "\n",
    "def stem_text(text):\n",
    "    #lst_stemmerised = [stemmer.stem(token) for token in tokenizer.tokenize(text)] \n",
    "    lst_stemmerised = [stemmer.stem(token) for token in word_tokenize(text)]\n",
    "    return ' '.join(lst_stemmerised)\n",
    "\n",
    "\n",
    "def replace_words_with_pos_tag(text):\n",
    "    lst_tags = [token.pos_ for token in nlp(text)]\n",
    "    return ' '.join(lst_tags)\n",
    "\n",
    "\n",
    "def ner(text): #entites nommees\n",
    "    dico_remplacement = {entite_nommee.text : entite_nommee.label_ for entite_nommee in nlp(text).ents}\n",
    "    for entite_nommee, remplacement in dico_remplacement.items():\n",
    "        text = text.replace(entite_nommee, remplacement)\n",
    "    return text\n",
    "\n",
    "\n",
    "def substitute_punctuation(text):\n",
    "    return ' '.join(text.replace(\"'\", ' ').translate(str.maketrans('', '', string.punctuation)).split())\n",
    "\n",
    "\n",
    "def supp(text):\n",
    "    return text.replace(\"«\", \"\").replace(\"’\", \"\").replace(\"•\", \"\").replace(\"®\", \"\")\n",
    "\n",
    "\n",
    "def supprime_accent(txt):\n",
    "    return unidecode.unidecode(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = (X_train.apply(lemmatise_text)\n",
    "                        .apply(stem_text)\n",
    "                        .apply(substitute_punctuation)\n",
    "                        .apply(supp)\n",
    "                )\n",
    "\n",
    "X_test_clean = (X_test.apply(lemmatise_text)\n",
    "                      .apply(stem_text)\n",
    "                      .apply(substitute_punctuation)\n",
    "                      .apply(supp)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Test de différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Les différents vectoriseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriseur binaire\n",
    "\n",
    "bin_count = CountVectorizer(binary=True)\n",
    "bin_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_bin = bin_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_bin = bin_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriseur numérique discret\n",
    "\n",
    "vect_count = CountVectorizer(binary=False)\n",
    "vect_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_count = vect_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_count = vect_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_classif_theme.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectoriseur numérique continu : TF-IDF\n",
    "\n",
    "vect_tfidf = TfidfVectorizer(stop_words=sw)\n",
    "vect_tfidf.fit(X_train_clean)\n",
    "X_train_clean_vectorized_tfidf = vect_tfidf.transform(X_train_clean)\n",
    "X_test_clean_vectorized_tfidf = vect_tfidf.transform(X_test_clean) \n",
    "\n",
    "## export vectorizer\n",
    "from joblib import dump\n",
    "dump(vect_tfidf, 'vectorizer_classif_theme.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Les différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous entraînerons des modèles de classification appartenant à quelques familles d'algorithmes d'apprentissage automatique classique. L'objectif est de comparer non seulement les performances des différentes méthodes entre elles, mais aussi la performance d'une même méthode sur des représentations différentes du texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b.1 DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06060606060606061"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12121212121212122"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21212121212121213"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b.2 Classifieur naïf bayesien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060606060606061"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.3 Complement NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060606060606061"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.4 BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.5KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30303030303030304"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.7. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3939393939393939"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3939393939393939"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.8 Réseaux de neurones de convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, SpatialDropout1D, MaxPooling1D, Conv1D, Flatten, MaxPooling2D, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train = X_train_clean_vectorized_tfidf.toarray().reshape(X_train_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_train_clean_vectorized_tfidf.shape[1])\n",
    "XX_test = X_test_clean_vectorized_tfidf.toarray().reshape(X_test_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_test_clean_vectorized_tfidf.shape[1])\n",
    "YY_train = pd.get_dummies(y_train)\n",
    "YY_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45 samples, validate on 30 samples\n",
      "Epoch 1/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.6183 - accuracy: 0.03 - 0s 8ms/step - loss: 1.6174 - accuracy: 0.0667 - val_loss: 1.6137 - val_accuracy: 0.2000\n",
      "Epoch 2/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.6071 - accuracy: 0.18 - 0s 489us/step - loss: 1.6074 - accuracy: 0.1778 - val_loss: 1.6126 - val_accuracy: 0.2000\n",
      "Epoch 3/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5977 - accuracy: 0.34 - 0s 622us/step - loss: 1.5993 - accuracy: 0.3111 - val_loss: 1.6114 - val_accuracy: 0.2667\n",
      "Epoch 4/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5937 - accuracy: 0.37 - 0s 533us/step - loss: 1.5919 - accuracy: 0.3556 - val_loss: 1.6101 - val_accuracy: 0.3333\n",
      "Epoch 5/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5844 - accuracy: 0.43 - 0s 578us/step - loss: 1.5851 - accuracy: 0.4667 - val_loss: 1.6087 - val_accuracy: 0.3333\n",
      "Epoch 6/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5791 - accuracy: 0.53 - 0s 733us/step - loss: 1.5780 - accuracy: 0.5333 - val_loss: 1.6072 - val_accuracy: 0.3667\n",
      "Epoch 7/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5750 - accuracy: 0.56 - 0s 1ms/step - loss: 1.5717 - accuracy: 0.6000 - val_loss: 1.6057 - val_accuracy: 0.3667\n",
      "Epoch 8/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5717 - accuracy: 0.65 - 0s 555us/step - loss: 1.5652 - accuracy: 0.6667 - val_loss: 1.6043 - val_accuracy: 0.3667\n",
      "Epoch 9/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5557 - accuracy: 0.71 - 0s 511us/step - loss: 1.5585 - accuracy: 0.6667 - val_loss: 1.6027 - val_accuracy: 0.4000\n",
      "Epoch 10/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5611 - accuracy: 0.59 - 0s 533us/step - loss: 1.5511 - accuracy: 0.6889 - val_loss: 1.6010 - val_accuracy: 0.4333\n",
      "Epoch 11/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5461 - accuracy: 0.71 - 0s 668us/step - loss: 1.5439 - accuracy: 0.7333 - val_loss: 1.5989 - val_accuracy: 0.4667\n",
      "Epoch 12/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5394 - accuracy: 0.84 - 0s 733us/step - loss: 1.5359 - accuracy: 0.7778 - val_loss: 1.5966 - val_accuracy: 0.4667\n",
      "Epoch 13/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5322 - accuracy: 0.78 - 0s 733us/step - loss: 1.5275 - accuracy: 0.7778 - val_loss: 1.5940 - val_accuracy: 0.4667\n",
      "Epoch 14/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5177 - accuracy: 0.78 - 0s 756us/step - loss: 1.5186 - accuracy: 0.8000 - val_loss: 1.5913 - val_accuracy: 0.4667\n",
      "Epoch 15/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5165 - accuracy: 0.75 - 0s 467us/step - loss: 1.5088 - accuracy: 0.8222 - val_loss: 1.5885 - val_accuracy: 0.4667\n",
      "Epoch 16/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5032 - accuracy: 0.78 - 0s 755us/step - loss: 1.4986 - accuracy: 0.8222 - val_loss: 1.5856 - val_accuracy: 0.5000\n",
      "Epoch 17/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4874 - accuracy: 0.84 - 0s 667us/step - loss: 1.4881 - accuracy: 0.8222 - val_loss: 1.5821 - val_accuracy: 0.5000\n",
      "Epoch 18/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4793 - accuracy: 0.81 - 0s 422us/step - loss: 1.4761 - accuracy: 0.8444 - val_loss: 1.5784 - val_accuracy: 0.5000\n",
      "Epoch 19/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4617 - accuracy: 0.90 - 0s 755us/step - loss: 1.4639 - accuracy: 0.8667 - val_loss: 1.5740 - val_accuracy: 0.5000\n",
      "Epoch 20/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4479 - accuracy: 0.87 - 0s 533us/step - loss: 1.4508 - accuracy: 0.8667 - val_loss: 1.5693 - val_accuracy: 0.5000\n",
      "Epoch 21/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4326 - accuracy: 0.87 - 0s 533us/step - loss: 1.4370 - accuracy: 0.8667 - val_loss: 1.5644 - val_accuracy: 0.5000\n",
      "Epoch 22/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4168 - accuracy: 0.93 - 0s 444us/step - loss: 1.4227 - accuracy: 0.8667 - val_loss: 1.5587 - val_accuracy: 0.5000\n",
      "Epoch 23/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4165 - accuracy: 0.81 - 0s 489us/step - loss: 1.4069 - accuracy: 0.8667 - val_loss: 1.5525 - val_accuracy: 0.5000\n",
      "Epoch 24/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3922 - accuracy: 0.84 - 0s 467us/step - loss: 1.3906 - accuracy: 0.8667 - val_loss: 1.5460 - val_accuracy: 0.5000\n",
      "Epoch 25/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3590 - accuracy: 0.93 - 0s 534us/step - loss: 1.3737 - accuracy: 0.8889 - val_loss: 1.5391 - val_accuracy: 0.5000\n",
      "Epoch 26/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3580 - accuracy: 0.87 - 0s 467us/step - loss: 1.3553 - accuracy: 0.8667 - val_loss: 1.5320 - val_accuracy: 0.5000\n",
      "Epoch 27/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3456 - accuracy: 0.81 - 0s 511us/step - loss: 1.3361 - accuracy: 0.8444 - val_loss: 1.5237 - val_accuracy: 0.4667\n",
      "Epoch 28/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2983 - accuracy: 0.87 - 0s 555us/step - loss: 1.3166 - accuracy: 0.8667 - val_loss: 1.5147 - val_accuracy: 0.4667\n",
      "Epoch 29/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2916 - accuracy: 0.84 - 0s 600us/step - loss: 1.2952 - accuracy: 0.8667 - val_loss: 1.5057 - val_accuracy: 0.4667\n",
      "Epoch 30/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2579 - accuracy: 0.90 - 0s 511us/step - loss: 1.2735 - accuracy: 0.8667 - val_loss: 1.4960 - val_accuracy: 0.4667\n",
      "Epoch 31/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2302 - accuracy: 0.87 - 0s 489us/step - loss: 1.2500 - accuracy: 0.8889 - val_loss: 1.4861 - val_accuracy: 0.4667\n",
      "Epoch 32/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2099 - accuracy: 0.87 - 0s 667us/step - loss: 1.2258 - accuracy: 0.8889 - val_loss: 1.4759 - val_accuracy: 0.4667\n",
      "Epoch 33/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2061 - accuracy: 0.87 - 0s 489us/step - loss: 1.2000 - accuracy: 0.8889 - val_loss: 1.4655 - val_accuracy: 0.4667\n",
      "Epoch 34/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1750 - accuracy: 0.87 - 0s 667us/step - loss: 1.1738 - accuracy: 0.8889 - val_loss: 1.4543 - val_accuracy: 0.4667\n",
      "Epoch 35/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1538 - accuracy: 0.87 - 0s 712us/step - loss: 1.1466 - accuracy: 0.8667 - val_loss: 1.4424 - val_accuracy: 0.4667\n",
      "Epoch 36/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1461 - accuracy: 0.81 - 0s 422us/step - loss: 1.1174 - accuracy: 0.8667 - val_loss: 1.4300 - val_accuracy: 0.5000\n",
      "Epoch 37/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0818 - accuracy: 0.90 - 0s 578us/step - loss: 1.0885 - accuracy: 0.8889 - val_loss: 1.4164 - val_accuracy: 0.5000\n",
      "Epoch 38/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0834 - accuracy: 0.87 - 0s 467us/step - loss: 1.0577 - accuracy: 0.9111 - val_loss: 1.4022 - val_accuracy: 0.5333\n",
      "Epoch 39/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0752 - accuracy: 0.90 - 0s 622us/step - loss: 1.0273 - accuracy: 0.9111 - val_loss: 1.3872 - val_accuracy: 0.5333\n",
      "Epoch 40/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0046 - accuracy: 0.90 - 0s 511us/step - loss: 0.9968 - accuracy: 0.9111 - val_loss: 1.3722 - val_accuracy: 0.5333\n",
      "Epoch 41/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9737 - accuracy: 0.90 - 0s 555us/step - loss: 0.9652 - accuracy: 0.9111 - val_loss: 1.3579 - val_accuracy: 0.5333\n",
      "Epoch 42/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9130 - accuracy: 0.93 - 0s 622us/step - loss: 0.9343 - accuracy: 0.9111 - val_loss: 1.3432 - val_accuracy: 0.5333\n",
      "Epoch 43/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8879 - accuracy: 0.93 - 0s 578us/step - loss: 0.9026 - accuracy: 0.9111 - val_loss: 1.3283 - val_accuracy: 0.5333\n",
      "Epoch 44/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9264 - accuracy: 0.93 - 0s 644us/step - loss: 0.8705 - accuracy: 0.9333 - val_loss: 1.3130 - val_accuracy: 0.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8581 - accuracy: 0.93 - 0s 622us/step - loss: 0.8400 - accuracy: 0.9333 - val_loss: 1.2979 - val_accuracy: 0.5333\n",
      "Epoch 46/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7872 - accuracy: 0.93 - 0s 623us/step - loss: 0.8095 - accuracy: 0.9333 - val_loss: 1.2847 - val_accuracy: 0.5333\n",
      "Epoch 47/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7926 - accuracy: 0.96 - 0s 622us/step - loss: 0.7790 - accuracy: 0.9333 - val_loss: 1.2721 - val_accuracy: 0.5333\n",
      "Epoch 48/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7331 - accuracy: 0.96 - 0s 778us/step - loss: 0.7488 - accuracy: 0.9333 - val_loss: 1.2599 - val_accuracy: 0.5333\n",
      "Epoch 49/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.93 - 0s 400us/step - loss: 0.7203 - accuracy: 0.9556 - val_loss: 1.2479 - val_accuracy: 0.5333\n",
      "Epoch 50/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7261 - accuracy: 0.96 - 0s 689us/step - loss: 0.6909 - accuracy: 0.9556 - val_loss: 1.2348 - val_accuracy: 0.5333\n",
      "Epoch 51/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6774 - accuracy: 0.93 - 0s 444us/step - loss: 0.6629 - accuracy: 0.9556 - val_loss: 1.2219 - val_accuracy: 0.5667\n",
      "Epoch 52/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6515 - accuracy: 0.96 - 0s 489us/step - loss: 0.6358 - accuracy: 0.9556 - val_loss: 1.2092 - val_accuracy: 0.5667\n",
      "Epoch 53/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5850 - accuracy: 0.93 - 0s 422us/step - loss: 0.6094 - accuracy: 0.9556 - val_loss: 1.1959 - val_accuracy: 0.5667\n",
      "Epoch 54/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5119 - accuracy: 1.00 - 0s 512us/step - loss: 0.5842 - accuracy: 0.9778 - val_loss: 1.1839 - val_accuracy: 0.5667\n",
      "Epoch 55/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.96 - 0s 444us/step - loss: 0.5602 - accuracy: 0.9778 - val_loss: 1.1725 - val_accuracy: 0.5667\n",
      "Epoch 56/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5855 - accuracy: 0.96 - 0s 533us/step - loss: 0.5362 - accuracy: 0.9778 - val_loss: 1.1623 - val_accuracy: 0.5667\n",
      "Epoch 57/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.96 - 0s 467us/step - loss: 0.5135 - accuracy: 0.9778 - val_loss: 1.1529 - val_accuracy: 0.5667\n",
      "Epoch 58/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5187 - accuracy: 0.96 - 0s 467us/step - loss: 0.4920 - accuracy: 0.9778 - val_loss: 1.1436 - val_accuracy: 0.5667\n",
      "Epoch 59/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4829 - accuracy: 0.96 - 0s 512us/step - loss: 0.4712 - accuracy: 0.9778 - val_loss: 1.1335 - val_accuracy: 0.5667\n",
      "Epoch 60/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.96 - 0s 511us/step - loss: 0.4508 - accuracy: 0.9778 - val_loss: 1.1236 - val_accuracy: 0.5667\n",
      "Epoch 61/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4228 - accuracy: 0.96 - 0s 533us/step - loss: 0.4311 - accuracy: 0.9778 - val_loss: 1.1148 - val_accuracy: 0.5667\n",
      "Epoch 62/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.96 - 0s 467us/step - loss: 0.4136 - accuracy: 0.9778 - val_loss: 1.1056 - val_accuracy: 0.5667\n",
      "Epoch 63/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4154 - accuracy: 0.96 - 0s 444us/step - loss: 0.3968 - accuracy: 0.9778 - val_loss: 1.0971 - val_accuracy: 0.5667\n",
      "Epoch 64/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 1.00 - 0s 467us/step - loss: 0.3810 - accuracy: 0.9778 - val_loss: 1.0878 - val_accuracy: 0.5667\n",
      "Epoch 65/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.96 - 0s 489us/step - loss: 0.3651 - accuracy: 0.9778 - val_loss: 1.0787 - val_accuracy: 0.5667\n",
      "Epoch 66/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3446 - accuracy: 1.00 - 0s 467us/step - loss: 0.3497 - accuracy: 0.9778 - val_loss: 1.0708 - val_accuracy: 0.6000\n",
      "Epoch 67/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.96 - 0s 489us/step - loss: 0.3357 - accuracy: 0.9778 - val_loss: 1.0629 - val_accuracy: 0.6000\n",
      "Epoch 68/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.96 - 0s 400us/step - loss: 0.3217 - accuracy: 0.9778 - val_loss: 1.0554 - val_accuracy: 0.6000\n",
      "Epoch 69/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 1.00 - 0s 467us/step - loss: 0.3087 - accuracy: 0.9778 - val_loss: 1.0480 - val_accuracy: 0.6000\n",
      "Epoch 70/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2010 - accuracy: 1.00 - 0s 467us/step - loss: 0.2956 - accuracy: 0.9778 - val_loss: 1.0413 - val_accuracy: 0.6000\n",
      "Epoch 71/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3042 - accuracy: 0.96 - 0s 489us/step - loss: 0.2855 - accuracy: 0.9778 - val_loss: 1.0359 - val_accuracy: 0.6000\n",
      "Epoch 72/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 1.00 - 0s 467us/step - loss: 0.2731 - accuracy: 0.9778 - val_loss: 1.0303 - val_accuracy: 0.6000\n",
      "Epoch 73/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.96 - 0s 467us/step - loss: 0.2624 - accuracy: 0.9778 - val_loss: 1.0231 - val_accuracy: 0.6000\n",
      "Epoch 74/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.96 - 0s 467us/step - loss: 0.2526 - accuracy: 0.9778 - val_loss: 1.0165 - val_accuracy: 0.6000\n",
      "Epoch 75/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.96 - 0s 489us/step - loss: 0.2429 - accuracy: 0.9778 - val_loss: 1.0108 - val_accuracy: 0.6000\n",
      "Epoch 76/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 1.00 - 0s 511us/step - loss: 0.2340 - accuracy: 0.9778 - val_loss: 1.0054 - val_accuracy: 0.6000\n",
      "Epoch 77/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2544 - accuracy: 0.96 - 0s 489us/step - loss: 0.2255 - accuracy: 0.9778 - val_loss: 1.0008 - val_accuracy: 0.6000\n",
      "Epoch 78/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.96 - 0s 466us/step - loss: 0.2175 - accuracy: 0.9778 - val_loss: 0.9965 - val_accuracy: 0.6000\n",
      "Epoch 79/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1718 - accuracy: 1.00 - 0s 422us/step - loss: 0.2100 - accuracy: 0.9778 - val_loss: 0.9930 - val_accuracy: 0.6000\n",
      "Epoch 80/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2085 - accuracy: 1.00 - 0s 467us/step - loss: 0.2024 - accuracy: 0.9778 - val_loss: 0.9906 - val_accuracy: 0.6000\n",
      "Epoch 81/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.96 - 0s 422us/step - loss: 0.1964 - accuracy: 0.9778 - val_loss: 0.9881 - val_accuracy: 0.6000\n",
      "Epoch 82/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2084 - accuracy: 0.96 - 0s 467us/step - loss: 0.1889 - accuracy: 0.9778 - val_loss: 0.9857 - val_accuracy: 0.6000\n",
      "Epoch 83/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 1.00 - 0s 422us/step - loss: 0.1832 - accuracy: 0.9778 - val_loss: 0.9828 - val_accuracy: 0.6000\n",
      "Epoch 84/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.96 - 0s 489us/step - loss: 0.1765 - accuracy: 0.9778 - val_loss: 0.9803 - val_accuracy: 0.6000\n",
      "Epoch 85/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 1.00 - 0s 533us/step - loss: 0.1716 - accuracy: 0.9778 - val_loss: 0.9784 - val_accuracy: 0.6000\n",
      "Epoch 86/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.96 - 0s 511us/step - loss: 0.1658 - accuracy: 0.9778 - val_loss: 0.9758 - val_accuracy: 0.6000\n",
      "Epoch 87/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1435 - accuracy: 1.00 - 0s 467us/step - loss: 0.1606 - accuracy: 0.9778 - val_loss: 0.9728 - val_accuracy: 0.6000\n",
      "Epoch 88/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1387 - accuracy: 0.96 - 0s 444us/step - loss: 0.1559 - accuracy: 0.9778 - val_loss: 0.9695 - val_accuracy: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.96 - 0s 467us/step - loss: 0.1516 - accuracy: 0.9778 - val_loss: 0.9664 - val_accuracy: 0.6333\n",
      "Epoch 90/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.96 - 0s 489us/step - loss: 0.1472 - accuracy: 0.9778 - val_loss: 0.9630 - val_accuracy: 0.6333\n",
      "Epoch 91/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1482 - accuracy: 0.96 - 0s 444us/step - loss: 0.1432 - accuracy: 0.9778 - val_loss: 0.9605 - val_accuracy: 0.6333\n",
      "Epoch 92/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.96 - 0s 422us/step - loss: 0.1394 - accuracy: 0.9778 - val_loss: 0.9585 - val_accuracy: 0.6333\n",
      "Epoch 93/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 1.00 - 0s 511us/step - loss: 0.1357 - accuracy: 0.9778 - val_loss: 0.9561 - val_accuracy: 0.6333\n",
      "Epoch 94/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.96 - 0s 422us/step - loss: 0.1326 - accuracy: 0.9778 - val_loss: 0.9533 - val_accuracy: 0.6333\n",
      "Epoch 95/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.96 - 0s 467us/step - loss: 0.1281 - accuracy: 0.9778 - val_loss: 0.9505 - val_accuracy: 0.6333\n",
      "Epoch 96/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1142 - accuracy: 0.96 - 0s 444us/step - loss: 0.1251 - accuracy: 0.9778 - val_loss: 0.9484 - val_accuracy: 0.6333\n",
      "Epoch 97/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.96 - 0s 467us/step - loss: 0.1214 - accuracy: 0.9778 - val_loss: 0.9473 - val_accuracy: 0.6333\n",
      "Epoch 98/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.96 - 0s 533us/step - loss: 0.1185 - accuracy: 0.9778 - val_loss: 0.9454 - val_accuracy: 0.6333\n",
      "Epoch 99/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.96 - 0s 467us/step - loss: 0.1155 - accuracy: 0.9778 - val_loss: 0.9429 - val_accuracy: 0.6333\n",
      "Epoch 100/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1271 - accuracy: 0.96 - 0s 444us/step - loss: 0.1129 - accuracy: 0.9778 - val_loss: 0.9407 - val_accuracy: 0.6333\n",
      "Epoch 101/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1147 - accuracy: 0.96 - 0s 489us/step - loss: 0.1100 - accuracy: 0.9778 - val_loss: 0.9385 - val_accuracy: 0.6333\n",
      "Epoch 102/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1095 - accuracy: 0.96 - 0s 467us/step - loss: 0.1074 - accuracy: 0.9778 - val_loss: 0.9360 - val_accuracy: 0.6333\n",
      "Epoch 103/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.96 - 0s 422us/step - loss: 0.1049 - accuracy: 0.9778 - val_loss: 0.9338 - val_accuracy: 0.6333\n",
      "Epoch 104/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1140 - accuracy: 0.96 - 0s 444us/step - loss: 0.1025 - accuracy: 0.9778 - val_loss: 0.9323 - val_accuracy: 0.6333\n",
      "Epoch 105/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.96 - 0s 467us/step - loss: 0.1002 - accuracy: 0.9778 - val_loss: 0.9308 - val_accuracy: 0.6333\n",
      "Epoch 106/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.96 - 0s 444us/step - loss: 0.0980 - accuracy: 0.9778 - val_loss: 0.9294 - val_accuracy: 0.6333\n",
      "Epoch 107/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.96 - 0s 422us/step - loss: 0.0963 - accuracy: 0.9556 - val_loss: 0.9282 - val_accuracy: 0.6333\n",
      "Epoch 108/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1058 - accuracy: 0.96 - 0s 444us/step - loss: 0.0939 - accuracy: 0.9778 - val_loss: 0.9267 - val_accuracy: 0.6333\n",
      "Epoch 109/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 1.00 - 0s 444us/step - loss: 0.0928 - accuracy: 0.9778 - val_loss: 0.9250 - val_accuracy: 0.6333\n",
      "Epoch 110/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1144 - accuracy: 0.96 - 0s 444us/step - loss: 0.0902 - accuracy: 0.9778 - val_loss: 0.9229 - val_accuracy: 0.6333\n",
      "Epoch 111/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0589 - accuracy: 1.00 - 0s 444us/step - loss: 0.0884 - accuracy: 0.9778 - val_loss: 0.9211 - val_accuracy: 0.6333\n",
      "Epoch 112/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0874 - accuracy: 0.96 - 0s 422us/step - loss: 0.0870 - accuracy: 0.9778 - val_loss: 0.9194 - val_accuracy: 0.6333\n",
      "Epoch 113/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.96 - 0s 511us/step - loss: 0.0853 - accuracy: 0.9778 - val_loss: 0.9177 - val_accuracy: 0.6333\n",
      "Epoch 114/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0774 - accuracy: 0.96 - 0s 489us/step - loss: 0.0839 - accuracy: 0.9778 - val_loss: 0.9162 - val_accuracy: 0.6333\n",
      "Epoch 115/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0989 - accuracy: 0.96 - 0s 511us/step - loss: 0.0829 - accuracy: 0.9778 - val_loss: 0.9138 - val_accuracy: 0.6333\n",
      "Epoch 116/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 1.00 - 0s 422us/step - loss: 0.0831 - accuracy: 0.9778 - val_loss: 0.9120 - val_accuracy: 0.6333\n",
      "Epoch 117/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0931 - accuracy: 0.96 - 0s 467us/step - loss: 0.0809 - accuracy: 0.9778 - val_loss: 0.9120 - val_accuracy: 0.6333\n",
      "Epoch 118/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.96 - 0s 467us/step - loss: 0.0793 - accuracy: 0.9778 - val_loss: 0.9122 - val_accuracy: 0.6333\n",
      "Epoch 119/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0883 - accuracy: 0.96 - 0s 467us/step - loss: 0.0778 - accuracy: 0.9778 - val_loss: 0.9123 - val_accuracy: 0.6333\n",
      "Epoch 120/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.96 - 0s 467us/step - loss: 0.0772 - accuracy: 0.9778 - val_loss: 0.9115 - val_accuracy: 0.6333\n",
      "Epoch 121/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.96 - 0s 444us/step - loss: 0.0755 - accuracy: 0.9778 - val_loss: 0.9096 - val_accuracy: 0.6333\n",
      "Epoch 122/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0887 - accuracy: 0.96 - 0s 444us/step - loss: 0.0742 - accuracy: 0.9778 - val_loss: 0.9070 - val_accuracy: 0.6333\n",
      "Epoch 123/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0878 - accuracy: 0.96 - 0s 489us/step - loss: 0.0734 - accuracy: 0.9778 - val_loss: 0.9047 - val_accuracy: 0.6333\n",
      "Epoch 124/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0868 - accuracy: 0.96 - 0s 467us/step - loss: 0.0726 - accuracy: 0.9778 - val_loss: 0.9027 - val_accuracy: 0.6333\n",
      "Epoch 125/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 1.00 - 0s 489us/step - loss: 0.0723 - accuracy: 0.9778 - val_loss: 0.9012 - val_accuracy: 0.6333\n",
      "Epoch 126/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.96 - 0s 467us/step - loss: 0.0707 - accuracy: 0.9778 - val_loss: 0.9009 - val_accuracy: 0.6667\n",
      "Epoch 127/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0519 - accuracy: 1.00 - 0s 489us/step - loss: 0.0690 - accuracy: 0.9778 - val_loss: 0.9008 - val_accuracy: 0.6667\n",
      "Epoch 128/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0817 - accuracy: 0.96 - 0s 444us/step - loss: 0.0684 - accuracy: 0.9778 - val_loss: 0.9016 - val_accuracy: 0.6667\n",
      "Epoch 129/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0553 - accuracy: 0.96 - 0s 489us/step - loss: 0.0673 - accuracy: 0.9778 - val_loss: 0.9022 - val_accuracy: 0.6667\n",
      "Epoch 130/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0778 - accuracy: 0.96 - 0s 444us/step - loss: 0.0674 - accuracy: 0.9778 - val_loss: 0.9031 - val_accuracy: 0.6667\n",
      "Epoch 131/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.96 - 0s 422us/step - loss: 0.0672 - accuracy: 0.9778 - val_loss: 0.9035 - val_accuracy: 0.6667\n",
      "Epoch 132/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 1.00 - 0s 467us/step - loss: 0.0677 - accuracy: 0.9778 - val_loss: 0.9027 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 1.00 - 0s 467us/step - loss: 0.0658 - accuracy: 0.9778 - val_loss: 0.8999 - val_accuracy: 0.6667\n",
      "Epoch 134/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.96 - 0s 489us/step - loss: 0.0645 - accuracy: 0.9778 - val_loss: 0.8965 - val_accuracy: 0.6667\n",
      "Epoch 135/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.96 - 0s 533us/step - loss: 0.0646 - accuracy: 0.9778 - val_loss: 0.8942 - val_accuracy: 0.6667\n",
      "Epoch 136/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0761 - accuracy: 0.96 - 0s 489us/step - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.8933 - val_accuracy: 0.6667\n",
      "Epoch 137/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.96 - 0s 444us/step - loss: 0.0618 - accuracy: 0.9778 - val_loss: 0.8926 - val_accuracy: 0.6667\n",
      "Epoch 138/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.96 - 0s 444us/step - loss: 0.0612 - accuracy: 0.9778 - val_loss: 0.8920 - val_accuracy: 0.6667\n",
      "Epoch 139/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.96 - 0s 511us/step - loss: 0.0609 - accuracy: 0.9778 - val_loss: 0.8914 - val_accuracy: 0.6667\n",
      "Epoch 140/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0717 - accuracy: 0.96 - 0s 511us/step - loss: 0.0601 - accuracy: 0.9778 - val_loss: 0.8905 - val_accuracy: 0.6667\n",
      "Epoch 141/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.96 - 0s 622us/step - loss: 0.0598 - accuracy: 0.9778 - val_loss: 0.8897 - val_accuracy: 0.6667\n",
      "Epoch 142/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.96 - 0s 711us/step - loss: 0.0595 - accuracy: 0.9778 - val_loss: 0.8887 - val_accuracy: 0.6667\n",
      "Epoch 143/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 1.00 - 0s 644us/step - loss: 0.0590 - accuracy: 0.9778 - val_loss: 0.8872 - val_accuracy: 0.6667\n",
      "Epoch 144/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.96 - 0s 711us/step - loss: 0.0585 - accuracy: 0.9778 - val_loss: 0.8868 - val_accuracy: 0.6667\n",
      "Epoch 145/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0663 - accuracy: 0.96 - 0s 533us/step - loss: 0.0580 - accuracy: 0.9778 - val_loss: 0.8869 - val_accuracy: 0.6667\n",
      "Epoch 146/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 1.00 - 0s 600us/step - loss: 0.0576 - accuracy: 0.9778 - val_loss: 0.8874 - val_accuracy: 0.6667\n",
      "Epoch 147/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.00 - 0s 578us/step - loss: 0.0566 - accuracy: 0.9778 - val_loss: 0.8891 - val_accuracy: 0.6667\n",
      "Epoch 148/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.96 - 0s 467us/step - loss: 0.0559 - accuracy: 0.9778 - val_loss: 0.8906 - val_accuracy: 0.6667\n",
      "Epoch 149/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0503 - accuracy: 0.96 - 0s 489us/step - loss: 0.0564 - accuracy: 0.9556 - val_loss: 0.8913 - val_accuracy: 0.6667\n",
      "Epoch 150/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.96 - 0s 489us/step - loss: 0.0550 - accuracy: 0.9778 - val_loss: 0.8910 - val_accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = XX_train.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(units=YY_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 150\n",
    "batch_size =32\n",
    "history = model.fit(XX_train, YY_train, epochs=epochs, batch_size=batch_size, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060606060606061"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba=model.predict(XX_test)\n",
    "idx = np.argmax(pred_proba, axis=-1)\n",
    "YY_pred = np.zeros( pred_proba.shape )\n",
    "YY_pred[ np.arange(YY_pred.shape[0]), idx] = 1\n",
    "accuracy_score(YY_test, YY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_classif_theme.joblib']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model, 'model_classif_theme.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
