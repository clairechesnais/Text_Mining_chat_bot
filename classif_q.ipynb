{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification de la question**\n",
    "\n",
    "Lorsque l'agent reçoit une question, il devra décider si la question est réellement liée au domaine métier ou non. Si oui et si les données sont en plus regroupées par thématiques, une deuxième décision est à prendre : sur laquelle de ces thématiques porte la question.\n",
    "\n",
    "Si c'est une question métier, le chatbot retournera une réponse pertinente selon sa stratégie ; si non, il déclenchera la composante conversationnelle, qui produira une réponse originale.\n",
    "\n",
    "Il faut donc mettre en place une stratégie pour la prise de ces décisions et pour la sélection de la réponse.\n",
    "\n",
    "Quelle que soit l'approche il faudra d'abord :\n",
    "\n",
    "    prétraiter la base de données (à faire une seule fois et à stocker). Attention, si on vectorise le corpus il faudra garder le vectoriseur (l'enregistrer comme pickle) pour appliquer ensuite le même vectoriseur à la question ;\n",
    "    prétraiter la question (en temps réel).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prétraitement textuel de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lecture du fichier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reponse</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>Il est possible d’arriver n’importe quel jour ...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>Le classement par « birdies » évalue l’offre C...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>En réservant votre hébergement, vous bénéficie...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>Lors de la réservation de votre hébergement, v...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>Sur la page d'accueil de notre site, cliquez s...</td>\n",
       "      <td>Préparer mon séjour</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   Quels sont les jours d’arrivée ?   \n",
       "1  Comment évaluer le confort de mon domaine et d...   \n",
       "2  Quels sont les services et activités compris d...   \n",
       "3                   Comment réserver mes activités ?   \n",
       "4                    Où trouver le plan du domaine ?   \n",
       "\n",
       "                                             reponse                theme  \n",
       "0  Il est possible d’arriver n’importe quel jour ...  Préparer mon séjour  \n",
       "1  Le classement par « birdies » évalue l’offre C...  Préparer mon séjour  \n",
       "2  En réservant votre hébergement, vous bénéficie...  Préparer mon séjour  \n",
       "3  Lors de la réservation de votre hébergement, v...  Préparer mon séjour  \n",
       "4  Sur la page d'accueil de notre site, cliquez s...  Préparer mon séjour  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq = pd.read_pickle('faq_centerPark.pkl')\n",
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre jeu de données est composé de :\n",
    "- 54 lignes\n",
    "- 3 colonnes\n",
    "- 5 thèmes différents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On pose :\n",
    "- 1 = Préparer mon séjour\n",
    "- 2 = Réserver et payer\n",
    "- 3 = Gérer ma réservation\n",
    "- 4 = Mon séjour\n",
    "- 5 = Assurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_code_theme = {\"Préparer mon séjour\": 1,\n",
    "                  \"Réserver et payer\": 2,\n",
    "                  \"Gérer ma réservation\": 3,\n",
    "                  \"Mon séjour\": 4,\n",
    "                  \"Assurances\": 5}\n",
    "dic_decode_theme = {val: key for key, val in dic_code_theme.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_faq[\"theme\"].replace(dic_code_theme, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>reponse</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>Il est possible d’arriver n’importe quel jour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>Le classement par « birdies » évalue l’offre C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>En réservant votre hébergement, vous bénéficie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>Lors de la réservation de votre hébergement, v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>Sur la page d'accueil de notre site, cliquez s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                   Quels sont les jours d’arrivée ?   \n",
       "1  Comment évaluer le confort de mon domaine et d...   \n",
       "2  Quels sont les services et activités compris d...   \n",
       "3                   Comment réserver mes activités ?   \n",
       "4                    Où trouver le plan du domaine ?   \n",
       "\n",
       "                                             reponse  theme  \n",
       "0  Il est possible d’arriver n’importe quel jour ...      1  \n",
       "1  Le classement par « birdies » évalue l’offre C...      1  \n",
       "2  En réservant votre hébergement, vous bénéficie...      1  \n",
       "3  Lors de la réservation de votre hébergement, v...      1  \n",
       "4  Sur la page d'accueil de notre site, cliquez s...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_faq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enora\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_question = df_faq[['question', 'theme']]\n",
    "df_question.rename(columns={'question': 'texte', 'theme': 'theme'}, inplace=True)\n",
    "df_reponse = df_faq[['reponse', 'theme']]\n",
    "df_reponse.rename(columns={'reponse': 'texte', 'theme': 'theme'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_question, df_reponse])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>theme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quels sont les jours d’arrivée ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comment évaluer le confort de mon domaine et d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quels sont les services et activités compris d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comment réserver mes activités ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Où trouver le plan du domaine ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Puis-je venir avec mon animal domestique ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Peut-on accéder au domaine à la journée (sans ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Comment réserver un logement adapté aux person...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Comment recevoir la brochure ?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Est-il possible d'acheter des billets pour les...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Un visa ou un passeport est-il impératif pour ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Comment utiliser l’offre Early Booking avec le...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Y a-t-il un service bagagerie pour déposer mes...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Y'a-t-il des frais de dossier ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dois-je payer la totalité de mon séjour au mom...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ai-je un droit de rétractation ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Comment payer si je réserve mon séjour sur le ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Comment payer si je réserve mon séjour via le ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Puis-je adresser mon règlement par courrier ?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Comment puis-je payer si je ne réside pas en F...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                texte  theme\n",
       "0                    Quels sont les jours d’arrivée ?      1\n",
       "1   Comment évaluer le confort de mon domaine et d...      1\n",
       "2   Quels sont les services et activités compris d...      1\n",
       "3                    Comment réserver mes activités ?      1\n",
       "4                     Où trouver le plan du domaine ?      1\n",
       "5          Puis-je venir avec mon animal domestique ?      1\n",
       "6   Peut-on accéder au domaine à la journée (sans ...      1\n",
       "7   Comment réserver un logement adapté aux person...      1\n",
       "8                      Comment recevoir la brochure ?      1\n",
       "9   Est-il possible d'acheter des billets pour les...      1\n",
       "10  Un visa ou un passeport est-il impératif pour ...      1\n",
       "11  Comment utiliser l’offre Early Booking avec le...      1\n",
       "12  Y a-t-il un service bagagerie pour déposer mes...      1\n",
       "13                    Y'a-t-il des frais de dossier ?      2\n",
       "14  Dois-je payer la totalité de mon séjour au mom...      2\n",
       "15                   Ai-je un droit de rétractation ?      2\n",
       "16  Comment payer si je réserve mon séjour sur le ...      2\n",
       "17  Comment payer si je réserve mon séjour via le ...      2\n",
       "18      Puis-je adresser mon règlement par courrier ?      2\n",
       "19  Comment puis-je payer si je ne réside pas en F...      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "df_concat.to_pickle('df_concat.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Définition de fonctions pour le nettoyage du texte des tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# pour le nettoyage du texte\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# pour la classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.read_pickle('df_concat.pkl')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_concat['texte'],\n",
    "                                                    df_concat['theme'],\n",
    "                                                    train_size=0.7,\n",
    "                                                    random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('french')\n",
    "#tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) # tokenizer for tweet\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']\n",
    "sw.sort()\n",
    "\n",
    "def lemmatise_text(text):\n",
    "    lst_lematised = [token.lemma_ for token in nlp(text)] \n",
    "    return ' '.join(lst_lematised).lower()\n",
    "\n",
    "\n",
    "def stem_text(text):\n",
    "    #lst_stemmerised = [stemmer.stem(token) for token in tokenizer.tokenize(text)]    \n",
    "    lst_stemmerised = [stemmer.stem(token) for token in word_tokenize(text)]    \n",
    "    return ' '.join(lst_stemmerised)\n",
    "\n",
    "\n",
    "def replace_words_with_pos_tag(text):\n",
    "    lst_tags = [token.pos_ for token in nlp(text)]    \n",
    "    return ' '.join(lst_tags)\n",
    "\n",
    "\n",
    "def ner(text): #entites nommees\n",
    "    dico_remplacement = {entite_nommee.text : entite_nommee.label_ for entite_nommee in nlp(text).ents}\n",
    "    for entite_nommee, remplacement in dico_remplacement.items():\n",
    "        text = text.replace(entite_nommee, remplacement)\n",
    "    return text\n",
    "\n",
    "\n",
    "def substitute_punctuation(text):\n",
    "    return ' '.join(text.replace(\"'\", ' ').translate(str.maketrans('', '', string.punctuation)).split())\n",
    "\n",
    "\n",
    "def substitute_number(text, url_replacement=''):\n",
    "    return re.sub(r\"\\d\", url_replacement, text)\n",
    "\n",
    "\n",
    "def supp(text):\n",
    "    return text.replace(\"«\", \"\").replace(\"’\", \"\").replace(\"•\", \"\").replace(\"®\", \"\")\n",
    "\n",
    "\n",
    "def supprime_accent(txt):\n",
    "    return unidecode.unidecode(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Nettoyage du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Nettoyage "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On combine quelques fonctions définies en partie A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = (X_train.apply(lemmatise_text)\n",
    "                        .apply(stem_text)\n",
    "                        .apply(substitute_punctuation)\n",
<<<<<<< HEAD
    "                        .apply(supprime_accent)\n",
=======
    "                        #.apply(supprime_accent)\n",
>>>>>>> enora
    "#                         .apply(substitute_number)\n",
    "                         .apply(supp)\n",
    "                )\n",
    "X_test_clean = (X_test.apply(lemmatise_text)\n",
    "                       .apply(stem_text)\n",
    "                       .apply(substitute_punctuation)\n",
<<<<<<< HEAD
    "                       .apply(supprime_accent)\n",
=======
    "                      # .apply(supprime_accent)\n",
>>>>>>> enora
    "#                        .apply(substitute_number)\n",
    "                        .apply(supp)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test de différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons tester différents modèles sur le texte des tweets qui ont été nettoyés dans la partie 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Les différents vectoriseurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriseur numérique discret\n",
    "\n",
    "vect_count = CountVectorizer(binary=False)\n",
    "vect_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_count = vect_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_count = vect_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectoriseur binaire\n",
    "\n",
    "bin_count = CountVectorizer(binary=True)\n",
    "bin_count.fit(X_train_clean)\n",
    "X_train_clean_vectorized_bin = vect_count.transform(X_train_clean)\n",
    "X_test_clean_vectorized_bin = vect_count.transform(X_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_classif_theme.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vectoriseur numérique continu : TF-IDF\n",
    "\n",
    "vect_tfidf = TfidfVectorizer(stop_words=sw)\n",
    "vect_tfidf.fit(X_train_clean)\n",
    "X_train_clean_vectorized_tfidf = vect_tfidf.transform(X_train_clean)\n",
    "X_test_clean_vectorized_tfidf = vect_tfidf.transform(X_test_clean) \n",
    "\n",
    "## export vectoriser\n",
    "from joblib import dump\n",
    "dump(vect_tfidf, 'vectorizer_classif_theme.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Les différents modèles\n",
    "\n",
    "Nous entraînerons des modèles de classification appartenant à quelques familles d'algorithmes d'apprentissage automatique classique. L'objectif est de comparer non seulement les performances des différentes méthodes entre elles, mais aussi la performance d'une même méthode sur des représentations différentes du texte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b.1 DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='most_frequent').fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = random_uniform.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_prop_class = DummyClassifier(strategy='most_frequent').fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "pred = random_prop_class.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b.2 Classifieur naïf bayesien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5757575757575758"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_classif_theme.joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.3 Complement NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 86,
=======
   "execution_count": 75,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.5757575757575758"
      ]
     },
     "execution_count": 86,
=======
       "0.5526315789473685"
      ]
     },
     "execution_count": 75,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 87,
=======
   "execution_count": 76,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.5757575757575758"
      ]
     },
     "execution_count": 87,
=======
       "0.5526315789473685"
      ]
     },
     "execution_count": 76,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 88,
=======
   "execution_count": 90,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6578947368421053"
      ]
     },
<<<<<<< HEAD
     "execution_count": 88,
=======
     "execution_count": 90,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comp = ComplementNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_comp.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 2, 1, 1, 2, 4, 4, 1, 2, 2, 2, 1, 1, 2, 1, 5, 4, 4, 4, 1,\n",
       "       2, 5, 4, 3, 2, 4, 1, 4, 1, 4, 2, 2, 2, 1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.4 BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 43,
=======
   "execution_count": 31,
>>>>>>> enora
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 89,
=======
   "execution_count": 78,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4473684210526316"
      ]
     },
<<<<<<< HEAD
     "execution_count": 89,
=======
     "execution_count": 78,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 90,
=======
   "execution_count": 79,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4473684210526316"
      ]
     },
<<<<<<< HEAD
     "execution_count": 90,
=======
     "execution_count": 79,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 91,
=======
   "execution_count": 80,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42105263157894735"
      ]
     },
<<<<<<< HEAD
     "execution_count": 91,
=======
     "execution_count": 80,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bern = BernoulliNB().fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_bern.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.5 RandomForestClassifier/LinearSVC"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 92,
=======
   "execution_count": 81,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enora\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'RandomForestClassifier': 0.48484848484848486, 'LinearSVC': 0.36363636363636365}\n"
=======
      "{'RandomForestClassifier': 0.47368421052631576, 'LinearSVC': 0.39473684210526316}\n"
>>>>>>> enora
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=500, max_depth=100, random_state=0),\n",
    "    LinearSVC()\n",
    "]\n",
    "\n",
    "dic_acc = {}\n",
    "\n",
    "for model in models:\n",
    "    model_name = model.__class__.__name__\n",
    "    predictions_valid = model.fit(X_train_clean_vectorized_count, y_train).predict(X_test_clean_vectorized_count)\n",
    "    dic_acc[model_name] = accuracy_score(y_test, predictions_valid)\n",
    "\n",
    "print(dic_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.6 KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
=======
   "execution_count": 36,
>>>>>>> enora
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 93,
=======
   "execution_count": 82,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15789473684210525"
      ]
     },
<<<<<<< HEAD
     "execution_count": 93,
=======
     "execution_count": 82,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 94,
=======
   "execution_count": 83,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15789473684210525"
      ]
     },
<<<<<<< HEAD
     "execution_count": 94,
=======
     "execution_count": 83,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 95,
=======
   "execution_count": 84,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5526315789473685"
      ]
     },
<<<<<<< HEAD
     "execution_count": 95,
=======
     "execution_count": 84,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(5).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_knn.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.7. SVM"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
=======
   "execution_count": 40,
>>>>>>> enora
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 96,
=======
   "execution_count": 85,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.42424242424242425"
      ]
     },
     "execution_count": 96,
=======
       "0.47368421052631576"
      ]
     },
     "execution_count": 85,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.9).fit(X_train_clean_vectorized_count, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_count)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 98,
=======
   "execution_count": 86,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
<<<<<<< HEAD
     "execution_count": 98,
=======
     "execution_count": 86,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.1).fit(X_train_clean_vectorized_bin, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_bin)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 99,
=======
   "execution_count": 87,
>>>>>>> enora
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2894736842105263"
      ]
     },
<<<<<<< HEAD
     "execution_count": 99,
=======
     "execution_count": 87,
>>>>>>> enora
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', C=0.1).fit(X_train_clean_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_svm.predict(X_test_clean_vectorized_tfidf)\n",
    "accuracy_score(y_test, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.8 Réseaux de neurones de convolution"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 100,
=======
   "execution_count": 30,
>>>>>>> enora
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, SpatialDropout1D, MaxPooling1D, Conv1D, Flatten, MaxPooling2D, Conv2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 101,
=======
   "execution_count": 31,
>>>>>>> enora
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_train = X_train_clean_vectorized_tfidf.toarray().reshape(X_train_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_train_clean_vectorized_tfidf.shape[1])\n",
    "XX_test = X_test_clean_vectorized_tfidf.toarray().reshape(X_test_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_test_clean_vectorized_tfidf.shape[1])\n",
    "YY_train = pd.get_dummies(y_train)\n",
    "YY_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 102,
=======
   "execution_count": 70,
>>>>>>> enora
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Train on 52 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 8.0583 - accuracy: 0.0000e+00 - val_loss: 5.9808 - val_accuracy: 0.0435\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 6.7330 - accuracy: 0.0385 - val_loss: 5.0590 - val_accuracy: 0.0870\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 5.8343 - accuracy: 0.1731 - val_loss: 4.2685 - val_accuracy: 0.2174\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.5002 - accuracy: 0.2885 - val_loss: 3.8385 - val_accuracy: 0.2174\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.6833 - accuracy: 0.3462 - val_loss: 3.1776 - val_accuracy: 0.2609\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.7920 - accuracy: 0.3846 - val_loss: 2.9163 - val_accuracy: 0.3043\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.3378 - accuracy: 0.3462 - val_loss: 2.3512 - val_accuracy: 0.3478\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 2.1219 - accuracy: 0.4038 - val_loss: 2.2403 - val_accuracy: 0.3043\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.8121 - accuracy: 0.4038 - val_loss: 2.1562 - val_accuracy: 0.3478\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.7250 - accuracy: 0.4423 - val_loss: 1.7299 - val_accuracy: 0.3478\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.6769 - accuracy: 0.4423 - val_loss: 1.6204 - val_accuracy: 0.3043\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.6474 - accuracy: 0.4423 - val_loss: 1.5764 - val_accuracy: 0.3043\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.6300 - accuracy: 0.4615 - val_loss: 1.5504 - val_accuracy: 0.3043\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.6190 - accuracy: 0.5000 - val_loss: 1.5309 - val_accuracy: 0.3478\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.6096 - accuracy: 0.4615 - val_loss: 1.5175 - val_accuracy: 0.3043\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 346us/step - loss: 1.6018 - accuracy: 0.4808 - val_loss: 1.5071 - val_accuracy: 0.3478\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.5938 - accuracy: 0.4808 - val_loss: 1.4969 - val_accuracy: 0.3478\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.5856 - accuracy: 0.5000 - val_loss: 1.4867 - val_accuracy: 0.3913\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.5774 - accuracy: 0.4615 - val_loss: 1.4774 - val_accuracy: 0.4348\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.5682 - accuracy: 0.4615 - val_loss: 1.4687 - val_accuracy: 0.4783\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.5577 - accuracy: 0.4615 - val_loss: 1.4606 - val_accuracy: 0.4783\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.5465 - accuracy: 0.5000 - val_loss: 1.4530 - val_accuracy: 0.4348\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.5349 - accuracy: 0.5385 - val_loss: 1.4459 - val_accuracy: 0.4348\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.5227 - accuracy: 0.5769 - val_loss: 1.4392 - val_accuracy: 0.3478\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 346us/step - loss: 1.5105 - accuracy: 0.5769 - val_loss: 1.4331 - val_accuracy: 0.3478\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.4980 - accuracy: 0.6154 - val_loss: 1.4271 - val_accuracy: 0.3478\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.4853 - accuracy: 0.6346 - val_loss: 1.4216 - val_accuracy: 0.3043\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4720 - accuracy: 0.6346 - val_loss: 1.4164 - val_accuracy: 0.3043\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.4582 - accuracy: 0.6346 - val_loss: 1.4107 - val_accuracy: 0.3043\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.4439 - accuracy: 0.6346 - val_loss: 1.4059 - val_accuracy: 0.3043\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.4290 - accuracy: 0.6346 - val_loss: 1.4020 - val_accuracy: 0.3043\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4142 - accuracy: 0.6346 - val_loss: 1.3988 - val_accuracy: 0.3043\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.3996 - accuracy: 0.6346 - val_loss: 1.3951 - val_accuracy: 0.3043\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3849 - accuracy: 0.6154 - val_loss: 1.3908 - val_accuracy: 0.3478\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 385us/step - loss: 1.3698 - accuracy: 0.6154 - val_loss: 1.3858 - val_accuracy: 0.3913\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.3542 - accuracy: 0.6154 - val_loss: 1.3813 - val_accuracy: 0.3913\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3390 - accuracy: 0.6346 - val_loss: 1.3775 - val_accuracy: 0.3913\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3233 - accuracy: 0.6538 - val_loss: 1.3741 - val_accuracy: 0.3913\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.3075 - accuracy: 0.6538 - val_loss: 1.3709 - val_accuracy: 0.3913\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.2906 - accuracy: 0.6538 - val_loss: 1.3680 - val_accuracy: 0.3913\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.2737 - accuracy: 0.6538 - val_loss: 1.3653 - val_accuracy: 0.3913\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 1.2562 - accuracy: 0.6538 - val_loss: 1.3632 - val_accuracy: 0.3913\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 1.2372 - accuracy: 0.6538 - val_loss: 1.3626 - val_accuracy: 0.3913\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.2170 - accuracy: 0.6923 - val_loss: 1.3628 - val_accuracy: 0.3913\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1958 - accuracy: 0.6923 - val_loss: 1.3645 - val_accuracy: 0.3913\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.1739 - accuracy: 0.6923 - val_loss: 1.3679 - val_accuracy: 0.3913\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.1519 - accuracy: 0.6923 - val_loss: 1.3728 - val_accuracy: 0.3913\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.1291 - accuracy: 0.6923 - val_loss: 1.3785 - val_accuracy: 0.3913\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1058 - accuracy: 0.6923 - val_loss: 1.3853 - val_accuracy: 0.3913\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.0812 - accuracy: 0.6923 - val_loss: 1.3977 - val_accuracy: 0.3913\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.0540 - accuracy: 0.6923 - val_loss: 1.4225 - val_accuracy: 0.3913\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.0256 - accuracy: 0.7115 - val_loss: 1.7771 - val_accuracy: 0.3913\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.9977 - accuracy: 0.7115 - val_loss: 1.7712 - val_accuracy: 0.3913\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.9695 - accuracy: 0.7308 - val_loss: 1.7666 - val_accuracy: 0.3913\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.9401 - accuracy: 0.7308 - val_loss: 1.7652 - val_accuracy: 0.3913\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.9099 - accuracy: 0.7308 - val_loss: 1.7664 - val_accuracy: 0.3913\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7554 - accuracy: 0.7308 - val_loss: 1.8624 - val_accuracy: 0.3913\n"
=======
      "Train on 45 samples, validate on 30 samples\n",
      "Epoch 1/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5938 - accuracy: 0.25 - 0s 6ms/step - loss: 1.5965 - accuracy: 0.2000 - val_loss: 1.6026 - val_accuracy: 0.3000\n",
      "Epoch 2/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5864 - accuracy: 0.34 - 0s 533us/step - loss: 1.5859 - accuracy: 0.3111 - val_loss: 1.6000 - val_accuracy: 0.3000\n",
      "Epoch 3/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5740 - accuracy: 0.50 - 0s 600us/step - loss: 1.5758 - accuracy: 0.4889 - val_loss: 1.5978 - val_accuracy: 0.3333\n",
      "Epoch 4/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5646 - accuracy: 0.59 - 0s 422us/step - loss: 1.5656 - accuracy: 0.5333 - val_loss: 1.5958 - val_accuracy: 0.3333\n",
      "Epoch 5/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5505 - accuracy: 0.65 - 0s 555us/step - loss: 1.5561 - accuracy: 0.5556 - val_loss: 1.5937 - val_accuracy: 0.3333\n",
      "Epoch 6/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5488 - accuracy: 0.53 - 0s 667us/step - loss: 1.5458 - accuracy: 0.5556 - val_loss: 1.5914 - val_accuracy: 0.4000\n",
      "Epoch 7/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5391 - accuracy: 0.56 - 0s 533us/step - loss: 1.5356 - accuracy: 0.5778 - val_loss: 1.5886 - val_accuracy: 0.4000\n",
      "Epoch 8/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5333 - accuracy: 0.53 - 0s 511us/step - loss: 1.5245 - accuracy: 0.6000 - val_loss: 1.5855 - val_accuracy: 0.4000\n",
      "Epoch 9/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.5079 - accuracy: 0.62 - 0s 644us/step - loss: 1.5137 - accuracy: 0.6000 - val_loss: 1.5823 - val_accuracy: 0.3667\n",
      "Epoch 10/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4932 - accuracy: 0.68 - 0s 689us/step - loss: 1.5023 - accuracy: 0.6000 - val_loss: 1.5790 - val_accuracy: 0.3667\n",
      "Epoch 11/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4887 - accuracy: 0.62 - 0s 422us/step - loss: 1.4898 - accuracy: 0.6000 - val_loss: 1.5752 - val_accuracy: 0.3667\n",
      "Epoch 12/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4885 - accuracy: 0.50 - 0s 578us/step - loss: 1.4769 - accuracy: 0.6000 - val_loss: 1.5712 - val_accuracy: 0.3667\n",
      "Epoch 13/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4598 - accuracy: 0.53 - 0s 578us/step - loss: 1.4640 - accuracy: 0.6000 - val_loss: 1.5670 - val_accuracy: 0.3667\n",
      "Epoch 14/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4428 - accuracy: 0.62 - 0s 422us/step - loss: 1.4503 - accuracy: 0.6222 - val_loss: 1.5626 - val_accuracy: 0.3667\n",
      "Epoch 15/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4401 - accuracy: 0.62 - 0s 489us/step - loss: 1.4358 - accuracy: 0.6222 - val_loss: 1.5579 - val_accuracy: 0.3667\n",
      "Epoch 16/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.4608 - accuracy: 0.53 - 0s 467us/step - loss: 1.4197 - accuracy: 0.6222 - val_loss: 1.5530 - val_accuracy: 0.3667\n",
      "Epoch 17/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3942 - accuracy: 0.62 - 0s 511us/step - loss: 1.4057 - accuracy: 0.6222 - val_loss: 1.5479 - val_accuracy: 0.3667\n",
      "Epoch 18/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3596 - accuracy: 0.71 - 0s 467us/step - loss: 1.3903 - accuracy: 0.6222 - val_loss: 1.5426 - val_accuracy: 0.3667\n",
      "Epoch 19/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3848 - accuracy: 0.62 - 0s 644us/step - loss: 1.3728 - accuracy: 0.6222 - val_loss: 1.5366 - val_accuracy: 0.3667\n",
      "Epoch 20/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3841 - accuracy: 0.59 - 0s 489us/step - loss: 1.3555 - accuracy: 0.6222 - val_loss: 1.5299 - val_accuracy: 0.3667\n",
      "Epoch 21/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3494 - accuracy: 0.62 - 0s 578us/step - loss: 1.3383 - accuracy: 0.6222 - val_loss: 1.5231 - val_accuracy: 0.3667\n",
      "Epoch 22/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3067 - accuracy: 0.59 - 0s 555us/step - loss: 1.3203 - accuracy: 0.6222 - val_loss: 1.5166 - val_accuracy: 0.3667\n",
      "Epoch 23/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.3101 - accuracy: 0.59 - 0s 622us/step - loss: 1.3014 - accuracy: 0.6222 - val_loss: 1.5103 - val_accuracy: 0.3667\n",
      "Epoch 24/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2740 - accuracy: 0.68 - 0s 556us/step - loss: 1.2823 - accuracy: 0.6222 - val_loss: 1.5039 - val_accuracy: 0.3667\n",
      "Epoch 25/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2433 - accuracy: 0.65 - 0s 467us/step - loss: 1.2625 - accuracy: 0.6222 - val_loss: 1.4972 - val_accuracy: 0.3667\n",
      "Epoch 26/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2640 - accuracy: 0.62 - 0s 489us/step - loss: 1.2409 - accuracy: 0.6222 - val_loss: 1.4908 - val_accuracy: 0.3667\n",
      "Epoch 27/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2231 - accuracy: 0.65 - 0s 444us/step - loss: 1.2206 - accuracy: 0.6222 - val_loss: 1.4841 - val_accuracy: 0.3667\n",
      "Epoch 28/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2346 - accuracy: 0.59 - 0s 511us/step - loss: 1.1989 - accuracy: 0.6222 - val_loss: 1.4773 - val_accuracy: 0.3667\n",
      "Epoch 29/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1961 - accuracy: 0.65 - 0s 533us/step - loss: 1.1773 - accuracy: 0.6667 - val_loss: 1.4704 - val_accuracy: 0.3667\n",
      "Epoch 30/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.2311 - accuracy: 0.59 - 0s 578us/step - loss: 1.1545 - accuracy: 0.6667 - val_loss: 1.4637 - val_accuracy: 0.4000\n",
      "Epoch 31/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1344 - accuracy: 0.65 - 0s 578us/step - loss: 1.1329 - accuracy: 0.6667 - val_loss: 1.4569 - val_accuracy: 0.4000\n",
      "Epoch 32/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.1695 - accuracy: 0.71 - 0s 689us/step - loss: 1.1096 - accuracy: 0.7111 - val_loss: 1.4498 - val_accuracy: 0.4000\n",
      "Epoch 33/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.75 - 0s 422us/step - loss: 1.0876 - accuracy: 0.7111 - val_loss: 1.4430 - val_accuracy: 0.4667\n",
      "Epoch 34/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0625 - accuracy: 0.71 - 0s 578us/step - loss: 1.0646 - accuracy: 0.7333 - val_loss: 1.4352 - val_accuracy: 0.4667\n",
      "Epoch 35/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0812 - accuracy: 0.71 - 0s 489us/step - loss: 1.0421 - accuracy: 0.7556 - val_loss: 1.4270 - val_accuracy: 0.4667\n",
      "Epoch 36/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.9695 - accuracy: 0.81 - 0s 578us/step - loss: 1.0196 - accuracy: 0.7556 - val_loss: 1.4188 - val_accuracy: 0.4667\n",
      "Epoch 37/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0146 - accuracy: 0.75 - 0s 711us/step - loss: 0.9964 - accuracy: 0.7556 - val_loss: 1.4102 - val_accuracy: 0.4667\n",
      "Epoch 38/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 1.0403 - accuracy: 0.75 - 0s 467us/step - loss: 0.9729 - accuracy: 0.8000 - val_loss: 1.4020 - val_accuracy: 0.4667\n",
      "Epoch 39/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8934 - accuracy: 0.87 - 0s 578us/step - loss: 0.9510 - accuracy: 0.8222 - val_loss: 1.3937 - val_accuracy: 0.4667\n",
      "Epoch 40/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8737 - accuracy: 0.87 - 0s 555us/step - loss: 0.9274 - accuracy: 0.8444 - val_loss: 1.3847 - val_accuracy: 0.5000\n",
      "Epoch 41/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8485 - accuracy: 0.81 - 0s 555us/step - loss: 0.9038 - accuracy: 0.8444 - val_loss: 1.3761 - val_accuracy: 0.5000\n",
      "Epoch 42/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8852 - accuracy: 0.81 - 0s 711us/step - loss: 0.8808 - accuracy: 0.8444 - val_loss: 1.3678 - val_accuracy: 0.5000\n",
      "Epoch 43/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8584 - accuracy: 0.84 - 0s 467us/step - loss: 0.8583 - accuracy: 0.8667 - val_loss: 1.3592 - val_accuracy: 0.5000\n",
      "Epoch 44/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8609 - accuracy: 0.84 - 0s 622us/step - loss: 0.8349 - accuracy: 0.8667 - val_loss: 1.3517 - val_accuracy: 0.5000\n"
>>>>>>> enora
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 58/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6709 - accuracy: 0.7500 - val_loss: 2.3068 - val_accuracy: 0.3913\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6583 - accuracy: 0.7692 - val_loss: 2.4908 - val_accuracy: 0.3913\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 0.6497 - accuracy: 0.8077 - val_loss: 2.8281 - val_accuracy: 0.3478\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6420 - accuracy: 0.8077 - val_loss: 3.2387 - val_accuracy: 0.3478\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6321 - accuracy: 0.8462 - val_loss: 3.3013 - val_accuracy: 0.3043\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6215 - accuracy: 0.8269 - val_loss: 3.7086 - val_accuracy: 0.3043\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.6087 - accuracy: 0.8269 - val_loss: 3.7345 - val_accuracy: 0.2609\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.5947 - accuracy: 0.8654 - val_loss: 3.7473 - val_accuracy: 0.3478\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.5782 - accuracy: 0.8462 - val_loss: 3.7580 - val_accuracy: 0.3478\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.5607 - accuracy: 0.8654 - val_loss: 3.8023 - val_accuracy: 0.3478\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.5409 - accuracy: 0.8654 - val_loss: 3.9768 - val_accuracy: 0.3478\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.5193 - accuracy: 0.8846 - val_loss: 4.4173 - val_accuracy: 0.3478\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.4950 - accuracy: 0.8462 - val_loss: 4.3471 - val_accuracy: 0.3043\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.4666 - accuracy: 0.8462 - val_loss: 4.0976 - val_accuracy: 0.3043\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.4310 - accuracy: 0.8846 - val_loss: 3.9011 - val_accuracy: 0.3043\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.3975 - accuracy: 0.8846 - val_loss: 3.8568 - val_accuracy: 0.3043\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.3578 - accuracy: 0.8846 - val_loss: 3.8411 - val_accuracy: 0.3043\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.3336 - accuracy: 0.8846 - val_loss: 4.3346 - val_accuracy: 0.2609\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.3177 - accuracy: 0.8846 - val_loss: 4.2978 - val_accuracy: 0.2609\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.3013 - accuracy: 0.8846 - val_loss: 4.3385 - val_accuracy: 0.2609\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.2855 - accuracy: 0.8846 - val_loss: 4.5384 - val_accuracy: 0.3043\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.2570 - accuracy: 0.8846 - val_loss: 4.3200 - val_accuracy: 0.3043\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.4116 - accuracy: 0.9038 - val_loss: 4.9286 - val_accuracy: 0.3043\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.2420 - accuracy: 0.9038 - val_loss: 5.1521 - val_accuracy: 0.3043\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.2179 - accuracy: 0.9038 - val_loss: 5.0771 - val_accuracy: 0.3043\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.2041 - accuracy: 0.9038 - val_loss: 4.8892 - val_accuracy: 0.2609\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1986 - accuracy: 0.8846 - val_loss: 5.0351 - val_accuracy: 0.2609\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.1966 - accuracy: 0.8846 - val_loss: 5.3155 - val_accuracy: 0.2609\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1952 - accuracy: 0.8846 - val_loss: 5.3833 - val_accuracy: 0.2609\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.1928 - accuracy: 0.8654 - val_loss: 5.1648 - val_accuracy: 0.2609\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.1853 - accuracy: 0.8846 - val_loss: 5.0696 - val_accuracy: 0.2609\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1766 - accuracy: 0.8846 - val_loss: 4.7685 - val_accuracy: 0.2609\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.1739 - accuracy: 0.9038 - val_loss: 4.6489 - val_accuracy: 0.2609\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1676 - accuracy: 0.9231 - val_loss: 4.5714 - val_accuracy: 0.2609\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1601 - accuracy: 0.9231 - val_loss: 4.4420 - val_accuracy: 0.2609\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1498 - accuracy: 0.9231 - val_loss: 4.2981 - val_accuracy: 0.2609\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.1439 - accuracy: 0.9231 - val_loss: 4.5066 - val_accuracy: 0.2609\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.2165 - accuracy: 0.9231 - val_loss: 4.5048 - val_accuracy: 0.2609\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.2050 - accuracy: 0.9231 - val_loss: 4.5100 - val_accuracy: 0.2609\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1983 - accuracy: 0.9231 - val_loss: 4.4265 - val_accuracy: 0.2609\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1888 - accuracy: 0.9231 - val_loss: 4.4279 - val_accuracy: 0.2609\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.1885 - accuracy: 0.9231 - val_loss: 4.6498 - val_accuracy: 0.2609\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.1849 - accuracy: 0.9423 - val_loss: 4.6452 - val_accuracy: 0.2609\n"
=======
      "Epoch 45/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7513 - accuracy: 0.90 - 0s 467us/step - loss: 0.8121 - accuracy: 0.8889 - val_loss: 1.3440 - val_accuracy: 0.5333\n",
      "Epoch 46/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7899 - accuracy: 0.87 - 0s 511us/step - loss: 0.7891 - accuracy: 0.8889 - val_loss: 1.3353 - val_accuracy: 0.5000\n",
      "Epoch 47/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8598 - accuracy: 0.87 - 0s 467us/step - loss: 0.7671 - accuracy: 0.8889 - val_loss: 1.3264 - val_accuracy: 0.5000\n",
      "Epoch 48/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7804 - accuracy: 0.87 - 0s 533us/step - loss: 0.7445 - accuracy: 0.8889 - val_loss: 1.3164 - val_accuracy: 0.5000\n",
      "Epoch 49/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7218 - accuracy: 0.87 - 0s 556us/step - loss: 0.7227 - accuracy: 0.8889 - val_loss: 1.3065 - val_accuracy: 0.5000\n",
      "Epoch 50/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.7282 - accuracy: 0.90 - 0s 534us/step - loss: 0.7020 - accuracy: 0.8889 - val_loss: 1.2966 - val_accuracy: 0.5000\n",
      "Epoch 51/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.87 - 0s 667us/step - loss: 0.6807 - accuracy: 0.8889 - val_loss: 1.2879 - val_accuracy: 0.5000\n",
      "Epoch 52/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6242 - accuracy: 0.90 - 0s 467us/step - loss: 0.6602 - accuracy: 0.8889 - val_loss: 1.2806 - val_accuracy: 0.5000\n",
      "Epoch 53/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6464 - accuracy: 0.84 - 0s 467us/step - loss: 0.6399 - accuracy: 0.8889 - val_loss: 1.2733 - val_accuracy: 0.5333\n",
      "Epoch 54/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5936 - accuracy: 0.90 - 0s 733us/step - loss: 0.6210 - accuracy: 0.8889 - val_loss: 1.2649 - val_accuracy: 0.5333\n",
      "Epoch 55/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6236 - accuracy: 0.90 - 0s 578us/step - loss: 0.6022 - accuracy: 0.8889 - val_loss: 1.2565 - val_accuracy: 0.5333\n",
      "Epoch 56/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.6535 - accuracy: 0.87 - 0s 444us/step - loss: 0.5838 - accuracy: 0.8889 - val_loss: 1.2468 - val_accuracy: 0.5667\n",
      "Epoch 57/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.87 - 0s 800us/step - loss: 0.5656 - accuracy: 0.8889 - val_loss: 1.2379 - val_accuracy: 0.5667\n",
      "Epoch 58/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5476 - accuracy: 0.90 - 0s 467us/step - loss: 0.5491 - accuracy: 0.8889 - val_loss: 1.2304 - val_accuracy: 0.5667\n",
      "Epoch 59/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5206 - accuracy: 0.90 - 0s 489us/step - loss: 0.5321 - accuracy: 0.8889 - val_loss: 1.2240 - val_accuracy: 0.5667\n",
      "Epoch 60/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5861 - accuracy: 0.84 - 0s 533us/step - loss: 0.5162 - accuracy: 0.8889 - val_loss: 1.2184 - val_accuracy: 0.5667\n",
      "Epoch 61/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.90 - 0s 711us/step - loss: 0.5003 - accuracy: 0.8889 - val_loss: 1.2121 - val_accuracy: 0.5667\n",
      "Epoch 62/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4417 - accuracy: 0.93 - 0s 600us/step - loss: 0.4855 - accuracy: 0.8889 - val_loss: 1.2048 - val_accuracy: 0.5667\n",
      "Epoch 63/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4568 - accuracy: 0.87 - 0s 1ms/step - loss: 0.4708 - accuracy: 0.8889 - val_loss: 1.1976 - val_accuracy: 0.5667\n",
      "Epoch 64/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4064 - accuracy: 0.93 - 0s 511us/step - loss: 0.4571 - accuracy: 0.8889 - val_loss: 1.1911 - val_accuracy: 0.5667\n",
      "Epoch 65/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.87 - 0s 622us/step - loss: 0.4439 - accuracy: 0.8889 - val_loss: 1.1861 - val_accuracy: 0.5667\n",
      "Epoch 66/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4055 - accuracy: 0.93 - 0s 622us/step - loss: 0.4305 - accuracy: 0.8889 - val_loss: 1.1821 - val_accuracy: 0.5667\n",
      "Epoch 67/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.87 - 0s 755us/step - loss: 0.4179 - accuracy: 0.8889 - val_loss: 1.1785 - val_accuracy: 0.5667\n",
      "Epoch 68/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3855 - accuracy: 0.90 - 0s 622us/step - loss: 0.4058 - accuracy: 0.8889 - val_loss: 1.1743 - val_accuracy: 0.5667\n",
      "Epoch 69/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2953 - accuracy: 0.96 - 0s 623us/step - loss: 0.3944 - accuracy: 0.8889 - val_loss: 1.1691 - val_accuracy: 0.5667\n",
      "Epoch 70/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3788 - accuracy: 0.90 - 0s 578us/step - loss: 0.3834 - accuracy: 0.8889 - val_loss: 1.1628 - val_accuracy: 0.6000\n",
      "Epoch 71/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.90 - 0s 600us/step - loss: 0.3723 - accuracy: 0.8889 - val_loss: 1.1569 - val_accuracy: 0.6000\n",
      "Epoch 72/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.4610 - accuracy: 0.84 - 0s 667us/step - loss: 0.3620 - accuracy: 0.8889 - val_loss: 1.1513 - val_accuracy: 0.6000\n",
      "Epoch 73/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.96 - 0s 444us/step - loss: 0.3515 - accuracy: 0.8889 - val_loss: 1.1462 - val_accuracy: 0.6000\n",
      "Epoch 74/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3965 - accuracy: 0.87 - 0s 489us/step - loss: 0.3423 - accuracy: 0.9111 - val_loss: 1.1411 - val_accuracy: 0.6333\n",
      "Epoch 75/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3209 - accuracy: 0.90 - 0s 467us/step - loss: 0.3326 - accuracy: 0.9111 - val_loss: 1.1364 - val_accuracy: 0.6333\n",
      "Epoch 76/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3902 - accuracy: 0.87 - 0s 422us/step - loss: 0.3241 - accuracy: 0.9111 - val_loss: 1.1319 - val_accuracy: 0.6333\n",
      "Epoch 77/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.90 - 0s 467us/step - loss: 0.3155 - accuracy: 0.9111 - val_loss: 1.1270 - val_accuracy: 0.6333\n",
      "Epoch 78/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.93 - 0s 467us/step - loss: 0.3070 - accuracy: 0.9111 - val_loss: 1.1231 - val_accuracy: 0.6333\n",
      "Epoch 79/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.93 - 0s 444us/step - loss: 0.2988 - accuracy: 0.9333 - val_loss: 1.1195 - val_accuracy: 0.6333\n",
      "Epoch 80/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.90 - 0s 622us/step - loss: 0.2910 - accuracy: 0.9333 - val_loss: 1.1138 - val_accuracy: 0.6667\n",
      "Epoch 81/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.96 - 0s 533us/step - loss: 0.2836 - accuracy: 0.9333 - val_loss: 1.1083 - val_accuracy: 0.6667\n",
      "Epoch 82/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.96 - 0s 622us/step - loss: 0.2760 - accuracy: 0.9556 - val_loss: 1.1032 - val_accuracy: 0.6667\n",
      "Epoch 83/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1961 - accuracy: 1.00 - 0s 534us/step - loss: 0.2684 - accuracy: 0.9778 - val_loss: 1.0984 - val_accuracy: 0.6667\n",
      "Epoch 84/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2581 - accuracy: 0.96 - 0s 578us/step - loss: 0.2612 - accuracy: 0.9778 - val_loss: 1.0940 - val_accuracy: 0.6667\n",
      "Epoch 85/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.96 - 0s 733us/step - loss: 0.2545 - accuracy: 0.9778 - val_loss: 1.0910 - val_accuracy: 0.6667\n",
      "Epoch 86/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1943 - accuracy: 1.00 - 0s 622us/step - loss: 0.2470 - accuracy: 0.9778 - val_loss: 1.0885 - val_accuracy: 0.6667\n",
      "Epoch 87/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.96 - 0s 644us/step - loss: 0.2408 - accuracy: 0.9778 - val_loss: 1.0859 - val_accuracy: 0.6667\n",
      "Epoch 88/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2369 - accuracy: 0.96 - 0s 511us/step - loss: 0.2340 - accuracy: 0.9778 - val_loss: 1.0840 - val_accuracy: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.96 - 0s 600us/step - loss: 0.2277 - accuracy: 0.9778 - val_loss: 1.0816 - val_accuracy: 0.6333\n",
      "Epoch 90/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1918 - accuracy: 0.96 - 0s 622us/step - loss: 0.2215 - accuracy: 0.9778 - val_loss: 1.0786 - val_accuracy: 0.6333\n",
      "Epoch 91/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1921 - accuracy: 0.96 - 0s 533us/step - loss: 0.2155 - accuracy: 0.9778 - val_loss: 1.0753 - val_accuracy: 0.6333\n",
      "Epoch 92/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.96 - 0s 555us/step - loss: 0.2104 - accuracy: 0.9778 - val_loss: 1.0730 - val_accuracy: 0.6333\n",
      "Epoch 93/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 1.00 - 0s 667us/step - loss: 0.2043 - accuracy: 0.9778 - val_loss: 1.0707 - val_accuracy: 0.6333\n",
      "Epoch 94/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.96 - 0s 578us/step - loss: 0.1989 - accuracy: 0.9778 - val_loss: 1.0690 - val_accuracy: 0.6333\n",
      "Epoch 95/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1361 - accuracy: 1.00 - 0s 622us/step - loss: 0.1936 - accuracy: 0.9778 - val_loss: 1.0676 - val_accuracy: 0.6667\n",
      "Epoch 96/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2048 - accuracy: 1.00 - 0s 489us/step - loss: 0.1892 - accuracy: 0.9778 - val_loss: 1.0661 - val_accuracy: 0.6667\n",
      "Epoch 97/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1728 - accuracy: 0.96 - 0s 600us/step - loss: 0.1836 - accuracy: 0.9778 - val_loss: 1.0640 - val_accuracy: 0.6667\n",
      "Epoch 98/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.2001 - accuracy: 0.96 - 0s 400us/step - loss: 0.1795 - accuracy: 0.9778 - val_loss: 1.0612 - val_accuracy: 0.6667\n",
      "Epoch 99/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.96 - 0s 578us/step - loss: 0.1746 - accuracy: 0.9778 - val_loss: 1.0587 - val_accuracy: 0.6667\n",
      "Epoch 100/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 1.00 - 0s 467us/step - loss: 0.1707 - accuracy: 0.9778 - val_loss: 1.0569 - val_accuracy: 0.6667\n",
      "Epoch 101/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.96 - 0s 489us/step - loss: 0.1662 - accuracy: 0.9778 - val_loss: 1.0552 - val_accuracy: 0.6667\n",
      "Epoch 102/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.96 - 0s 511us/step - loss: 0.1625 - accuracy: 0.9778 - val_loss: 1.0533 - val_accuracy: 0.6667\n",
      "Epoch 103/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 1.00 - 0s 444us/step - loss: 0.1586 - accuracy: 0.9778 - val_loss: 1.0517 - val_accuracy: 0.6667\n",
      "Epoch 104/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1290 - accuracy: 0.96 - 0s 444us/step - loss: 0.1545 - accuracy: 0.9778 - val_loss: 1.0502 - val_accuracy: 0.6667\n",
      "Epoch 105/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1580 - accuracy: 0.96 - 0s 511us/step - loss: 0.1511 - accuracy: 0.9778 - val_loss: 1.0481 - val_accuracy: 0.6667\n",
      "Epoch 106/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1792 - accuracy: 0.96 - 0s 622us/step - loss: 0.1480 - accuracy: 0.9778 - val_loss: 1.0456 - val_accuracy: 0.6667\n",
      "Epoch 107/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1201 - accuracy: 0.96 - 0s 445us/step - loss: 0.1444 - accuracy: 0.9778 - val_loss: 1.0436 - val_accuracy: 0.6667\n",
      "Epoch 108/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 1.00 - 0s 444us/step - loss: 0.1417 - accuracy: 0.9778 - val_loss: 1.0429 - val_accuracy: 0.6667\n",
      "Epoch 109/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.96 - 0s 511us/step - loss: 0.1384 - accuracy: 0.9778 - val_loss: 1.0429 - val_accuracy: 0.6667\n",
      "Epoch 110/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1291 - accuracy: 0.96 - 0s 555us/step - loss: 0.1356 - accuracy: 0.9778 - val_loss: 1.0412 - val_accuracy: 0.6667\n",
      "Epoch 111/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 1.00 - 0s 533us/step - loss: 0.1328 - accuracy: 0.9778 - val_loss: 1.0383 - val_accuracy: 0.6667\n",
      "Epoch 112/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.96 - 0s 600us/step - loss: 0.1299 - accuracy: 0.9778 - val_loss: 1.0364 - val_accuracy: 0.6667\n",
      "Epoch 113/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1128 - accuracy: 1.00 - 0s 622us/step - loss: 0.1270 - accuracy: 0.9778 - val_loss: 1.0338 - val_accuracy: 0.6667\n",
      "Epoch 114/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1307 - accuracy: 0.96 - 0s 511us/step - loss: 0.1245 - accuracy: 0.9778 - val_loss: 1.0316 - val_accuracy: 0.6667\n",
      "Epoch 115/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1514 - accuracy: 0.96 - 0s 578us/step - loss: 0.1219 - accuracy: 0.9778 - val_loss: 1.0291 - val_accuracy: 0.6667\n",
      "Epoch 116/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1062 - accuracy: 1.00 - 0s 644us/step - loss: 0.1199 - accuracy: 0.9778 - val_loss: 1.0277 - val_accuracy: 0.6667\n",
      "Epoch 117/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1045 - accuracy: 0.96 - 0s 667us/step - loss: 0.1175 - accuracy: 0.9778 - val_loss: 1.0272 - val_accuracy: 0.6667\n",
      "Epoch 118/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1234 - accuracy: 0.96 - 0s 644us/step - loss: 0.1151 - accuracy: 0.9778 - val_loss: 1.0252 - val_accuracy: 0.6667\n",
      "Epoch 119/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0792 - accuracy: 1.00 - 0s 622us/step - loss: 0.1128 - accuracy: 0.9778 - val_loss: 1.0226 - val_accuracy: 0.6667\n",
      "Epoch 120/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.96 - 0s 533us/step - loss: 0.1107 - accuracy: 0.9778 - val_loss: 1.0211 - val_accuracy: 0.6667\n",
      "Epoch 121/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.96 - 0s 578us/step - loss: 0.1086 - accuracy: 0.9778 - val_loss: 1.0193 - val_accuracy: 0.6667\n",
      "Epoch 122/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1069 - accuracy: 0.96 - 0s 489us/step - loss: 0.1065 - accuracy: 0.9778 - val_loss: 1.0169 - val_accuracy: 0.6667\n",
      "Epoch 123/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.96 - 0s 600us/step - loss: 0.1045 - accuracy: 0.9778 - val_loss: 1.0144 - val_accuracy: 0.6667\n",
      "Epoch 124/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.96 - 0s 467us/step - loss: 0.1027 - accuracy: 0.9778 - val_loss: 1.0126 - val_accuracy: 0.6667\n",
      "Epoch 125/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.96 - 0s 467us/step - loss: 0.1007 - accuracy: 0.9778 - val_loss: 1.0103 - val_accuracy: 0.6667\n",
      "Epoch 126/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.96 - 0s 667us/step - loss: 0.0990 - accuracy: 0.9778 - val_loss: 1.0081 - val_accuracy: 0.6667\n",
      "Epoch 127/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0842 - accuracy: 0.96 - 0s 489us/step - loss: 0.0973 - accuracy: 0.9778 - val_loss: 1.0064 - val_accuracy: 0.6667\n",
      "Epoch 128/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0978 - accuracy: 0.96 - 0s 467us/step - loss: 0.0954 - accuracy: 0.9778 - val_loss: 1.0046 - val_accuracy: 0.6667\n",
      "Epoch 129/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1164 - accuracy: 0.96 - 0s 467us/step - loss: 0.0939 - accuracy: 0.9778 - val_loss: 1.0040 - val_accuracy: 0.6667\n",
      "Epoch 130/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.96 - 0s 467us/step - loss: 0.0924 - accuracy: 0.9778 - val_loss: 1.0036 - val_accuracy: 0.6667\n",
      "Epoch 131/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0814 - accuracy: 0.96 - 0s 489us/step - loss: 0.0909 - accuracy: 0.9778 - val_loss: 1.0033 - val_accuracy: 0.6667\n",
      "Epoch 132/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.96 - 0s 444us/step - loss: 0.0894 - accuracy: 0.9778 - val_loss: 1.0017 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 1.00 - 0s 444us/step - loss: 0.0884 - accuracy: 0.9778 - val_loss: 1.0002 - val_accuracy: 0.6667\n",
      "Epoch 134/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0822 - accuracy: 1.00 - 0s 444us/step - loss: 0.0867 - accuracy: 0.9778 - val_loss: 1.0007 - val_accuracy: 0.6667\n",
      "Epoch 135/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1042 - accuracy: 0.96 - 0s 444us/step - loss: 0.0852 - accuracy: 0.9778 - val_loss: 1.0024 - val_accuracy: 0.6667\n",
      "Epoch 136/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.96 - 0s 422us/step - loss: 0.0839 - accuracy: 0.9778 - val_loss: 1.0030 - val_accuracy: 0.6333\n",
      "Epoch 137/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 1.00 - 0s 444us/step - loss: 0.0825 - accuracy: 0.9778 - val_loss: 1.0024 - val_accuracy: 0.6333\n",
      "Epoch 138/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0919 - accuracy: 0.96 - 0s 489us/step - loss: 0.0814 - accuracy: 0.9778 - val_loss: 1.0027 - val_accuracy: 0.6333\n",
      "Epoch 139/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 1.00 - 0s 444us/step - loss: 0.0802 - accuracy: 0.9778 - val_loss: 1.0031 - val_accuracy: 0.6333\n",
      "Epoch 140/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0796 - accuracy: 1.00 - 0s 444us/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.6000\n",
      "Epoch 141/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0860 - accuracy: 0.96 - 0s 422us/step - loss: 0.0783 - accuracy: 0.9778 - val_loss: 1.0065 - val_accuracy: 0.6000\n",
      "Epoch 142/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0679 - accuracy: 1.00 - 0s 422us/step - loss: 0.0785 - accuracy: 0.9778 - val_loss: 1.0063 - val_accuracy: 0.6000\n",
      "Epoch 143/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.1017 - accuracy: 0.96 - 0s 467us/step - loss: 0.0769 - accuracy: 0.9778 - val_loss: 1.0034 - val_accuracy: 0.6000\n",
      "Epoch 144/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0793 - accuracy: 0.96 - 0s 489us/step - loss: 0.0761 - accuracy: 0.9778 - val_loss: 1.0011 - val_accuracy: 0.6000\n",
      "Epoch 145/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0808 - accuracy: 0.96 - 0s 467us/step - loss: 0.0745 - accuracy: 0.9778 - val_loss: 1.0003 - val_accuracy: 0.6000\n",
      "Epoch 146/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0910 - accuracy: 0.96 - 0s 422us/step - loss: 0.0737 - accuracy: 0.9778 - val_loss: 0.9998 - val_accuracy: 0.6000\n",
      "Epoch 147/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.96 - 0s 467us/step - loss: 0.0730 - accuracy: 0.9778 - val_loss: 0.9999 - val_accuracy: 0.6000\n",
      "Epoch 148/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 1.00 - 0s 378us/step - loss: 0.0721 - accuracy: 0.9778 - val_loss: 1.0008 - val_accuracy: 0.6000\n",
      "Epoch 149/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 1.00 - 0s 778us/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 1.0008 - val_accuracy: 0.6000\n",
      "Epoch 150/150\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.0930 - accuracy: 0.96 - 0s 467us/step - loss: 0.0704 - accuracy: 0.9778 - val_loss: 0.9994 - val_accuracy: 0.6000\n"
>>>>>>> enora
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = XX_train.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(units=YY_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 150\n",
    "batch_size =32\n",
    "history = model.fit(XX_train, YY_train, epochs=epochs, batch_size=batch_size, validation_split=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proba=model.predict(XX_test)\n",
    "idx = np.argmax(pred_proba, axis=-1)\n",
    "YY_pred = np.zeros( pred_proba.shape )\n",
    "YY_pred[ np.arange(YY_pred.shape[0]), idx] = 1\n",
    "accuracy_score(YY_test, YY_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_classif_theme.joblib']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(model, 'model_classif_theme.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 103,
=======
   "execution_count": 48,
>>>>>>> enora
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bin = X_train_clean_vectorized_bin.toarray().reshape(X_train_clean_vectorized_bin.shape[0],1,\n",
    "                                                X_train_clean_vectorized_bin.shape[1])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 104,
=======
   "execution_count": 49,
>>>>>>> enora
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
<<<<<<< HEAD
      "52/52 [==============================] - 0s 7ms/step - loss: 4.3150 - accuracy: 0.0192 - val_loss: 4.3129 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 4.2893 - accuracy: 0.0192 - val_loss: 4.2995 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.2679 - accuracy: 0.0192 - val_loss: 4.2869 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.2466 - accuracy: 0.0192 - val_loss: 4.2742 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 4.2238 - accuracy: 0.0769 - val_loss: 4.2625 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 4.2027 - accuracy: 0.0769 - val_loss: 4.2499 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.1800 - accuracy: 0.0962 - val_loss: 4.2373 - val_accuracy: 0.0435\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 4.1565 - accuracy: 0.1154 - val_loss: 4.2239 - val_accuracy: 0.1304\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 4.1313 - accuracy: 0.1154 - val_loss: 4.2097 - val_accuracy: 0.1739\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.1040 - accuracy: 0.1538 - val_loss: 4.1944 - val_accuracy: 0.1739\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 4.0751 - accuracy: 0.1538 - val_loss: 4.1773 - val_accuracy: 0.1739\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.0442 - accuracy: 0.1731 - val_loss: 4.1586 - val_accuracy: 0.2174\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.0113 - accuracy: 0.1923 - val_loss: 4.1388 - val_accuracy: 0.2174\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.9765 - accuracy: 0.1923 - val_loss: 4.1170 - val_accuracy: 0.2174\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.9402 - accuracy: 0.2308 - val_loss: 4.0927 - val_accuracy: 0.1739\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.9015 - accuracy: 0.2500 - val_loss: 4.0664 - val_accuracy: 0.1739\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.8604 - accuracy: 0.2692 - val_loss: 4.0389 - val_accuracy: 0.1739\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.8156 - accuracy: 0.2885 - val_loss: 4.0089 - val_accuracy: 0.1739\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.7689 - accuracy: 0.3077 - val_loss: 3.9753 - val_accuracy: 0.1304\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 3.7196 - accuracy: 0.3077 - val_loss: 3.9384 - val_accuracy: 0.1739\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.6679 - accuracy: 0.3269 - val_loss: 3.8995 - val_accuracy: 0.1739\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.6152 - accuracy: 0.3269 - val_loss: 3.8584 - val_accuracy: 0.2174\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.5613 - accuracy: 0.3269 - val_loss: 3.8152 - val_accuracy: 0.2174\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.5057 - accuracy: 0.3462 - val_loss: 3.7694 - val_accuracy: 0.2174\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.4484 - accuracy: 0.3654 - val_loss: 3.7216 - val_accuracy: 0.1739\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.3897 - accuracy: 0.3654 - val_loss: 3.6732 - val_accuracy: 0.2174\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.3312 - accuracy: 0.3846 - val_loss: 3.6226 - val_accuracy: 0.2174\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.2722 - accuracy: 0.3846 - val_loss: 3.5699 - val_accuracy: 0.2174\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.2135 - accuracy: 0.3846 - val_loss: 3.5160 - val_accuracy: 0.2174\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.1553 - accuracy: 0.3846 - val_loss: 3.4598 - val_accuracy: 0.2174\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.0966 - accuracy: 0.3846 - val_loss: 3.4029 - val_accuracy: 0.2174\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.0388 - accuracy: 0.3846 - val_loss: 3.3438 - val_accuracy: 0.2174\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.9803 - accuracy: 0.4038 - val_loss: 3.2842 - val_accuracy: 0.2174\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 2.9219 - accuracy: 0.4231 - val_loss: 3.2235 - val_accuracy: 0.2174\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.8635 - accuracy: 0.4231 - val_loss: 3.1617 - val_accuracy: 0.2174\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.8052 - accuracy: 0.4231 - val_loss: 3.0992 - val_accuracy: 0.2174\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 2.7469 - accuracy: 0.4423 - val_loss: 3.0364 - val_accuracy: 0.3043\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.6882 - accuracy: 0.4615 - val_loss: 2.9736 - val_accuracy: 0.3478\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.6296 - accuracy: 0.5000 - val_loss: 2.9106 - val_accuracy: 0.3478\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 2.5707 - accuracy: 0.5192 - val_loss: 2.8481 - val_accuracy: 0.3478\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 2.5127 - accuracy: 0.5577 - val_loss: 2.7866 - val_accuracy: 0.3043\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.4554 - accuracy: 0.5769 - val_loss: 2.7253 - val_accuracy: 0.2609\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 2.3988 - accuracy: 0.5962 - val_loss: 2.6646 - val_accuracy: 0.3043\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.3427 - accuracy: 0.5962 - val_loss: 2.6055 - val_accuracy: 0.3043\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.2878 - accuracy: 0.6154 - val_loss: 2.5476 - val_accuracy: 0.3043\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 2.2341 - accuracy: 0.6346 - val_loss: 2.4911 - val_accuracy: 0.3043\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.1814 - accuracy: 0.6538 - val_loss: 2.4352 - val_accuracy: 0.3913\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 2.1299 - accuracy: 0.6731 - val_loss: 2.3794 - val_accuracy: 0.3913\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 2.0786 - accuracy: 0.6923 - val_loss: 2.3237 - val_accuracy: 0.3913\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.0276 - accuracy: 0.7308 - val_loss: 2.2686 - val_accuracy: 0.4348\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 307us/step - loss: 1.9775 - accuracy: 0.7692 - val_loss: 2.2135 - val_accuracy: 0.3913\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.9273 - accuracy: 0.8077 - val_loss: 2.1592 - val_accuracy: 0.3913\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.8779 - accuracy: 0.8462 - val_loss: 2.1064 - val_accuracy: 0.4348\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.8300 - accuracy: 0.8269 - val_loss: 2.0541 - val_accuracy: 0.4348\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.7827 - accuracy: 0.8077 - val_loss: 2.0032 - val_accuracy: 0.4348\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.7364 - accuracy: 0.8077 - val_loss: 1.9543 - val_accuracy: 0.4348\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.6913 - accuracy: 0.8077 - val_loss: 1.9073 - val_accuracy: 0.4348\n"
=======
      "52/52 [==============================] - 0s 6ms/step - loss: 4.3302 - accuracy: 0.0000e+00 - val_loss: 4.2669 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.2939 - accuracy: 0.0000e+00 - val_loss: 4.2519 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 4.2606 - accuracy: 0.0192 - val_loss: 4.2359 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.2297 - accuracy: 0.0769 - val_loss: 4.2191 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.2027 - accuracy: 0.0962 - val_loss: 4.2031 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 4.1762 - accuracy: 0.0962 - val_loss: 4.1865 - val_accuracy: 0.0870\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.1492 - accuracy: 0.1154 - val_loss: 4.1696 - val_accuracy: 0.1304\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 4.1215 - accuracy: 0.1154 - val_loss: 4.1524 - val_accuracy: 0.1304\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.0936 - accuracy: 0.1346 - val_loss: 4.1343 - val_accuracy: 0.1304\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.0653 - accuracy: 0.1538 - val_loss: 4.1148 - val_accuracy: 0.1304\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.0368 - accuracy: 0.1538 - val_loss: 4.0930 - val_accuracy: 0.1739\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.0065 - accuracy: 0.2115 - val_loss: 4.0694 - val_accuracy: 0.1739\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.9741 - accuracy: 0.2115 - val_loss: 4.0442 - val_accuracy: 0.1739\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.9399 - accuracy: 0.1923 - val_loss: 4.0173 - val_accuracy: 0.1739\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.9046 - accuracy: 0.2308 - val_loss: 3.9889 - val_accuracy: 0.2609\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.8675 - accuracy: 0.2308 - val_loss: 3.9590 - val_accuracy: 0.3043\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.8288 - accuracy: 0.2500 - val_loss: 3.9268 - val_accuracy: 0.3043\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.7882 - accuracy: 0.2500 - val_loss: 3.8926 - val_accuracy: 0.3043\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 3.7460 - accuracy: 0.2500 - val_loss: 3.8566 - val_accuracy: 0.3043\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.7021 - accuracy: 0.2500 - val_loss: 3.8191 - val_accuracy: 0.3043\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.6562 - accuracy: 0.2500 - val_loss: 3.7803 - val_accuracy: 0.3043\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.6083 - accuracy: 0.2885 - val_loss: 3.7400 - val_accuracy: 0.3043\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.5585 - accuracy: 0.2885 - val_loss: 3.6984 - val_accuracy: 0.3043\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.5067 - accuracy: 0.2885 - val_loss: 3.6558 - val_accuracy: 0.3043\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.4537 - accuracy: 0.3077 - val_loss: 3.6123 - val_accuracy: 0.2609\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.3999 - accuracy: 0.3077 - val_loss: 3.5683 - val_accuracy: 0.2609\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.3460 - accuracy: 0.3077 - val_loss: 3.5236 - val_accuracy: 0.2609\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.2916 - accuracy: 0.3077 - val_loss: 3.4786 - val_accuracy: 0.3043\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.2370 - accuracy: 0.3077 - val_loss: 3.4336 - val_accuracy: 0.3043\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.1831 - accuracy: 0.3269 - val_loss: 3.3885 - val_accuracy: 0.3043\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.1292 - accuracy: 0.3269 - val_loss: 3.3436 - val_accuracy: 0.3043\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.0757 - accuracy: 0.3269 - val_loss: 3.2986 - val_accuracy: 0.3043\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.0227 - accuracy: 0.3269 - val_loss: 3.2538 - val_accuracy: 0.3043\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.9703 - accuracy: 0.3269 - val_loss: 3.2095 - val_accuracy: 0.3043\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.9186 - accuracy: 0.3654 - val_loss: 3.1655 - val_accuracy: 0.3043\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.8673 - accuracy: 0.3846 - val_loss: 3.1221 - val_accuracy: 0.3478\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.8160 - accuracy: 0.4038 - val_loss: 3.0789 - val_accuracy: 0.3478\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.7643 - accuracy: 0.4423 - val_loss: 3.0362 - val_accuracy: 0.3043\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.7131 - accuracy: 0.4615 - val_loss: 2.9939 - val_accuracy: 0.3043\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.6624 - accuracy: 0.4615 - val_loss: 2.9519 - val_accuracy: 0.3043\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.6121 - accuracy: 0.4423 - val_loss: 2.9100 - val_accuracy: 0.2609\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.5627 - accuracy: 0.4808 - val_loss: 2.8681 - val_accuracy: 0.2609\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.5146 - accuracy: 0.4808 - val_loss: 2.8264 - val_accuracy: 0.2609\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.4668 - accuracy: 0.5192 - val_loss: 2.7850 - val_accuracy: 0.2609\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.4192 - accuracy: 0.5385 - val_loss: 2.7437 - val_accuracy: 0.2174\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.3717 - accuracy: 0.5000 - val_loss: 2.7020 - val_accuracy: 0.2174\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 2.3245 - accuracy: 0.5000 - val_loss: 2.6596 - val_accuracy: 0.1739\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.2772 - accuracy: 0.4615 - val_loss: 2.6162 - val_accuracy: 0.1739\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.2305 - accuracy: 0.4615 - val_loss: 2.5726 - val_accuracy: 0.1739\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.1839 - accuracy: 0.4615 - val_loss: 2.5286 - val_accuracy: 0.1739\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.1370 - accuracy: 0.4615 - val_loss: 2.4838 - val_accuracy: 0.2174\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.0899 - accuracy: 0.4615 - val_loss: 2.4381 - val_accuracy: 0.2174\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.0420 - accuracy: 0.4808 - val_loss: 2.3930 - val_accuracy: 0.2174\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.9944 - accuracy: 0.4808 - val_loss: 2.3477 - val_accuracy: 0.2174\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.9471 - accuracy: 0.5000 - val_loss: 2.3032 - val_accuracy: 0.2174\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.8998 - accuracy: 0.5192 - val_loss: 2.2595 - val_accuracy: 0.2174\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.8529 - accuracy: 0.5192 - val_loss: 2.2170 - val_accuracy: 0.2174\n"
>>>>>>> enora
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
<<<<<<< HEAD
      "52/52 [==============================] - 0s 250us/step - loss: 1.6465 - accuracy: 0.8269 - val_loss: 1.8625 - val_accuracy: 0.4348\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.6027 - accuracy: 0.8269 - val_loss: 1.8203 - val_accuracy: 0.4348\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.5598 - accuracy: 0.8269 - val_loss: 1.7811 - val_accuracy: 0.4783\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.5179 - accuracy: 0.8462 - val_loss: 1.7448 - val_accuracy: 0.4783\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.4769 - accuracy: 0.8846 - val_loss: 1.7114 - val_accuracy: 0.5217\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.4369 - accuracy: 0.9038 - val_loss: 1.6812 - val_accuracy: 0.5217\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3980 - accuracy: 0.9038 - val_loss: 1.6539 - val_accuracy: 0.5217\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.3602 - accuracy: 0.8846 - val_loss: 1.6295 - val_accuracy: 0.5217\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.3238 - accuracy: 0.8846 - val_loss: 1.6075 - val_accuracy: 0.5217\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.2883 - accuracy: 0.9038 - val_loss: 1.5879 - val_accuracy: 0.5652\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.2541 - accuracy: 0.9231 - val_loss: 1.5702 - val_accuracy: 0.5217\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.2214 - accuracy: 0.9231 - val_loss: 1.5537 - val_accuracy: 0.5217\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 270us/step - loss: 1.1900 - accuracy: 0.9231 - val_loss: 1.5380 - val_accuracy: 0.5217\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.1598 - accuracy: 0.9038 - val_loss: 1.5229 - val_accuracy: 0.5217\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 1.1310 - accuracy: 0.9038 - val_loss: 1.5078 - val_accuracy: 0.5217\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.1032 - accuracy: 0.8846 - val_loss: 1.4925 - val_accuracy: 0.5217\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.0766 - accuracy: 0.8846 - val_loss: 1.4770 - val_accuracy: 0.5217\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.0508 - accuracy: 0.9038 - val_loss: 1.4609 - val_accuracy: 0.5217\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.0258 - accuracy: 0.9038 - val_loss: 1.4441 - val_accuracy: 0.4783\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 1.0017 - accuracy: 0.9038 - val_loss: 1.4268 - val_accuracy: 0.4783\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.9786 - accuracy: 0.9038 - val_loss: 1.4090 - val_accuracy: 0.4783\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.9568 - accuracy: 0.9038 - val_loss: 1.3914 - val_accuracy: 0.4783\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.9358 - accuracy: 0.9038 - val_loss: 1.3749 - val_accuracy: 0.5217\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.9155 - accuracy: 0.9038 - val_loss: 1.3594 - val_accuracy: 0.4783\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.8964 - accuracy: 0.9231 - val_loss: 1.3444 - val_accuracy: 0.4783\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.8779 - accuracy: 0.9231 - val_loss: 1.3307 - val_accuracy: 0.4783\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8600 - accuracy: 0.9231 - val_loss: 1.3184 - val_accuracy: 0.4783\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8429 - accuracy: 0.9231 - val_loss: 1.3077 - val_accuracy: 0.4783\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8263 - accuracy: 0.9231 - val_loss: 1.2985 - val_accuracy: 0.4783\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.8101 - accuracy: 0.9231 - val_loss: 1.2904 - val_accuracy: 0.4783\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7941 - accuracy: 0.9231 - val_loss: 1.2831 - val_accuracy: 0.4783\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7787 - accuracy: 0.9231 - val_loss: 1.2759 - val_accuracy: 0.4783\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7638 - accuracy: 0.9231 - val_loss: 1.2685 - val_accuracy: 0.4783\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7491 - accuracy: 0.9231 - val_loss: 1.2605 - val_accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7348 - accuracy: 0.9231 - val_loss: 1.2519 - val_accuracy: 0.4783\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7209 - accuracy: 0.9231 - val_loss: 1.2421 - val_accuracy: 0.5217\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7073 - accuracy: 0.9231 - val_loss: 1.2323 - val_accuracy: 0.5217\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6941 - accuracy: 0.9423 - val_loss: 1.2225 - val_accuracy: 0.5217\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 251us/step - loss: 0.6809 - accuracy: 0.9423 - val_loss: 1.2128 - val_accuracy: 0.5217\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.6679 - accuracy: 0.9231 - val_loss: 1.2031 - val_accuracy: 0.5217\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6552 - accuracy: 0.9231 - val_loss: 1.1933 - val_accuracy: 0.5217\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6428 - accuracy: 0.9231 - val_loss: 1.1835 - val_accuracy: 0.5217\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.6306 - accuracy: 0.9231 - val_loss: 1.1737 - val_accuracy: 0.5217\n"
=======
      "52/52 [==============================] - 0s 231us/step - loss: 1.8067 - accuracy: 0.5192 - val_loss: 2.1766 - val_accuracy: 0.2174\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.7613 - accuracy: 0.5192 - val_loss: 2.1381 - val_accuracy: 0.2174\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.7165 - accuracy: 0.5385 - val_loss: 2.1017 - val_accuracy: 0.2174\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.6727 - accuracy: 0.5385 - val_loss: 2.0667 - val_accuracy: 0.2609\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 193us/step - loss: 1.6295 - accuracy: 0.5385 - val_loss: 2.0338 - val_accuracy: 0.2609\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.5878 - accuracy: 0.5385 - val_loss: 2.0024 - val_accuracy: 0.2609\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.5468 - accuracy: 0.5577 - val_loss: 1.9722 - val_accuracy: 0.2609\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 1.5067 - accuracy: 0.5769 - val_loss: 1.9432 - val_accuracy: 0.2609\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.4671 - accuracy: 0.5769 - val_loss: 1.9158 - val_accuracy: 0.2609\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.4289 - accuracy: 0.5769 - val_loss: 1.8898 - val_accuracy: 0.2609\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.3916 - accuracy: 0.5769 - val_loss: 1.8655 - val_accuracy: 0.2609\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.3550 - accuracy: 0.5769 - val_loss: 1.8429 - val_accuracy: 0.2609\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.3196 - accuracy: 0.5769 - val_loss: 1.8209 - val_accuracy: 0.2609\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.2853 - accuracy: 0.5769 - val_loss: 1.7995 - val_accuracy: 0.2609\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.2526 - accuracy: 0.5769 - val_loss: 1.7785 - val_accuracy: 0.3043\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.2211 - accuracy: 0.5962 - val_loss: 1.7580 - val_accuracy: 0.3043\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.1908 - accuracy: 0.6154 - val_loss: 1.7379 - val_accuracy: 0.3913\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.1614 - accuracy: 0.6154 - val_loss: 1.7176 - val_accuracy: 0.3913\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.1335 - accuracy: 0.5962 - val_loss: 1.6971 - val_accuracy: 0.3913\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.1068 - accuracy: 0.5962 - val_loss: 1.6772 - val_accuracy: 0.3913\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.0810 - accuracy: 0.6154 - val_loss: 1.6583 - val_accuracy: 0.3913\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.0564 - accuracy: 0.6346 - val_loss: 1.6415 - val_accuracy: 0.3913\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 1.0328 - accuracy: 0.6538 - val_loss: 1.6261 - val_accuracy: 0.3913\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.0101 - accuracy: 0.6538 - val_loss: 1.6116 - val_accuracy: 0.3913\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.9882 - accuracy: 0.6923 - val_loss: 1.5976 - val_accuracy: 0.3913\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.9672 - accuracy: 0.6923 - val_loss: 1.5828 - val_accuracy: 0.4348\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.9469 - accuracy: 0.7115 - val_loss: 1.5686 - val_accuracy: 0.4348\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.9275 - accuracy: 0.7308 - val_loss: 1.5547 - val_accuracy: 0.4348\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.9089 - accuracy: 0.7500 - val_loss: 1.5409 - val_accuracy: 0.4348\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8910 - accuracy: 0.7500 - val_loss: 1.5273 - val_accuracy: 0.4348\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.8737 - accuracy: 0.7500 - val_loss: 1.5137 - val_accuracy: 0.4348\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.8569 - accuracy: 0.7692 - val_loss: 1.4998 - val_accuracy: 0.4348\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.8403 - accuracy: 0.7885 - val_loss: 1.4858 - val_accuracy: 0.4783\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.8242 - accuracy: 0.8269 - val_loss: 1.4715 - val_accuracy: 0.4783\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.8083 - accuracy: 0.8269 - val_loss: 1.4570 - val_accuracy: 0.5217\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7928 - accuracy: 0.8269 - val_loss: 1.4422 - val_accuracy: 0.5217\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7776 - accuracy: 0.8654 - val_loss: 1.4277 - val_accuracy: 0.5217\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7628 - accuracy: 0.8654 - val_loss: 1.4138 - val_accuracy: 0.5217\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.7480 - accuracy: 0.8846 - val_loss: 1.4006 - val_accuracy: 0.5217\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.7336 - accuracy: 0.8846 - val_loss: 1.3883 - val_accuracy: 0.5217\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7195 - accuracy: 0.8846 - val_loss: 1.3746 - val_accuracy: 0.5217\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.7056 - accuracy: 0.8846 - val_loss: 1.3596 - val_accuracy: 0.5217\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 0.6919 - accuracy: 0.8846 - val_loss: 1.3438 - val_accuracy: 0.5217\n"
>>>>>>> enora
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = X_bin.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[0], activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "history = model.fit(X_bin, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count = X_train_clean_vectorized_count.toarray().reshape(X_train_clean_vectorized_count.shape[0],1,\n",
    "                                                X_train_clean_vectorized_count.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52 samples, validate on 23 samples\n",
      "Epoch 1/100\n",
<<<<<<< HEAD
      "52/52 [==============================] - 0s 7ms/step - loss: 8.4548 - accuracy: 0.0192 - val_loss: 7.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 8.1950 - accuracy: 0.0769 - val_loss: 7.4636 - val_accuracy: 0.0435\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 7.8272 - accuracy: 0.1154 - val_loss: 7.2732 - val_accuracy: 0.0435\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 7.6161 - accuracy: 0.1346 - val_loss: 7.1033 - val_accuracy: 0.0870\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 7.2395 - accuracy: 0.1731 - val_loss: 6.9430 - val_accuracy: 0.2174\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 7.0500 - accuracy: 0.2308 - val_loss: 6.7871 - val_accuracy: 0.2609\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 6.6350 - accuracy: 0.3269 - val_loss: 6.6355 - val_accuracy: 0.3913\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 6.0778 - accuracy: 0.3654 - val_loss: 6.5001 - val_accuracy: 0.4348\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 5.6491 - accuracy: 0.4038 - val_loss: 6.3599 - val_accuracy: 0.4783\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 366us/step - loss: 5.0607 - accuracy: 0.4808 - val_loss: 6.2242 - val_accuracy: 0.4783\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.6984 - accuracy: 0.5000 - val_loss: 6.0932 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 4.2066 - accuracy: 0.5192 - val_loss: 5.9825 - val_accuracy: 0.5652\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 4.0075 - accuracy: 0.5000 - val_loss: 5.8788 - val_accuracy: 0.6087\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.8924 - accuracy: 0.5192 - val_loss: 5.7770 - val_accuracy: 0.6087\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.7896 - accuracy: 0.6154 - val_loss: 5.6844 - val_accuracy: 0.6087\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 384us/step - loss: 3.5455 - accuracy: 0.6154 - val_loss: 5.6039 - val_accuracy: 0.6087\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 3.4196 - accuracy: 0.5769 - val_loss: 5.1343 - val_accuracy: 0.6087\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 327us/step - loss: 3.3496 - accuracy: 0.6346 - val_loss: 5.0393 - val_accuracy: 0.6087\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.8756 - accuracy: 0.6346 - val_loss: 4.6615 - val_accuracy: 0.5217\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.7958 - accuracy: 0.6154 - val_loss: 4.4969 - val_accuracy: 0.4783\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.7412 - accuracy: 0.6154 - val_loss: 4.4211 - val_accuracy: 0.4783\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.5125 - accuracy: 0.5962 - val_loss: 4.3565 - val_accuracy: 0.4783\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 289us/step - loss: 2.4358 - accuracy: 0.5962 - val_loss: 3.8949 - val_accuracy: 0.4783\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.3834 - accuracy: 0.5962 - val_loss: 3.4002 - val_accuracy: 0.4783\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.3343 - accuracy: 0.5769 - val_loss: 2.8833 - val_accuracy: 0.4783\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.0697 - accuracy: 0.5577 - val_loss: 2.7624 - val_accuracy: 0.4783\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 2.0110 - accuracy: 0.5769 - val_loss: 2.6812 - val_accuracy: 0.4783\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.7996 - accuracy: 0.5962 - val_loss: 2.6280 - val_accuracy: 0.4783\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.6903 - accuracy: 0.6154 - val_loss: 2.5925 - val_accuracy: 0.4783\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4751 - accuracy: 0.5962 - val_loss: 2.5578 - val_accuracy: 0.4783\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1975 - accuracy: 0.6154 - val_loss: 2.5334 - val_accuracy: 0.4783\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 1.1606 - accuracy: 0.6538 - val_loss: 2.5111 - val_accuracy: 0.4783\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.1249 - accuracy: 0.6538 - val_loss: 2.4763 - val_accuracy: 0.4783\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.2938 - accuracy: 0.7115 - val_loss: 2.4450 - val_accuracy: 0.4783\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.2636 - accuracy: 0.7115 - val_loss: 2.4156 - val_accuracy: 0.4783\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 1.2247 - accuracy: 0.7308 - val_loss: 2.3854 - val_accuracy: 0.4783\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.1841 - accuracy: 0.7692 - val_loss: 2.3651 - val_accuracy: 0.4783\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 1.1480 - accuracy: 0.7115 - val_loss: 2.3487 - val_accuracy: 0.4783\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 365us/step - loss: 1.1149 - accuracy: 0.7115 - val_loss: 2.1276 - val_accuracy: 0.4783\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.0828 - accuracy: 0.7115 - val_loss: 1.9157 - val_accuracy: 0.4783\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 1.0529 - accuracy: 0.7308 - val_loss: 1.9032 - val_accuracy: 0.4783\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 1.0173 - accuracy: 0.7500 - val_loss: 1.8940 - val_accuracy: 0.5217\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 270us/step - loss: 0.9922 - accuracy: 0.7500 - val_loss: 1.9002 - val_accuracy: 0.5217\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.9651 - accuracy: 0.7692 - val_loss: 1.9159 - val_accuracy: 0.5217\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.9309 - accuracy: 0.8077 - val_loss: 1.9261 - val_accuracy: 0.4783\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.8983 - accuracy: 0.8077 - val_loss: 1.9774 - val_accuracy: 0.4783\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.8639 - accuracy: 0.8269 - val_loss: 2.4178 - val_accuracy: 0.4783\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.8343 - accuracy: 0.8269 - val_loss: 3.1288 - val_accuracy: 0.4783\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.8035 - accuracy: 0.8077 - val_loss: 3.1182 - val_accuracy: 0.4783\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 0.7760 - accuracy: 0.8269 - val_loss: 3.1133 - val_accuracy: 0.4783\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7514 - accuracy: 0.8269 - val_loss: 3.1133 - val_accuracy: 0.4783\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7246 - accuracy: 0.8269 - val_loss: 3.1210 - val_accuracy: 0.4783\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6931 - accuracy: 0.8269 - val_loss: 3.1434 - val_accuracy: 0.4783\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6672 - accuracy: 0.8269 - val_loss: 3.2257 - val_accuracy: 0.4783\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.6586 - accuracy: 0.8269 - val_loss: 3.5679 - val_accuracy: 0.4783\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6377 - accuracy: 0.8462 - val_loss: 3.9475 - val_accuracy: 0.4783\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 0.6272 - accuracy: 0.8462 - val_loss: 3.9345 - val_accuracy: 0.4783\n"
=======
      "52/52 [==============================] - 0s 8ms/step - loss: 11.3917 - accuracy: 0.0000e+00 - val_loss: 10.5064 - val_accuracy: 0.0435\n",
      "Epoch 2/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 10.2238 - accuracy: 0.0000e+00 - val_loss: 10.3584 - val_accuracy: 0.0435\n",
      "Epoch 3/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 9.7123 - accuracy: 0.0192 - val_loss: 10.2379 - val_accuracy: 0.0435\n",
      "Epoch 4/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 8.7527 - accuracy: 0.0385 - val_loss: 9.7266 - val_accuracy: 0.0435\n",
      "Epoch 5/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 8.4367 - accuracy: 0.0962 - val_loss: 9.5603 - val_accuracy: 0.0435\n",
      "Epoch 6/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 8.0136 - accuracy: 0.1346 - val_loss: 9.4056 - val_accuracy: 0.0435\n",
      "Epoch 7/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 7.7865 - accuracy: 0.1538 - val_loss: 8.8455 - val_accuracy: 0.0870\n",
      "Epoch 8/100\n",
      "52/52 [==============================] - 0s 346us/step - loss: 7.5092 - accuracy: 0.1538 - val_loss: 8.1898 - val_accuracy: 0.0870\n",
      "Epoch 9/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 6.8221 - accuracy: 0.2308 - val_loss: 7.9921 - val_accuracy: 0.1304\n",
      "Epoch 10/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 5.8365 - accuracy: 0.2885 - val_loss: 7.4212 - val_accuracy: 0.1739\n",
      "Epoch 11/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 5.2206 - accuracy: 0.3269 - val_loss: 7.2437 - val_accuracy: 0.1739\n",
      "Epoch 12/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 4.8628 - accuracy: 0.3462 - val_loss: 7.0902 - val_accuracy: 0.1739\n",
      "Epoch 13/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.7036 - accuracy: 0.3846 - val_loss: 6.9648 - val_accuracy: 0.1739\n",
      "Epoch 14/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 4.3895 - accuracy: 0.4038 - val_loss: 6.4312 - val_accuracy: 0.1739\n",
      "Epoch 15/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 4.2658 - accuracy: 0.4423 - val_loss: 6.2987 - val_accuracy: 0.1739\n",
      "Epoch 16/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 4.0212 - accuracy: 0.4423 - val_loss: 5.8067 - val_accuracy: 0.1739\n",
      "Epoch 17/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 3.9094 - accuracy: 0.4615 - val_loss: 5.6819 - val_accuracy: 0.1739\n",
      "Epoch 18/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.8339 - accuracy: 0.4808 - val_loss: 5.2476 - val_accuracy: 0.1739\n",
      "Epoch 19/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.7734 - accuracy: 0.4808 - val_loss: 5.0866 - val_accuracy: 0.1739\n",
      "Epoch 20/100\n",
      "52/52 [==============================] - 0s 308us/step - loss: 3.7215 - accuracy: 0.5000 - val_loss: 4.9914 - val_accuracy: 0.1739\n",
      "Epoch 21/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.6760 - accuracy: 0.5192 - val_loss: 4.9152 - val_accuracy: 0.1739\n",
      "Epoch 22/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.6285 - accuracy: 0.5385 - val_loss: 4.8519 - val_accuracy: 0.2174\n",
      "Epoch 23/100\n",
      "52/52 [==============================] - 0s 288us/step - loss: 3.5841 - accuracy: 0.5577 - val_loss: 4.7998 - val_accuracy: 0.2174\n",
      "Epoch 24/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.5428 - accuracy: 0.5577 - val_loss: 4.7533 - val_accuracy: 0.2609\n",
      "Epoch 25/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.4973 - accuracy: 0.5577 - val_loss: 4.7112 - val_accuracy: 0.3478\n",
      "Epoch 26/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.4542 - accuracy: 0.5769 - val_loss: 4.6748 - val_accuracy: 0.3478\n",
      "Epoch 27/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.4070 - accuracy: 0.5962 - val_loss: 4.6412 - val_accuracy: 0.3478\n",
      "Epoch 28/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.3627 - accuracy: 0.5769 - val_loss: 4.6105 - val_accuracy: 0.3478\n",
      "Epoch 29/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.3273 - accuracy: 0.5769 - val_loss: 4.5796 - val_accuracy: 0.3478\n",
      "Epoch 30/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.2920 - accuracy: 0.5769 - val_loss: 4.5488 - val_accuracy: 0.3478\n",
      "Epoch 31/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 3.2538 - accuracy: 0.5769 - val_loss: 4.5160 - val_accuracy: 0.3478\n",
      "Epoch 32/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.2140 - accuracy: 0.5769 - val_loss: 4.4832 - val_accuracy: 0.3478\n",
      "Epoch 33/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.1718 - accuracy: 0.5769 - val_loss: 4.4489 - val_accuracy: 0.3478\n",
      "Epoch 34/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.1371 - accuracy: 0.5769 - val_loss: 4.4175 - val_accuracy: 0.3478\n",
      "Epoch 35/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.1080 - accuracy: 0.5769 - val_loss: 4.3900 - val_accuracy: 0.3043\n",
      "Epoch 36/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 3.0803 - accuracy: 0.5962 - val_loss: 4.3677 - val_accuracy: 0.3043\n",
      "Epoch 37/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 3.0476 - accuracy: 0.6154 - val_loss: 4.3464 - val_accuracy: 0.3043\n",
      "Epoch 38/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 3.0291 - accuracy: 0.6538 - val_loss: 4.3262 - val_accuracy: 0.3043\n",
      "Epoch 39/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 3.0053 - accuracy: 0.6538 - val_loss: 4.3085 - val_accuracy: 0.3043\n",
      "Epoch 40/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 2.9779 - accuracy: 0.6731 - val_loss: 4.2926 - val_accuracy: 0.3043\n",
      "Epoch 41/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 2.7585 - accuracy: 0.6731 - val_loss: 4.2768 - val_accuracy: 0.3043\n",
      "Epoch 42/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.7025 - accuracy: 0.6731 - val_loss: 4.2611 - val_accuracy: 0.3043\n",
      "Epoch 43/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.6853 - accuracy: 0.6923 - val_loss: 4.2463 - val_accuracy: 0.3043\n",
      "Epoch 44/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.6756 - accuracy: 0.6923 - val_loss: 4.2295 - val_accuracy: 0.3043\n",
      "Epoch 45/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.6554 - accuracy: 0.6731 - val_loss: 4.2112 - val_accuracy: 0.3043\n",
      "Epoch 46/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 2.6416 - accuracy: 0.6731 - val_loss: 4.1950 - val_accuracy: 0.3043\n",
      "Epoch 47/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.6237 - accuracy: 0.6731 - val_loss: 4.1796 - val_accuracy: 0.3913\n",
      "Epoch 48/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.6173 - accuracy: 0.6923 - val_loss: 4.1667 - val_accuracy: 0.3913\n",
      "Epoch 49/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.6019 - accuracy: 0.6923 - val_loss: 4.1569 - val_accuracy: 0.4348\n",
      "Epoch 50/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 2.5753 - accuracy: 0.6731 - val_loss: 4.1503 - val_accuracy: 0.4783\n",
      "Epoch 51/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 2.5543 - accuracy: 0.6731 - val_loss: 4.1441 - val_accuracy: 0.4783\n",
      "Epoch 52/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 2.5364 - accuracy: 0.6731 - val_loss: 4.1384 - val_accuracy: 0.4783\n",
      "Epoch 53/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 2.5185 - accuracy: 0.6731 - val_loss: 4.1347 - val_accuracy: 0.4348\n",
      "Epoch 54/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.5023 - accuracy: 0.6538 - val_loss: 4.1353 - val_accuracy: 0.4348\n",
      "Epoch 55/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.4787 - accuracy: 0.6538 - val_loss: 4.1389 - val_accuracy: 0.4348\n",
      "Epoch 56/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.4696 - accuracy: 0.6538 - val_loss: 4.1501 - val_accuracy: 0.4348\n",
      "Epoch 57/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.4460 - accuracy: 0.6923 - val_loss: 4.1686 - val_accuracy: 0.4348\n"
>>>>>>> enora
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
<<<<<<< HEAD
      "52/52 [==============================] - 0s 231us/step - loss: 0.6238 - accuracy: 0.8462 - val_loss: 3.9371 - val_accuracy: 0.4783\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6100 - accuracy: 0.8462 - val_loss: 3.9456 - val_accuracy: 0.4783\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.5928 - accuracy: 0.8462 - val_loss: 3.9957 - val_accuracy: 0.4783\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7873 - accuracy: 0.8269 - val_loss: 4.3636 - val_accuracy: 0.4348\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 230us/step - loss: 0.5835 - accuracy: 0.8269 - val_loss: 4.3387 - val_accuracy: 0.4348\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.5721 - accuracy: 0.8462 - val_loss: 4.3232 - val_accuracy: 0.4348\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6648 - accuracy: 0.8269 - val_loss: 4.3260 - val_accuracy: 0.4348\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6775 - accuracy: 0.8462 - val_loss: 4.4152 - val_accuracy: 0.4348\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.6817 - accuracy: 0.8654 - val_loss: 4.6517 - val_accuracy: 0.4348\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 269us/step - loss: 0.7615 - accuracy: 0.8462 - val_loss: 4.6246 - val_accuracy: 0.4348\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7597 - accuracy: 0.8462 - val_loss: 4.5917 - val_accuracy: 0.4348\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7502 - accuracy: 0.8462 - val_loss: 4.5582 - val_accuracy: 0.4348\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 250us/step - loss: 0.7409 - accuracy: 0.8462 - val_loss: 4.5120 - val_accuracy: 0.4348\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7308 - accuracy: 0.8462 - val_loss: 4.7537 - val_accuracy: 0.4348\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7208 - accuracy: 0.8462 - val_loss: 4.7249 - val_accuracy: 0.4348\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7113 - accuracy: 0.8462 - val_loss: 4.6707 - val_accuracy: 0.4348\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7024 - accuracy: 0.8462 - val_loss: 4.5297 - val_accuracy: 0.4348\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.6929 - accuracy: 0.8462 - val_loss: 4.5269 - val_accuracy: 0.4348\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6803 - accuracy: 0.8462 - val_loss: 4.5278 - val_accuracy: 0.4348\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6688 - accuracy: 0.8462 - val_loss: 4.5285 - val_accuracy: 0.4348\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6588 - accuracy: 0.8462 - val_loss: 4.5295 - val_accuracy: 0.4348\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.6468 - accuracy: 0.8654 - val_loss: 4.5317 - val_accuracy: 0.4348\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.6352 - accuracy: 0.8654 - val_loss: 4.5409 - val_accuracy: 0.4348\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6227 - accuracy: 0.8654 - val_loss: 4.5795 - val_accuracy: 0.4348\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6142 - accuracy: 0.8846 - val_loss: 4.8987 - val_accuracy: 0.4348\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.5988 - accuracy: 0.8846 - val_loss: 5.0719 - val_accuracy: 0.3913\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.5876 - accuracy: 0.8846 - val_loss: 5.0577 - val_accuracy: 0.3913\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.5782 - accuracy: 0.9038 - val_loss: 5.0369 - val_accuracy: 0.3913\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6483 - accuracy: 0.8846 - val_loss: 5.0151 - val_accuracy: 0.3913\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.6388 - accuracy: 0.8846 - val_loss: 4.9964 - val_accuracy: 0.3913\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6288 - accuracy: 0.8846 - val_loss: 4.9795 - val_accuracy: 0.3913\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6181 - accuracy: 0.8846 - val_loss: 4.9622 - val_accuracy: 0.3913\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.6122 - accuracy: 0.8846 - val_loss: 4.9447 - val_accuracy: 0.3913\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6087 - accuracy: 0.8846 - val_loss: 4.9294 - val_accuracy: 0.3913\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6049 - accuracy: 0.8654 - val_loss: 4.9142 - val_accuracy: 0.3913\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.8913 - accuracy: 0.8462 - val_loss: 4.8903 - val_accuracy: 0.3913\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 231us/step - loss: 0.7567 - accuracy: 0.8269 - val_loss: 4.8653 - val_accuracy: 0.3913\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.8584 - accuracy: 0.7885 - val_loss: 4.8187 - val_accuracy: 0.4348\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 0.7601 - accuracy: 0.8269 - val_loss: 4.7600 - val_accuracy: 0.4348\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.7601 - accuracy: 0.8269 - val_loss: 4.6813 - val_accuracy: 0.4348\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 0.8471 - accuracy: 0.8462 - val_loss: 4.5601 - val_accuracy: 0.4348\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.7523 - accuracy: 0.8462 - val_loss: 4.5396 - val_accuracy: 0.4348\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 0.6611 - accuracy: 0.8654 - val_loss: 4.5138 - val_accuracy: 0.4348\n"
=======
      "52/52 [==============================] - 0s 173us/step - loss: 2.4220 - accuracy: 0.6731 - val_loss: 4.2480 - val_accuracy: 0.3913\n",
      "Epoch 59/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.4039 - accuracy: 0.6731 - val_loss: 4.5621 - val_accuracy: 0.3913\n",
      "Epoch 60/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.3751 - accuracy: 0.6923 - val_loss: 4.5773 - val_accuracy: 0.3913\n",
      "Epoch 61/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 2.3541 - accuracy: 0.6923 - val_loss: 4.6063 - val_accuracy: 0.3913\n",
      "Epoch 62/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.3333 - accuracy: 0.7115 - val_loss: 4.9569 - val_accuracy: 0.3913\n",
      "Epoch 63/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.3149 - accuracy: 0.7308 - val_loss: 4.9485 - val_accuracy: 0.3913\n",
      "Epoch 64/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 2.2923 - accuracy: 0.7500 - val_loss: 4.9408 - val_accuracy: 0.3913\n",
      "Epoch 65/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 2.2639 - accuracy: 0.7500 - val_loss: 4.9311 - val_accuracy: 0.4348\n",
      "Epoch 66/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.2344 - accuracy: 0.7500 - val_loss: 4.9209 - val_accuracy: 0.4348\n",
      "Epoch 67/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.2028 - accuracy: 0.7500 - val_loss: 4.9136 - val_accuracy: 0.4348\n",
      "Epoch 68/100\n",
      "52/52 [==============================] - 0s 212us/step - loss: 2.1678 - accuracy: 0.7500 - val_loss: 4.9170 - val_accuracy: 0.4348\n",
      "Epoch 69/100\n",
      "52/52 [==============================] - 0s 135us/step - loss: 2.1689 - accuracy: 0.7500 - val_loss: 4.9228 - val_accuracy: 0.3913\n",
      "Epoch 70/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.1491 - accuracy: 0.7500 - val_loss: 4.9280 - val_accuracy: 0.4348\n",
      "Epoch 71/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.0970 - accuracy: 0.7500 - val_loss: 4.9418 - val_accuracy: 0.3913\n",
      "Epoch 72/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 2.0552 - accuracy: 0.7500 - val_loss: 4.9671 - val_accuracy: 0.3913\n",
      "Epoch 73/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 2.0041 - accuracy: 0.7500 - val_loss: 5.0008 - val_accuracy: 0.3913\n",
      "Epoch 74/100\n",
      "52/52 [==============================] - 0s 154us/step - loss: 1.8886 - accuracy: 0.7692 - val_loss: 5.0662 - val_accuracy: 0.3478\n",
      "Epoch 75/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.7549 - accuracy: 0.7692 - val_loss: 5.7933 - val_accuracy: 0.3478\n",
      "Epoch 76/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.6156 - accuracy: 0.7692 - val_loss: 5.7942 - val_accuracy: 0.3478\n",
      "Epoch 77/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.4441 - accuracy: 0.7500 - val_loss: 5.8113 - val_accuracy: 0.3478\n",
      "Epoch 78/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.2846 - accuracy: 0.7308 - val_loss: 5.6780 - val_accuracy: 0.3043\n",
      "Epoch 79/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4094 - accuracy: 0.7308 - val_loss: 5.7253 - val_accuracy: 0.3043\n",
      "Epoch 80/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.3937 - accuracy: 0.7308 - val_loss: 5.9105 - val_accuracy: 0.3043\n",
      "Epoch 81/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3973 - accuracy: 0.7115 - val_loss: 6.8178 - val_accuracy: 0.3043\n",
      "Epoch 82/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3796 - accuracy: 0.6923 - val_loss: 6.8097 - val_accuracy: 0.2609\n",
      "Epoch 83/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3337 - accuracy: 0.7115 - val_loss: 6.9644 - val_accuracy: 0.2174\n",
      "Epoch 84/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4025 - accuracy: 0.7308 - val_loss: 6.9827 - val_accuracy: 0.2609\n",
      "Epoch 85/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4058 - accuracy: 0.7115 - val_loss: 7.3091 - val_accuracy: 0.2609\n",
      "Epoch 86/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3554 - accuracy: 0.7115 - val_loss: 6.8565 - val_accuracy: 0.2609\n",
      "Epoch 87/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3138 - accuracy: 0.7308 - val_loss: 6.6610 - val_accuracy: 0.2609\n",
      "Epoch 88/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3078 - accuracy: 0.7308 - val_loss: 6.8144 - val_accuracy: 0.2174\n",
      "Epoch 89/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3035 - accuracy: 0.7308 - val_loss: 6.7846 - val_accuracy: 0.2609\n",
      "Epoch 90/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.4246 - accuracy: 0.7308 - val_loss: 6.5013 - val_accuracy: 0.1739\n",
      "Epoch 91/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.2868 - accuracy: 0.7308 - val_loss: 6.4281 - val_accuracy: 0.2174\n",
      "Epoch 92/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.3600 - accuracy: 0.7115 - val_loss: 6.3015 - val_accuracy: 0.2174\n",
      "Epoch 93/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.3591 - accuracy: 0.7115 - val_loss: 6.3220 - val_accuracy: 0.2174\n",
      "Epoch 94/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.5822 - accuracy: 0.6923 - val_loss: 6.7624 - val_accuracy: 0.2174\n",
      "Epoch 95/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.5800 - accuracy: 0.6923 - val_loss: 6.7609 - val_accuracy: 0.2174\n",
      "Epoch 96/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.5741 - accuracy: 0.7115 - val_loss: 6.7503 - val_accuracy: 0.2174\n",
      "Epoch 97/100\n",
      "52/52 [==============================] - 0s 211us/step - loss: 1.6430 - accuracy: 0.6923 - val_loss: 6.7457 - val_accuracy: 0.2174\n",
      "Epoch 98/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.8175 - accuracy: 0.6731 - val_loss: 6.7401 - val_accuracy: 0.1739\n",
      "Epoch 99/100\n",
      "52/52 [==============================] - 0s 192us/step - loss: 1.7217 - accuracy: 0.6731 - val_loss: 6.7310 - val_accuracy: 0.1739\n",
      "Epoch 100/100\n",
      "52/52 [==============================] - 0s 173us/step - loss: 1.7194 - accuracy: 0.6731 - val_loss: 6.7190 - val_accuracy: 0.1739\n"
>>>>>>> enora
     ]
    }
   ],
   "source": [
    "n_timesteps = 1\n",
    "n_features = X_count.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu', input_shape=(n_timesteps, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Conv1D(filters=16, kernel_size=1, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y_train.shape[0], activation='relu'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64\n",
    "history = model.fit(X_count, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèle vectoriel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du vectoriseur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On passe au vectoriseur use_idf=False pour qu'il soit binaire (0 = absence du terme, 1 = présence du terme)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words=None,\n",
    "                            ngram_range=(1, 1),\n",
    "                            use_idf=False, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la matrice termes-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-baccabf07bd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdtm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "dtm = vectorizer.fit_transform(df['question'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interrogation du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous souhaitons trouver le document du corpus qui est le plus similaire à cette requête:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('french')\n",
    "sw.append('les') # manque dans la liste, par exemple\n",
    "vect = vectorizer = TfidfVectorizer(lowercase=True, stop_words=None,\n",
    "                            ngram_range=(1, 1),\n",
    "                            use_idf=False, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')\n",
    "dtm = vect.fit_transform(df)\n",
    "\n",
    "def vectorize_query(query_text):\n",
    "    query_file = 'query.txt'\n",
    "    with open(query_file, 'w', encoding=\"utf-8\") as out_f:\n",
    "        out_f.write(query_text)\n",
    "    query_vector = vect.transform([query_file])\n",
    "    os.unlink(query_file)\n",
    "    return query_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les salutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction sera utilisé pour le message d'acceuil entré par l'utilisateur et la génération de la réponse correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour les salutations de départ\n",
    "\n",
    "salutations_inputs = (\"salut\", \"hey\", \"coucou\", \"bonjour\")\n",
    "salutations_responses = [\"bonjour et bienvenu.e\", \"bonjour\", \"bienvenu.e\"]\n",
    "\n",
    "def generate_greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons créer une fonction qui prend en entrée l'utilisateur, trouve la similitude en cosinus de \n",
    "l'entrée utilisateur et la compare avec les phrases du corpus.\n",
    "\n",
    "Source : https://stackabuse.com/python-for-nlp-creating-a-rule-based-chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "sw = stopwords.words('french')\n",
    "sw.append('les') # manque dans la liste, par exemple\n",
    "vect = vectorizer = TfidfVectorizer(lowercase=True, stop_words=sw,\n",
    "                            ngram_range=(1, 1),\n",
    "                            use_idf=False, smooth_idf=True, # idf lissé\n",
    "                            sublinear_tf=False, norm='l2')\n",
    "dtm = vect.fit_transform(df)\n",
    "\n",
    "#Vectorisation de l'input utilisateur\n",
    "def vectorize_query(query_text):\n",
    "    query_file = 'query.txt'\n",
    "    with open(query_file, 'w', encoding=\"utf-8\") as out_f:\n",
    "        out_f.write(query_text) #ecrire l'input utilisateur dans un fichier texte\n",
    "    query_vector = vect.transform([query_file])\n",
    "    os.unlink(query_file)\n",
    "    return query_vector\n",
    "\n",
    "query = [\"test.txt\"]\n",
    "query_vector = vect.transform(query)\n",
    "#query_vector = vectorize_query(query)\n",
    "query_corpus_sim = np.squeeze(cosine_similarity(dtm, query_vector))\n",
    "idx_most_sim = np.argmax(query_corpus_sim)\n",
    "df[idx_most_sim]\n",
    "print(df[idx_most_sim])\n",
    "\n",
    "def get_best_doc(query_text):\n",
    "    query_vector = vectorize_query(query_text)\n",
    "    query_corpus_sim = np.squeeze(cosine_similarity(dtm, query_vector))\n",
    "    doc_id = np.argmax(query_corpus_sim)\n",
    "    doc_path = df[doc_id] # contient le répertoire parent\n",
    "    return doc_path\n",
    "\n",
    "def print_result(query_text):\n",
    "    doc_path = get_best_doc(query_text)\n",
    "    doc_filename = os.path.split(doc_path)[-1] # sans le répertoire parent\n",
    "    print(doc_filename) # affiche le nom du fichier\n",
    "    print('-' * 20)     # affiche une ligne de '-'\n",
    "    with open(doc_path, 'r') as in_f:\n",
    "        print(in_f.read(500) + '...') # affiche les premiers 500 caractères du doc\n",
    "\n",
    "query = 'politique'\n",
    "print_result(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
