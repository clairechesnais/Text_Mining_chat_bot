{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectif : trouver la question du thème la plus similaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_quest_user = \"Préparer mon séjour\" # on fixe un theme au pif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quest_user = \"Puis-je évaluer le confort de mon domaine ?\"\n",
    "#quest_user = \"Les annimaux domestiques sont-ils acceptés ?\"\n",
    "quest_user = \"ai-je besoin d'un visa ou d'un passeport ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq = pd.read_pickle('faq_centerPark.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('french')\n",
    "\n",
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']\n",
    "sw.sort()\n",
    "\n",
    "def lemmatise_text(text):\n",
    "    lst_lematised = [token.lemma_ for token in nlp(text)] \n",
    "    return ' '.join(lst_lematised).lower()\n",
    "\n",
    "\n",
    "def stem_text(text):\n",
    "    lst_stemmerised = [stemmer.stem(token) for token in word_tokenize(text)]    \n",
    "    return ' '.join(lst_stemmerised)\n",
    "\n",
    "\n",
    "def substitute_punctuation(text):\n",
    "    return ' '.join(text.replace(\"'\", ' ').translate(str.maketrans('', '', string.punctuation)).split())\n",
    "\n",
    "\n",
    "def supp(text):\n",
    "    return text.replace(\"«\", \"\").replace(\"’\", \"\").replace(\"•\", \"\").replace(\"®\", \"\")\n",
    "\n",
    "\n",
    "def supp_sw(text):\n",
    "    return ' '.join([token.text for token in nlp(text) if not token.text in sw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq['question_clean'] = (faq.question.apply(lemmatise_text)\n",
    "                                                 .apply(stem_text)\n",
    "                                                 .apply(substitute_punctuation)\n",
    "                                                 .apply(supp)\n",
    "                                                 .apply(supp_sw)\n",
    "                              )\n",
    "faq['reponse_clean'] = (faq.reponse.apply(lemmatise_text)\n",
    "                                               .apply(stem_text)\n",
    "                                               .apply(substitute_punctuation)\n",
    "                                               .apply(supp)\n",
    "                                               .apply(supp_sw)\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq.to_pickle('df_classif_similarity.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq['tokens'] = faq['question_clean'].apply(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sélection des questions du thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_theme = faq[faq.theme == theme_quest_user][[\"question\", 'reponse']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nettoyage de la question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_user_clean = supp_sw(supp(substitute_punctuation(stem_text(lemmatise_text(quest_user)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_user_clean_tokens = nlp(quest_user_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_similarity = [quest_user_clean_tokens.similarity(token) for token in faq_theme.tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_quest_user = faq_theme.reponse[np.asarray(lst_similarity).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Il est possible d’arriver n’importe quel jour de la semaine, à l’exception du dimanche, et pour une durée de 2 à 7 nuits. Les possibilités d’arrivées pendant les périodes de vacances scolaires sont plus limitées. Vous pouvez vous référer aux possibilités d’arrivées et de séjour dans votre réservation.'"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_quest_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
