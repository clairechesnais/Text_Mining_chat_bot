{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer('french')\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "sw = nltk.corpus.stopwords.words('french')\n",
    "sw += ['être', 'avoir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_code_theme = {\"Préparer mon séjour\": 1,\n",
    "                  \"Réserver et payer\": 2,\n",
    "                  \"Gérer ma réservation\": 3,\n",
    "                  \"Mon séjour\": 4,\n",
    "                  \"Assurances\": 5}\n",
    "dic_decode_theme = {val: key for key, val in dic_code_theme.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatise_text(text):\n",
    "    lst_lematised = [token.lemma_ for token in nlp(text)] \n",
    "    return ' '.join(lst_lematised).lower()\n",
    "\n",
    "\n",
    "def stem_text(text):\n",
    "    lst_stemmerised = [stemmer.stem(token) for token in word_tokenize(text)]    \n",
    "    return ' '.join(lst_stemmerised)\n",
    "\n",
    "\n",
    "def substitute_punctuation(text):\n",
    "    return ' '.join(text.replace(\"'\", ' ').translate(str.maketrans('', '', string.punctuation)).split())\n",
    "\n",
    "\n",
    "def supp(text):\n",
    "    return text.replace(\"«\", \"\").replace(\"’\", \"\").replace(\"•\", \"\").replace(\"®\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import du vectorizer et du classifieur\n",
    "\n",
    "from joblib import load\n",
    "vectoriser_theme = load('vectorizer_classif_theme.joblib')\n",
    "classifier_theme = load('model_classif_theme.joblib')\n",
    "classifier_domaine = load('model_classif_domaine.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_user = \"ça va ?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Classification de la question user en domaine (to be CenterPark or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "quest_user_clean = supp(substitute_punctuation(stem_text(lemmatise_text(quest_user))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_quest_user = pd.Series(quest_user_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_quest_user_clean_vectorized_tfidf = vectoriser_theme.transform(X_quest_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domaine_quest_user = classifier_domaine.predict(X_quest_user_clean_vectorized_tfidf)\n",
    "domaine_quest_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A. Si dans le domaine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Classification de la question user en themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redimension car NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_quest_user = X_quest_user_clean_vectorized_tfidf.toarray().reshape(X_quest_user_clean_vectorized_tfidf.shape[0],1,\n",
    "                                                X_quest_user_clean_vectorized_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédiction avec le classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = classifier_theme.predict(XX_quest_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation proba en classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "idx = np.argmax(pred_proba, axis=-1)\n",
    "YY_pred = np.zeros( pred_proba.shape )\n",
    "YY_pred[ np.arange(YY_pred.shape[0]), idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_quest_user = list(YY_pred[0]).index(1) +1\n",
    "theme_quest_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Trouver la question de la FAQ la plus proche/similaire de la question user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faq_theme = faq.iloc[theme_quest_user-1][[\"question\", 'reponse']]\n",
    "quest_user_clean = supp_sw(supp(substitute_punctuation(stem_text(lemmatise_text(quest_user)))))\n",
    "quest_user_clean_tokens = nlp(quest_user_clean)\n",
    "lst_similarity = [quest_user_clean_tokens.similarity(token) for token in faq_theme.tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Renvoyer la plus réponse de cette question FAQ (affichage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_quest_user = faq_theme.reponse[np.asarray(lst_similarity).argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Pas dans le domaine : générer réponse originale avec le GAN sur text (partie Mathilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
